{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 1: Imports & basic config\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport glob\n\nfrom numpy.linalg import norm\n\nfrom sklearn.model_selection import GridSearchCV, StratifiedGroupKFold, StratifiedKFold, GroupKFold, permutation_test_score, LeaveOneGroupOut, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.covariance import LedoitWolf\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.calibration import calibration_curve\nfrom sklearn.metrics import brier_score_loss\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_selection import RFE\nfrom sklearn.utils import resample, shuffle, resample\nfrom sklearn.base import clone\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\n\n\n\nimport nibabel as nib\n\n\nfrom joblib import Parallel, delayed\n\n\n\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom statsmodels.stats.multitest import multipletests\n\n\nimport itertools\nfrom itertools import combinations\n\nfrom nilearn import plotting, image, masking\nfrom nilearn.maskers import NiftiLabelsMasker\n\n\nfrom scipy import stats\nfrom scipy.stats import pearsonr, ttest_1samp, ttest_ind, entropy, kurtosis\nfrom scipy.spatial.distance import pdist, squareform, cdist\n\nfrom itertools import combinations\nfrom joblib import Parallel, delayed\nimport time\nimport statsmodels.formula.api as smf\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom typing import List, Union\nimport plotly.graph_objects as go\n# Nice plotting defaults\nsns.set_context(\"poster\")\n\nRANDOM_STATE = 42\nN_SPLITS = 5   # GroupKFold folds\nINNER_CV_SPLITS = 5     \nCS_LABELS = [\"CS-\", \"CSS\", \"CSR\"]  # the three CS types of interest\nN_JOBS = 1\nMAX_ITER = 5000\nthresh_hold_p = 1 - 0.05\nN_PERMUTATION = 5000\n#N_PERMUTATION = 1\n#N_REPEATS = 10\nN_REPEATS = 10\nCROSSNOBIS_REPEATS = 50\nSUBJECT_CV_SPLITS = 5\nSUBJECT_INNER_SPLITS = 3\nCALIB_BINS = 5\nTOP_PCT = 95\nLOW_PCT = 5\nTWO_TAIL_LOW = 2.5\nTWO_TAIL_HIGH = 97.5\nMIN_TRIALS_PER_SUBJECT = 10\nC_MIN_EXP = -2\nC_MAX_EXP = 2\nC_POINTS = 20\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subject_mean_accuracy(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    subjects: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"Compute mean subject-level accuracy from trial-level predictions.\"\"\"\n",
    "    sub_accs = []\n",
    "    for sub in np.unique(subjects):\n",
    "        mask = subjects == sub\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        sub_accs.append(accuracy_score(y_true[mask], y_pred[mask]))\n",
    "    return float(np.mean(sub_accs)) if sub_accs else 0.0\n",
    "\n",
    "def compute_subject_forced_choice_accs(\n",
    "    y_true: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    subjects: np.ndarray,\n",
    "    class_labels: List[str]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute per-subject forced-choice accuracies from decision scores.\"\"\"\n",
    "    df_scores = pd.DataFrame(scores, columns=class_labels)\n",
    "    df_scores[\"sub\"] = subjects\n",
    "    df_scores[\"y\"] = y_true\n",
    "\n",
    "    accs = []\n",
    "    for sub, sub_df in df_scores.groupby(\"sub\"):\n",
    "        mean_scores = sub_df.groupby(\"y\")[class_labels].mean().reset_index()\n",
    "        acc = compute_pairwise_forced_choice(\n",
    "            mean_scores[\"y\"].values,\n",
    "            mean_scores[class_labels].values,\n",
    "            class_labels\n",
    "        )\n",
    "        accs.append(acc)\n",
    "\n",
    "    return np.array(accs)\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "def compute_subject_forced_choice_mean_acc(\n",
    "    y_true: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    subjects: np.ndarray,\n",
    "    class_labels: List[str]\n",
    ") -> float:\n",
    "    \"\"\"Compute mean subject-level forced-choice accuracy from decision scores.\"\"\"\n",
    "    accs = compute_subject_forced_choice_accs(y_true, scores, subjects, class_labels)\n",
    "    return float(np.mean(accs)) if len(accs) > 0 else 0.0\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compute_perm_importance_simple ---\n",
    "\n",
    "def get_default_c_for_sub(sub_id):\n",
    "    group = get_group_for_sub(sub_id)\n",
    "    if group == \"SAD\" and best_c_sad is not None:\n",
    "        return float(best_c_sad)\n",
    "    if group == \"HC\" and best_c_hc is not None:\n",
    "        return float(best_c_hc)\n",
    "    return 1.0\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Calculation Helper (Entropy, Kurtosis, Variance)\n",
    "# =============================================================================\n",
    "\n",
    "def get_group_for_sub(sub_id):\n",
    "    if 'sub_to_meta' not in locals():\n",
    "        return None\n",
    "    s_str = str(sub_id).strip()\n",
    "    conds = None\n",
    "    if s_str in sub_to_meta:\n",
    "        conds = sub_to_meta[s_str]\n",
    "    elif f\"sub-{s_str}\" in sub_to_meta:\n",
    "        conds = sub_to_meta[f\"sub-{s_str}\"]\n",
    "    elif s_str.replace(\"sub-\", \"\") in sub_to_meta:\n",
    "        conds = sub_to_meta[s_str.replace(\"sub-\", \"\")]\n",
    "    if conds:\n",
    "        return conds.get(\"Group\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 2: Load phase2 (extinction) and phase3 (reinstatement) data\n# Update: Filters FEATURES to include only specific ROIs (Amygdala, Hippocampus, Insula, vmPFC, ACC).\n\nimport numpy as np\nimport os\n\nprint(\"--- Cell 2: Data Loading & ROI Filtering ---\")\n\nproject_root = \"/Users/xiaoqianxiao/projects/NARSAD\"\ndata_root = os.path.join(project_root, \"MRI/derivatives/fMRI_analysis/LSS\", \"firstLevel\", \"all_subjects/fear_network\")\nphase2_npz_path = os.path.join(data_root, \"phase2_X_ext_y_ext_roi_voxels.npz\")\nphase3_npz_path = os.path.join(data_root, \"phase3_X_reinst_y_reinst_roi_voxels.npz\") # Note: using 'reinst' variable name\n\n# Define the specific ROIs to keep\nTARGET_ROIS = [\n    'left_acc', 'left_amygdala', 'left_hippocampus', 'left_insula', 'left_vmpfc',\n    'right_acc', 'right_amygdala', 'right_hippocampus', 'right_insula', 'right_vmpfc'\n]\n\n# Load Files\nphase2_npz = np.load(phase2_npz_path, allow_pickle=True)\nphase3_npz = np.load(phase3_npz_path, allow_pickle=True)\n\n# ---- Helper: ROI Feature Selection ----\ndef filter_features_by_roi(X, roi_names, roi_counts, target_list):\n    \"\"\"\n    Creates a boolean mask for voxels belonging to target ROIs and filters X.\n    Returns: Filtered X, Filtered Parcel Names\n    \"\"\"\n    feature_mask = []\n    new_parcel_names = []\n    \n    # Iterate through each ROI metadata entry\n    for name, count in zip(roi_names, roi_counts):\n        # Create labels for this ROI (e.g., \"left_amygdala_0\")\n        current_labels = [f\"{name}_{i}\" for i in range(count)]\n        \n        if name in target_list:\n            # Keep these voxels\n            feature_mask.extend([True] * count)\n            new_parcel_names.extend(current_labels)\n        else:\n            # Drop these voxels\n            feature_mask.extend([False] * count)\n            \n    feature_mask = np.array(feature_mask)\n    \n    # Apply mask to columns (features)\n    if X.shape[1] != len(feature_mask):\n        raise ValueError(f\"Shape mismatch: X has {X.shape[1]} features, but ROI counts imply {len(feature_mask)}.\")\n        \n    X_filtered = X[:, feature_mask]\n    \n    return X_filtered, new_parcel_names\n\n# ---- Process Phase 2 (Extinction) ----\nX_ext_raw = phase2_npz[\"X_ext\"]\ny_ext = phase2_npz[\"y_ext\"]\nsub_ext = phase2_npz[\"subjects\"]\nroi_names_ext = phase2_npz[\"roi_names\"]\nroi_counts_ext = phase2_npz[\"roi_voxel_counts\"]\n\nprint(f\"Original Extinction Shape: {X_ext_raw.shape}\")\n\n# Apply ROI Filter\nX_ext, parcel_names_ext = filter_features_by_roi(X_ext_raw, roi_names_ext, roi_counts_ext, TARGET_ROIS)\nprint(f\"Filtered Extinction Shape: {X_ext.shape} (kept {len(TARGET_ROIS)} ROIs)\")\n\n\n# ---- Process Phase 3 (Reinstatement) ----\nX_reinst_raw = phase3_npz[\"X_reinst\"]\ny_reinst = phase3_npz[\"y_reinst\"]\nsub_reinst = phase3_npz[\"subjects\"]\nroi_names_reinst = phase3_npz[\"roi_names\"]\nroi_counts_reinst = phase3_npz[\"roi_voxel_counts\"]\n\n# Apply ROI Filter\nX_reinst, parcel_names_reinst = filter_features_by_roi(X_reinst_raw, roi_names_reinst, roi_counts_reinst, TARGET_ROIS)\nprint(f\"Filtered Reinstatement Shape: {X_reinst.shape}\")\n\n\n# ---- Filter for CS Trials Only ----\n# Constants (Define if not present)\nif 'CS_LABELS' not in locals(): CS_LABELS = [\"CS-\", \"CSS\", \"CSR\"]\n\n# Keep only CS-, CSS, CSR trials\nmask_ext = np.isin(y_ext, CS_LABELS)\nmask_reinst = np.isin(y_reinst, CS_LABELS)\n\nX_ext = X_ext[mask_ext]\ny_ext = y_ext[mask_ext]\nsub_ext = sub_ext[mask_ext]\n\nX_reinst = X_reinst[mask_reinst]\ny_reinst = y_reinst[mask_reinst]\nsub_reinst = sub_reinst[mask_reinst]\n\nprint(\"\\nAfter CS filtering:\")\nprint(\"Phase2 (Ext):\", X_ext.shape, np.unique(y_ext, return_counts=True))\nprint(\"Phase3 (Reinst):\", X_reinst.shape, np.unique(y_reinst, return_counts=True))\nprint(f\"Target ROIs included: {TARGET_ROIS}\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 3: Load subject-level metadata (Group, Drug, etc.)\n\n# Example: a CSV with one row per subject, columns like:\n#   subject_id, Group, Drug, Age, Sex, ...\n# where Group \u2208 {SAD, HC}, Drug \u2208 {OT, PLC} or similar\nmeta_path = os.path.join(project_root, \"MRI/source_data/behav/drug_order.csv\")\n\nmeta = pd.read_csv(meta_path)\n\nprint(meta.head())\nprint(meta.columns)\n\n# Basic sanity check: make sure subjects in X_ext/X_reinst exist in metadata\nunique_subs_ext = np.unique(sub_ext)\nunique_subs_reinst = np.unique(sub_reinst)\n\nprint(\"Phase2 unique subjects:\", len(unique_subs_ext))\nprint(\"Phase3 unique subjects:\", len(unique_subs_reinst))\n\nmissing_in_meta_ext = [s for s in unique_subs_ext if s not in set(meta[\"subject_id\"])]\nmissing_in_meta_reinst = [s for s in unique_subs_reinst if s not in set(meta[\"subject_id\"])]\n\nprint(\"Missing in meta (phase2):\", missing_in_meta_ext)\nprint(\"Missing in meta (phase3):\", missing_in_meta_reinst)\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# cell 4 helper functions\n",
    "# =============================================================================\n",
    "# 1. Pipeline & Preprocessing\n",
    "# =============================================================================\n",
    "param_grid = {\n",
    "    'classification__C': np.logspace(C_MIN_EXP, C_MAX_EXP, C_POINTS)\n",
    "}\n",
    "\n",
    "# # Variables to keep things clean\n",
    "# prev_best_c = 0.0045\n",
    "# # We combine a broad search with a dense local search\n",
    "# broad_search = np.logspace(-4, 2, 10) \n",
    "# dense_zoom = np.logspace(np.log10(prev_best_c) - 1, np.log10(prev_best_c) + 1, 20)\n",
    "\n",
    "# # Combine and sort to ensure a clean progression for the solver\n",
    "# refined_c_range = np.unique(np.sort(np.concatenate([broad_search, dense_zoom])))\n",
    "\n",
    "# param_grid = {\n",
    "#     'classification__C': refined_c_range\n",
    "# }\n",
    "\n",
    "# print(f\"Total points to test: {len(refined_c_range)}\")\n",
    "\n",
    "\n",
    "\n",
    "# SEARCH_RANGE_START = -5\n",
    "# SEARCH_RANGE_END = 3\n",
    "# N_POINTS = 30\n",
    "\n",
    "# param_grid = {\n",
    "#     'classification__C': np.logspace(SEARCH_RANGE_START, SEARCH_RANGE_END, N_POINTS)\n",
    "# }\n",
    "# Constants for the updated pipeline\n",
    "SOLVER_TYPE = 'saga'           # Required for 'elasticnet' penalty\n",
    "ELASTIC_PENALTY = 'elasticnet'\n",
    "MAX_ITER_SAGA = 10000  # Saga needs more iterations to converge\n",
    "\n",
    "\n",
    "def build_binary_pipeline():\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        ('classification', LogisticRegression(\n",
    "            penalty='l2', \n",
    "            solver='lbfgs', \n",
    "            class_weight='balanced', \n",
    "            max_iter=MAX_ITER, \n",
    "            random_state=RANDOM_STATE, \n",
    "            n_jobs=1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#------------------------------\n",
    "#--- Function: get_cv ---\n",
    "def get_cv(y, groups=None, n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE):\n",
    "    \"\"\"Return StratifiedGroupKFold if multiple groups exist; otherwise StratifiedKFold.\"\"\"\n",
    "    if groups is None or len(np.unique(groups)) < 2:\n",
    "        return StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=(random_state if shuffle else None))\n",
    "    return StratifiedGroupKFold(n_splits=n_splits, shuffle=shuffle, random_state=(random_state if shuffle else None))\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "#\n",
    "#--- Function: get_top_percentile_mask ---\n",
    "def get_top_percentile_mask(scores, percentile):\n",
    "    thresh = np.percentile(scores, percentile)\n",
    "    return (scores >= thresh) & (scores > 0)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_cross_decoding ---\n",
    "def run_cross_decoding(model, X, y, groups, classes=None):\n",
    "    \"\"\"\n",
    "    Applies a pre-trained model to a new dataset and calculates accuracy \n",
    "    per subject (group).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : estimator\n",
    "        A fitted scikit-learn estimator (e.g., the SAD model).\n",
    "    X : array-like\n",
    "        Feature matrix of the test set (e.g., HC data).\n",
    "    y : array-like\n",
    "        True labels of the test set.\n",
    "    groups : array-like\n",
    "        Subject IDs corresponding to X and y.\n",
    "    classes : array-like, optional\n",
    "        Expected class labels (used for verification, if needed).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    accuracies : np.ndarray\n",
    "        Array of accuracy scores, one per subject in 'groups'.\n",
    "    \"\"\"\n",
    "    unique_subjects = np.unique(groups)\n",
    "    accuracies = []\n",
    "\n",
    "    for sub in unique_subjects:\n",
    "        # 1. Isolate data for the current subject\n",
    "        mask_sub = (groups == sub)\n",
    "        X_sub = X[mask_sub]\n",
    "        y_sub = y[mask_sub]\n",
    "        \n",
    "        # 2. Make predictions using the provided (frozen) model\n",
    "        y_pred = model.predict(X_sub)\n",
    "        \n",
    "        # 3. Calculate accuracy for this subject\n",
    "        acc = accuracy_score(y_sub, y_pred)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return np.array(accuracies)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_perm_simple ---\n",
    "def run_perm_simple(X, y, groups, n_iters):\n",
    "    \"\"\"\n",
    "    Runs permutation testing iterations for a single job using\n",
    "    subject-level forced-choice accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Feature matrix.\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Labels.\n",
    "    groups : array-like, shape (n_samples,)\n",
    "        Subject IDs.\n",
    "    n_iters : int\n",
    "        Number of permutation iterations for this job.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    scores : list of mean subject-level forced-choice accuracy scores\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    y_shuffled = y.copy()\n",
    "\n",
    "    # CV with grouping (no subject leakage)\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        # 1. Shuffle labels\n",
    "        np.random.shuffle(y_shuffled)\n",
    "\n",
    "        # 2. Cross-validated decision scores on shuffled labels\n",
    "        scores_cv = cross_val_predict(\n",
    "            pipe,\n",
    "            X,\n",
    "            y_shuffled,\n",
    "            groups=groups,\n",
    "            cv=cv,\n",
    "            method=\"decision_function\",\n",
    "            n_jobs=1\n",
    "        )\n",
    "\n",
    "        # 3. Convert to 2D scores and compute subject-level forced-choice accuracy\n",
    "        scores_2d = (\n",
    "            np.column_stack((-scores_cv, scores_cv))\n",
    "            if scores_cv.ndim == 1\n",
    "            else scores_cv\n",
    "        )\n",
    "        class_labels = list(np.unique(y))\n",
    "        scores.append(\n",
    "            compute_subject_forced_choice_mean_acc(\n",
    "                y_shuffled,\n",
    "                scores_2d,\n",
    "                groups,\n",
    "                class_labels\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return scores\n",
    "def run_cross_perm(model, X, y, subs, n_iter):\n",
    "    \"\"\"Cross-decoding permutation using subject-level forced-choice accuracy.\"\"\"\n",
    "    null_scores = []\n",
    "    mask_c = np.isin(y, model.classes_)\n",
    "    X_f = X[mask_c]\n",
    "    y_f = y[mask_c]\n",
    "    s_f = subs[mask_c]\n",
    "\n",
    "    scores = model.decision_function(X_f)\n",
    "    scores_2d = (\n",
    "        np.column_stack((-scores, scores))\n",
    "        if scores.ndim == 1\n",
    "        else scores\n",
    "    )\n",
    "    class_labels = list(model.classes_)\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        y_shuff = np.random.permutation(y_f)\n",
    "        accs = compute_subject_forced_choice_accs(y_shuff, scores_2d, s_f, class_labels)\n",
    "        null_scores.append(float(np.mean(accs)) if len(accs) > 0 else 0.0)\n",
    "    return np.array(null_scores)\n",
    "\n",
    "#------------------------------\n",
    "def run_spatial_perm(seed, maps, groups):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    shuffled = rng.permutation(groups)\n",
    "    w_sad_p = np.mean(maps[shuffled == \"SAD\"], axis=0)\n",
    "    w_hc_p = np.mean(maps[shuffled == \"HC\"], axis=0)\n",
    "    return cosine_similarity(w_sad_p.reshape(1, -1), w_hc_p.reshape(1, -1))[0][0]\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_pairwise_decoding_analysis ---\n",
    "def run_pairwise_decoding_analysis(X, y, subjects, n_repeats=10):\n",
    "    X = np.array(X); y = np.array(y); subjects = np.array(subjects)\n",
    "    \n",
    "    classes = np.unique(y); pairs = list(combinations(classes, 2)); results = {}\n",
    "    \n",
    "    print(f\"\\n=== Starting Repeated Pairwise Decoding ({len(pairs)} pairs, {n_repeats} repeats) ===\")\n",
    "    \n",
    "    for c1, c2 in pairs:\n",
    "        pair_name = f\"{c1} vs {c2}\"; print(f\"\\n--- Analysis: {pair_name} ---\")\n",
    "        mask = np.isin(y, [c1, c2]); X_pair = X[mask]; y_pair = y[mask]; sub_pair = subjects[mask]\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # PHASE 1: EVALUATION (Repeated Nested CV with Forced-Choice)\n",
    "        # ---------------------------------------------------------------------\n",
    "        all_repeat_scores = []\n",
    "        \n",
    "        for r in range(n_repeats):\n",
    "            # Use a different random_state for each repeat to get different splits\n",
    "            # Important: shuffle=True is required for the seed to change the split\n",
    "            gkf_outer = get_cv(y_pair, sub_pair, n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE + r)\n",
    "            \n",
    "            repeat_scores = []\n",
    "            print(f\"  > Repeat {r+1}/{n_repeats}...\")\n",
    "            \n",
    "            for i, (train_idx, test_idx) in enumerate(gkf_outer.split(X_pair, y_pair, groups=sub_pair), 1):\n",
    "                cv_inner = get_cv(y_pair[train_idx], sub_pair[train_idx], n_splits=INNER_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE + r)\n",
    "                # Inner loop for hyperparameter tuning\n",
    "                gs = GridSearchCV(build_binary_pipeline(), param_grid, cv=cv_inner, scoring='accuracy', n_jobs=N_JOBS)\n",
    "                gs.fit(X_pair[train_idx], y_pair[train_idx], groups=sub_pair[train_idx])\n",
    "                \n",
    "                best_model = gs.best_estimator_\n",
    "                \n",
    "                # Forced-Choice logic on the Outer Test Fold\n",
    "                raw_val = best_model.decision_function(X_pair[test_idx])\n",
    "                scores_2d = np.column_stack((-raw_val, raw_val)) if raw_val.ndim == 1 else raw_val\n",
    "                \n",
    "                val_df = pd.DataFrame(scores_2d, columns=best_model.classes_)\n",
    "                val_df['sub'] = sub_pair[test_idx]\n",
    "                val_df['y'] = y_pair[test_idx]\n",
    "                mean_val = val_df.groupby(['sub', 'y']).mean().reset_index()\n",
    "                \n",
    "                fold_fc_acc = compute_pairwise_forced_choice(\n",
    "                    mean_val['y'].values, \n",
    "                    mean_val[best_model.classes_].values, \n",
    "                    best_model.classes_\n",
    "                )\n",
    "                repeat_scores.append(fold_fc_acc)\n",
    "            \n",
    "            all_repeat_scores.extend(repeat_scores)\n",
    "            \n",
    "        avg_cv_acc = np.mean(all_repeat_scores)\n",
    "        std_cv_acc = np.std(all_repeat_scores) # Total variance across all repeats/folds\n",
    "        print(f\"  > Final Mean Forced-Choice Accuracy ({n_repeats} repeats): {avg_cv_acc:.4f} (+/- {std_cv_acc:.4f})\")\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # PHASE 2: MODEL GENERATION (Refit on Full Data)\n",
    "        # ---------------------------------------------------------------------\n",
    "        # For the final model, we still refit once using a stable inner CV\n",
    "        print(\"  > Generating final model (Refit on full data for Haufe patterns)...\")\n",
    "        cv_inner_final = get_cv(y_pair, sub_pair, n_splits=INNER_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        gs_final = GridSearchCV(build_binary_pipeline(), param_grid, cv=cv_inner_final, scoring='accuracy', n_jobs=N_JOBS)\n",
    "        gs_final.fit(X_pair, y_pair, groups=sub_pair)\n",
    "        \n",
    "        final_model = gs_final.best_estimator_\n",
    "        \n",
    "        # Haufe Pattern calculation (using variables for stability)\n",
    "        W = final_model.named_steps['classification'].coef_\n",
    "        X_scaled = X_pair\n",
    "        A = np.cov(X_scaled, rowvar=False) @ W.T \n",
    "        \n",
    "        results[pair_name] = {\n",
    "            'model': final_model,\n",
    "            'accuracy': avg_cv_acc, \n",
    "            'std': std_cv_acc,\n",
    "            'best_C': gs_final.best_params_['classification__C'], \n",
    "            'haufe_pattern': A.flatten(), \n",
    "            'classes': final_model.classes_\n",
    "        }\n",
    "    return results\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: plot_dist_with_thresh ---\n",
    "def plot_dist_with_thresh(null_dist, obs_val, ax, title, tail='upper', color='gray'):\n",
    "    sns.histplot(null_dist, color='gray', stat='density', kde=True, alpha=0.4, ax=ax, label='Null Dist')\n",
    "    ax.axvline(obs_val, color='red', lw=2.5, label=f'Obs: {obs_val:.2f}')\n",
    "    if tail == 'upper':\n",
    "        thresh = np.percentile(null_dist, TOP_PCT); ax.axvline(thresh, color='blue', ls='--', lw=2, label=f'95%: {thresh:.2f}'); p_val = np.mean(null_dist >= obs_val)\n",
    "    elif tail == 'lower':\n",
    "        thresh = np.percentile(null_dist, LOW_PCT); ax.axvline(thresh, color='blue', ls='--', lw=2, label=f'5%: {thresh:.2f}'); p_val = np.mean(null_dist <= obs_val)\n",
    "    elif tail == 'two-tailed':\n",
    "        t_low = np.percentile(null_dist, TWO_TAIL_LOW); t_high = np.percentile(null_dist, TWO_TAIL_HIGH)\n",
    "        ax.axvline(t_low, color='blue', ls='--', lw=2); ax.axvline(t_high, color='blue', ls='--', lw=2)\n",
    "        p_val = 2 * min(np.mean(null_dist <= obs_val), np.mean(null_dist >= obs_val))\n",
    "    ax.set_title(f\"{title}\\n(p = {p_val:.4f})\"); ax.legend(loc='best', fontsize='small')\n",
    "    return p_val\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: make_river_plot_importance ---\n",
    "def make_river_plot_importance(importance_dict, feature_names, top_k=20, title=\"Neural Signatures\"):\n",
    "    # (Same as before)\n",
    "    pass \n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_group_key ---\n",
    "def get_group_key(sub_id):\n",
    "    \"\"\"Returns 'Group_Drug' key (e.g., 'SAD_Placebo') for a subject ID.\"\"\"\n",
    "    s_str = str(sub_id).strip()\n",
    "    \n",
    "    # Try different ID formats\n",
    "    conds = None\n",
    "    if s_str in sub_to_meta: conds = sub_to_meta[s_str]\n",
    "    elif f\"sub-{s_str}\" in sub_to_meta: conds = sub_to_meta[f\"sub-{s_str}\"]\n",
    "    elif s_str.replace(\"sub-\", \"\") in sub_to_meta: conds = sub_to_meta[s_str.replace(\"sub-\", \"\")]\n",
    "    \n",
    "    if conds:\n",
    "        return f\"{conds['Group']}_{conds['Drug']}\"\n",
    "    return None\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: process_phase_data ---\n",
    "def process_phase_data(X_all, y_all, sub_all, phase_name):\n",
    "    print(f\"\\nProcessing {phase_name} Phase...\")\n",
    "    if X_all is None: return {k: None for k in group_keys}\n",
    "    \n",
    "    # Storage for results\n",
    "    grouped_data = {k: {'X': [], 'y': [], 'sub': []} for k in group_keys}\n",
    "    \n",
    "    # 1. Identify Unique Subjects\n",
    "    unique_subs = np.unique(sub_all)\n",
    "    print(f\"  > Found {len(unique_subs)} unique subjects.\")\n",
    "    \n",
    "    count_missing_meta = 0\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # 2. Get Group Key\n",
    "        g_key = get_group_key(sub)\n",
    "        if not g_key:\n",
    "            count_missing_meta += 1\n",
    "            continue\n",
    "            \n",
    "        # 3. Extract Subject's FULL Data\n",
    "        mask_sub = (sub_all == sub)\n",
    "        X_sub_full = X_all[mask_sub]\n",
    "        y_sub_full = y_all[mask_sub]\n",
    "        \n",
    "        # 4. CENTER DATA (Full Subject Mean)\n",
    "        #    We subtract the mean of ALL trials (CS+, CS-, etc.) to preserve true baseline\n",
    "        sub_mean = np.mean(X_sub_full, axis=0)\n",
    "        X_sub_centered = X_sub_full - sub_mean\n",
    "        \n",
    "        # 5. FILTER CONDITIONS (Keep only CSS / CSR)\n",
    "        mask_cond = np.isin(y_sub_full, [\"CSS\", \"CSR\"])\n",
    "        \n",
    "        if np.sum(mask_cond) > 0:\n",
    "            grouped_data[g_key]['X'].append(X_sub_centered[mask_cond])\n",
    "            grouped_data[g_key]['y'].append(y_sub_full[mask_cond])\n",
    "            # Create subject ID array matching the filtered length\n",
    "            grouped_data[g_key]['sub'].append(np.full(np.sum(mask_cond), sub))\n",
    "            \n",
    "    if count_missing_meta > 0:\n",
    "        print(f\"  ! Warning: {count_missing_meta} subjects missing metadata skipped.\")\n",
    "\n",
    "    # 6. Final Assembly\n",
    "    final_output = {}\n",
    "    for key in group_keys:\n",
    "        if len(grouped_data[key]['X']) > 0:\n",
    "            final_output[key] = {\n",
    "                \"X\": np.vstack(grouped_data[key]['X']),\n",
    "                \"y\": np.concatenate(grouped_data[key]['y']),\n",
    "                \"sub\": np.concatenate(grouped_data[key]['sub'])\n",
    "            }\n",
    "            n_sub = len(np.unique(final_output[key]['sub']))\n",
    "            print(f\"  [{key}] {phase_name}: {n_sub} subjects | Matrix: {final_output[key]['X'].shape}\")\n",
    "        else:\n",
    "            final_output[key] = None\n",
    "            print(f\"  [{key}] {phase_name}: No data.\")\n",
    "            \n",
    "    return final_output\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_extinction_data ---\n",
    "def get_extinction_data(group_key):\n",
    "    if group_key not in data_subsets:\n",
    "        raise ValueError(f\"Group {group_key} missing from data_subsets.\")\n",
    "    \n",
    "    phase_data = data_subsets[group_key]['ext']\n",
    "    if phase_data is None:\n",
    "        raise ValueError(f\"Extinction data missing for {group_key}.\")\n",
    "        \n",
    "    # X is already centered from Cell 5\n",
    "    return phase_data[\"X\"], phase_data[\"y\"], phase_data[\"sub\"]\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: reconstruct_roi_map ---\n",
    "def reconstruct_roi_map(flat_data, roi_names, roi_dir):\n",
    "    \"\"\"\n",
    "    Paints a 1D array of values back into a 3D brain volume by iterating \n",
    "    through the specific list of ROI masks.\n",
    "    \"\"\"\n",
    "    # 1. Determine Reference Space (Load first mask)\n",
    "    first_mask_path = glob.glob(os.path.join(roi_dir, f\"*{roi_names[0]}*.nii*\"))[0]\n",
    "    ref_img = nib.load(first_mask_path)\n",
    "    affine = ref_img.affine\n",
    "    final_vol = np.zeros(ref_img.shape)\n",
    "    \n",
    "    current_idx = 0\n",
    "    \n",
    "    # 2. Iterate and Paint\n",
    "    for name in roi_names:\n",
    "        # Find file (handle potential suffixes like .nii or .nii.gz)\n",
    "        fpaths = glob.glob(os.path.join(roi_dir, f\"*{name}*.nii*\"))\n",
    "        if not fpaths:\n",
    "            print(f\"  ! Error: Mask for '{name}' not found in {roi_dir}\")\n",
    "            return None\n",
    "        \n",
    "        mask_img = nib.load(fpaths[0])\n",
    "        mask_data = mask_img.get_fdata() > 0 # Boolean mask\n",
    "        n_voxels = np.sum(mask_data)\n",
    "        \n",
    "        # Check if we have enough data left\n",
    "        if current_idx + n_voxels > len(flat_data):\n",
    "            print(f\"  ! Error: Data mismatch. Feature vector too short for ROI {name}.\")\n",
    "            return None\n",
    "            \n",
    "        # Extract chunk and paint\n",
    "        roi_values = flat_data[current_idx : current_idx + n_voxels]\n",
    "        final_vol[mask_data] = roi_values # Place values in 3D space\n",
    "        \n",
    "        current_idx += n_voxels\n",
    "        \n",
    "    # Check if data was fully consumed\n",
    "    if current_idx != len(flat_data):\n",
    "         print(f\"  ! Warning: {len(flat_data) - current_idx} features were unused (Feature vector longer than ROIs).\")\n",
    "\n",
    "    return nib.Nifti1Image(final_vol, affine)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compute_haufe_binary_robust ---\n",
    "def compute_haufe_binary_robust(model, X):\n",
    "    scores = model.decision_function(X)\n",
    "    return np.dot((X - np.mean(X, axis=0)).T, scores - np.mean(scores)) / (X.shape[0] - 1)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_robust_weights ---\n",
    "def get_robust_weights(X, y, subjects, pipeline, n_boot=10):\n",
    "    unique_subs = np.unique(subjects)\n",
    "    accumulated_weights = np.zeros(X.shape[1])\n",
    "    for i in range(n_boot):\n",
    "        boot_subs = resample(unique_subs, replace=True, random_state=i)\n",
    "        X_boot_list, y_boot_list = [], []\n",
    "        for sub in boot_subs:\n",
    "            mask = (subjects == sub)\n",
    "            X_sub = X[mask]\n",
    "            X_boot_list.append(X_sub - np.mean(X_sub, axis=0))\n",
    "            y_boot_list.append(y[mask])\n",
    "        X_boot = np.vstack(X_boot_list)\n",
    "        y_boot = np.hstack(y_boot_list)\n",
    "        \n",
    "        clf = clone(pipeline)\n",
    "        clf.fit(X_boot, y_boot)\n",
    "        accumulated_weights += compute_haufe_binary_robust(clf, X_boot)\n",
    "    return accumulated_weights / n_boot\n",
    "\n",
    "##------------------------------\n",
    "\n",
    "#--- Function: run_wen_paper_analysis_voxelwise ---\n",
    "def run_wen_paper_analysis_voxelwise(X, y, subjects, pipeline_template, best_C, n_permutations):\n",
    "    print(f\"  Estimating Weights ({n_permutations} perms)...\")\n",
    "    pipe = clone(pipeline_template); pipe.set_params(classification__C=best_C)\n",
    "    obs_weights = get_robust_weights(X, y, subjects, pipe, n_boot=10)\n",
    "    \n",
    "    def run_null(i):\n",
    "        y_shuff = shuffle(y, random_state=i)\n",
    "        return get_robust_weights(X, y_shuff, subjects, pipe, n_boot=1)\n",
    "\n",
    "    null_weights_list = Parallel(n_jobs=N_JOBS, verbose=1)(delayed(run_null)(i) for i in range(n_permutations))\n",
    "    null_weights = np.array(null_weights_list)\n",
    "    \n",
    "    null_mean = np.mean(null_weights, axis=0)\n",
    "    null_std = np.std(null_weights, axis=0)\n",
    "    z_scores = (obs_weights - null_mean) / (null_std + 1e-12)\n",
    "    \n",
    "    n_extreme = np.sum(np.abs(null_weights) >= np.abs(obs_weights), axis=0)\n",
    "    p_values = (n_extreme + 1) / (n_permutations + 1)\n",
    "    reject, _, _, _ = multipletests(p_values, alpha=fdr_alpha, method='fdr_bh')\n",
    "    \n",
    "    return z_scores, reject\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compute_pairwise_forced_choice ---\n",
    "def compute_pairwise_forced_choice(y_true, scores, class_labels):\n",
    "    \"\"\"\n",
    "    Computes accuracy where for each trial, the class with the higher \n",
    "    aggregated decision score is chosen.\n",
    "    \"\"\"\n",
    "    classes = sorted(list(set(y_true)))\n",
    "    accs = []\n",
    "    pairs = list(combinations(classes, 2))\n",
    "    \n",
    "    for c1, c2 in pairs:\n",
    "        idx_c1 = np.where(y_true == c1)[0]\n",
    "        idx_c2 = np.where(y_true == c2)[0]\n",
    "        if len(idx_c1) == 0 or len(idx_c2) == 0: continue\n",
    "            \n",
    "        col_c1 = list(class_labels).index(c1)\n",
    "        col_c2 = list(class_labels).index(c2)\n",
    "        \n",
    "        subset_idx = np.concatenate([idx_c1, idx_c2])\n",
    "        subset_y = y_true[subset_idx]\n",
    "        subset_scores = scores[subset_idx]\n",
    "        \n",
    "        # Choice logic: is score for C1 > score for C2?\n",
    "        diff = subset_scores[:, col_c1] - subset_scores[:, col_c2]\n",
    "        subset_pred = np.where(diff > 0, c1, c2)\n",
    "        \n",
    "        accs.append(accuracy_score(subset_y, subset_pred))\n",
    "        \n",
    "    return np.mean(accs) if accs else 0.0\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compute_perm_importance_simple ---\n",
    "def compute_perm_importance_simple(model, X, y, n_repeats=10):\n",
    "    \"\"\"\n",
    "    Calculates permutation importance for a model.\n",
    "    Returns: Mean importance decrease per feature.\n",
    "    \"\"\"\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    # We use 'accuracy' as the scoring metric to see which voxels contribute to decoding\n",
    "    result = permutation_importance(\n",
    "        model, X, y, n_repeats=n_repeats, random_state=42, n_jobs=-1, scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    return result.importances_mean\n",
    "\n",
    "def compute_perm_importance_cv(\n",
    "    model_template,\n",
    "    X,\n",
    "    y,\n",
    "    groups,\n",
    "    n_repeats=10,\n",
    "    n_splits=5\n",
    "):\n",
    "    \"\"\"Cross-validated permutation importance.\n",
    "\n",
    "    Fits a cloned model on each training fold and computes permutation\n",
    "    importance on the corresponding test fold to estimate generalization.\n",
    "    \"\"\"\n",
    "    from sklearn.inspection import permutation_importance\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    groups = np.asarray(groups)\n",
    "\n",
    "    cv = get_cv(y, groups, n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_importances = []\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y, groups=groups):\n",
    "        model = clone(model_template)\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        result = permutation_importance(\n",
    "            model,\n",
    "            X[test_idx],\n",
    "            y[test_idx],\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=1,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        fold_importances.append(result.importances_mean)\n",
    "\n",
    "    return np.mean(fold_importances, axis=0)\n",
    "\n",
    "##------------------------------\n",
    "\n",
    "#--- Function: calculate_centroid_rdm ---\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: extract_metrics ---\n",
    "def extract_metrics(rdms):\n",
    "    # Metric A: Threat (CSR) vs Safety (CSS)\n",
    "    m_a = rdms[:, idx_csr, idx_css] \n",
    "    # Metric B: Safety (CSS) vs Baseline (CS-)\n",
    "    m_b = rdms[:, idx_css, idx_cs_minus] \n",
    "    return m_a, m_b\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: one_sample_test ---\n",
    "def one_sample_test(data, name):\n",
    "    # Test if distance is greater than 0\n",
    "    t_val, p_val = ttest_1samp(data, 0, alternative='greater')\n",
    "    sig = \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"  > {name}: Mean={np.mean(data):.3f}, t={t_val:.3f}, p={p_val:.4f} ({sig})\")\n",
    "    return p_val\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: perm_ttest_ind ---\n",
    "def perm_ttest_ind(data1, data2, n_perm=N_PERMUTATION):\n",
    "    \"\"\"\n",
    "    Performs a permutation t-test for two independent samples.\n",
    "    Returns: t-stat, p-value, mean1, mean2\n",
    "    \"\"\"\n",
    "    from scipy.stats import ttest_ind\n",
    "    \n",
    "    # 1. Calculate observed t-statistic\n",
    "    t_obs, _ = ttest_ind(data1, data2)\n",
    "    \n",
    "    # 2. Permutation loop\n",
    "    pooled = np.concatenate([data1, data2])\n",
    "    n1 = len(data1)\n",
    "    null_dist = []\n",
    "    \n",
    "    rng = np.random.default_rng(42) # Fixed seed\n",
    "    \n",
    "    for _ in range(n_perm):\n",
    "        shuffled = rng.permutation(pooled)\n",
    "        # Split into two groups of same size as originals\n",
    "        g1 = shuffled[:n1]\n",
    "        g2 = shuffled[n1:]\n",
    "        \n",
    "        # Calculate t-stat for shuffled data\n",
    "        t_shuff, _ = ttest_ind(g1, g2)\n",
    "        null_dist.append(t_shuff)\n",
    "        \n",
    "    null_dist = np.array(null_dist)\n",
    "    \n",
    "    # 3. Calculate P-value (Two-tailed)\n",
    "    # Proportion of null t-stats more extreme than observed t\n",
    "    p_val = np.mean(np.abs(null_dist) >= np.abs(t_obs))\n",
    "    \n",
    "    return t_obs, p_val, np.mean(data1), np.mean(data2)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_sig_star ---\n",
    "def get_sig_star(p): return \"*\" if p < 0.05 else \"ns\"\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_phase_data ---\n",
    "def get_phase_data(group, phase):\n",
    "    try:\n",
    "        d = data_subsets[group][phase]\n",
    "        if d is None: return None, None, None\n",
    "        return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "    except KeyError:\n",
    "        return None, None, None\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calculate_plasticity_vectors ---\n",
    "def calculate_plasticity_vectors(\n",
    "    X_learn, y_learn, sub_learn,   # Data for Learning Trajectory (Start -> End)\n",
    "    X_targ, y_targ, sub_targ,      # Data for Target Definition\n",
    "    feature_mask, \n",
    "    cond_learn,                    # Condition changing (e.g., CSS or CSR)\n",
    "    cond_target_label              # Label of the target (e.g., CS- or CSR)\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates projection of learning (in X_learn) onto axis towards Target (in X_targ).\n",
    "    \"\"\"\n",
    "    # 1. Apply Feature Mask & Centering\n",
    "    # Note: Center phases separately to remove global session shifts (drift correction)\n",
    "    \n",
    "    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n",
    "    res = {'sub': [], 'projection': [], 'cosine': [], 'init_dist': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # Slice Learning Data (The Drift)\n",
    "        m_l = (sub_learn == sub); xl = X_L[m_l]; yl = y_learn[m_l]\n",
    "        \n",
    "        # Slice Target Data (The Goal)\n",
    "        m_t = (sub_targ == sub); xt = X_T[m_t]; yt = y_targ[m_t]\n",
    "        \n",
    "        # A. Define Target Centroid (P_target)\n",
    "        mask_tgt_cond = (yt == cond_target_label)\n",
    "        if np.sum(mask_tgt_cond) == 0: continue\n",
    "        P_target = np.mean(xt[mask_tgt_cond], axis=0)\n",
    "        \n",
    "        # B. Define Start & End (Learning Phase)\n",
    "        mask_lrn_cond = (yl == cond_learn)\n",
    "        idx_lrn = np.where(mask_lrn_cond)[0]\n",
    "        if len(idx_lrn) < 2: continue\n",
    "        \n",
    "        cutoff = len(idx_lrn) // 2\n",
    "        # Early Learning\n",
    "        P_start = np.mean(xl[idx_lrn[:cutoff]], axis=0)\n",
    "        # Late Learning\n",
    "        P_end = np.mean(xl[idx_lrn[cutoff:]], axis=0)\n",
    "        \n",
    "        # C. Define Vectors\n",
    "        # Axis: From Start (Ext) -> Target (Reinstatement or CS-)\n",
    "        V_axis = P_target - P_start\n",
    "        # Drift: Actual change during learning\n",
    "        V_drift = P_end - P_start\n",
    "        \n",
    "        norm_axis = norm(V_axis)\n",
    "        norm_drift = norm(V_drift)\n",
    "        \n",
    "        if norm_axis == 0 or norm_drift == 0: continue\n",
    "        \n",
    "        dot_prod = np.dot(V_drift, V_axis)\n",
    "        \n",
    "        # Scalar Projection (Magnitude)\n",
    "        projection = dot_prod / norm_axis\n",
    "        \n",
    "        # Cosine Similarity (Fidelity)\n",
    "        cosine = dot_prod / (norm_drift * norm_axis)\n",
    "        \n",
    "        res['sub'].append(sub)\n",
    "        res['projection'].append(projection)\n",
    "        res['cosine'].append(cosine)\n",
    "        res['init_dist'].append(norm_axis)\n",
    "        \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: tag_df ---\n",
    "def tag_df(df, grp, cond):\n",
    "    if df.empty: return df\n",
    "    d = df.copy(); d['Group'] = grp; d['Condition'] = cond\n",
    "    return d\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_trajectory ---\n",
    "def calc_trajectory(\n",
    "    X_learn, y_learn, sub_learn,    # The trials we want to project (the \"Movie\")\n",
    "    X_targ, y_targ, sub_targ,       # The dataset containing the Goal State\n",
    "    mask, \n",
    "    cond_learn,                     # Condition to track (e.g., CSS)\n",
    "    cond_target_label               # Label of Goal State (e.g., CS- or CSR)\n",
    "):\n",
    "    # Center Data separately to remove session effects\n",
    "    \n",
    "    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n",
    "    res = {'sub': [], 'trial': [], 'score': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # 1. Get Subject Data\n",
    "        xl = X_L[sub_learn == sub]; yl = y_learn[sub_learn == sub]\n",
    "        xt = X_T[sub_targ == sub]; yt = y_targ[sub_targ == sub]\n",
    "        \n",
    "        # 2. Define Start Point (Early Learning)\n",
    "        # We define \"Start\" as the centroid of the FIRST HALF of the learning trials\n",
    "        mask_l = (yl == cond_learn)\n",
    "        trials_l = xl[mask_l]\n",
    "        if len(trials_l) < 2: continue\n",
    "        \n",
    "        cutoff = max(1, len(trials_l) // 2)\n",
    "        P_start = np.mean(trials_l[:cutoff], axis=0)\n",
    "        \n",
    "        # 3. Define Target Point\n",
    "        mask_t = (yt == cond_target_label)\n",
    "        if np.sum(mask_t) == 0: continue\n",
    "        P_target = np.mean(xt[mask_t], axis=0)\n",
    "        \n",
    "        # 4. Define Axis\n",
    "        V_axis = P_target - P_start\n",
    "        sq_norm = np.dot(V_axis, V_axis)\n",
    "        if sq_norm == 0: continue\n",
    "        \n",
    "        # 5. Project Each Trial\n",
    "        # Logic: Score = ((Trial - Start) . Axis) / ||Axis||^2\n",
    "        # This normalizes the progress: 0.0 = Start, 1.0 = Target\n",
    "        \n",
    "        # We center the trials relative to the Start Point of this specific axis\n",
    "        trials_centered = trials_l - P_start\n",
    "        \n",
    "        scores = np.dot(trials_centered, V_axis) / sq_norm\n",
    "        \n",
    "        for i, s in enumerate(scores):\n",
    "            res['sub'].append(sub)\n",
    "            res['trial'].append(i + 1)\n",
    "            res['score'].append(s)\n",
    "            \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_detailed_stats ---\n",
    "def run_detailed_stats(df_sad, df_hc, label):\n",
    "    if df_sad.empty or df_hc.empty: return pd.DataFrame()\n",
    "    \n",
    "    trials = sorted(list(set(df_sad['trial'].unique()) & set(df_hc['trial'].unique())))\n",
    "    results = []\n",
    "    \n",
    "    for t in trials:\n",
    "        s_vals = df_sad[df_sad['trial'] == t]['score'].values\n",
    "        h_vals = df_hc[df_hc['trial'] == t]['score'].values\n",
    "        \n",
    "        # A. SAD > 0\n",
    "        t_s, p_s = ttest_1samp(s_vals, 0, alternative='greater')\n",
    "        df_s = len(s_vals) - 1\n",
    "        \n",
    "        # B. HC > 0\n",
    "        t_h, p_h = ttest_1samp(h_vals, 0, alternative='greater')\n",
    "        df_h = len(h_vals) - 1\n",
    "        \n",
    "        # C. SAD != HC\n",
    "        t_d, p_d = ttest_ind(s_vals, h_vals)\n",
    "        df_d = len(s_vals) + len(h_vals) - 2\n",
    "        \n",
    "        results.append({\n",
    "            'Trial': t,\n",
    "            'SAD_t': t_s, 'SAD_df': df_s, 'SAD_p': p_s,\n",
    "            'HC_t': t_h, 'HC_df': df_h, 'HC_p': p_h,\n",
    "            'Diff_t': t_d, 'Diff_df': df_d, 'Diff_p': p_d\n",
    "        })\n",
    "        \n",
    "    stats_df = pd.DataFrame(results)\n",
    "    \n",
    "    # FDR Correction\n",
    "    if not stats_df.empty:\n",
    "        _, stats_df['SAD_p_fdr'], _, _ = multipletests(stats_df['SAD_p'], alpha=0.05, method='fdr_bh')\n",
    "        _, stats_df['HC_p_fdr'], _, _ = multipletests(stats_df['HC_p'], alpha=0.05, method='fdr_bh')\n",
    "        _, stats_df['Diff_p_fdr'], _, _ = multipletests(stats_df['Diff_p'], alpha=0.05, method='fdr_bh')\n",
    "        \n",
    "    print(f\"\\n--- Statistics: {label} ---\")\n",
    "    # Print significant trials (Diff)\n",
    "    sig_diff = stats_df[stats_df['Diff_p_fdr'] < 0.05]\n",
    "    if not sig_diff.empty:\n",
    "        print(\"Significant Group Differences (FDR < 0.05):\")\n",
    "        print(sig_diff[['Trial', 'Diff_t', 'Diff_df', 'Diff_p', 'Diff_p_fdr']].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant group differences found (FDR corrected).\")\n",
    "        \n",
    "    return stats_df\n",
    "\n",
    "###------------------------------\n",
    "\n",
    "#--- Function: prepare_plot ---\n",
    "def prepare_plot(df_sad, df_hc, name):\n",
    "    if df_sad.empty and df_hc.empty: return pd.DataFrame()\n",
    "    d_list = []\n",
    "    if not df_sad.empty:\n",
    "        d1 = df_sad.copy(); d1['Group'] = 'SAD'; d_list.append(d1)\n",
    "    if not df_hc.empty:\n",
    "        d2 = df_hc.copy();  d2['Group'] = 'HC'; d_list.append(d2)\n",
    "    \n",
    "    if not d_list: return pd.DataFrame()\n",
    "    \n",
    "    df = pd.concat(d_list)\n",
    "    df['Condition'] = name\n",
    "    # Bin trials if needed\n",
    "    if BLOCK_SIZE > 1:\n",
    "        df['trial'] = ((df['trial'] - 1) // BLOCK_SIZE) + 1\n",
    "    return df\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_significant_mask ---\n",
    "def get_significant_mask(scores): return scores > 0\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calculate_distribution_stats ---\n",
    "def calculate_distribution_stats(X, y, subjects, feature_mask, best_params_dict):\n",
    "    # Slice Features & Center\n",
    "    X_masked = X[:, feature_mask]\n",
    "    \n",
    "    unique_subs = np.unique(subjects)\n",
    "    res = {'sub': [], 'entropy': [], 'kurtosis': [], 'variance': [], 'probabilities': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        c_val = best_params_dict.get(sub, 1.0)\n",
    "        mask_sub = (subjects == sub)\n",
    "        X_sub = X_masked[mask_sub]; y_sub = y[mask_sub]\n",
    "        \n",
    "        # Filter Boundary Classes\n",
    "        mask_binary = np.isin(y_sub, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n",
    "        X_binary = X_sub[mask_binary]; y_binary = y_sub[mask_binary]\n",
    "        \n",
    "        if len(y_binary) < MIN_TRIALS_PER_SUBJECT: continue\n",
    "        \n",
    "        try:\n",
    "            # Configure Model\n",
    "            fixed_model = build_binary_pipeline()\n",
    "            fixed_model.set_params(classification__C=c_val)\n",
    "            \n",
    "            # Cross-Validation\n",
    "            cv = get_cv(y_binary, np.full(len(y_binary), sub), n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            calib_model = CalibratedClassifierCV(\n",
    "                fixed_model,\n",
    "                method=\"sigmoid\",\n",
    "                cv=3\n",
    "            )\n",
    "            probs_all = cross_val_predict(calib_model, X_binary, y_binary, groups=np.full(len(y_binary), sub), cv=cv, method='predict_proba', n_jobs=1)\n",
    "            \n",
    "            # Extract Safety Cue Probabilities (P(Threat | Safety Cue))\n",
    "            classes = sorted(np.unique(y_binary))\n",
    "            if COND_CLASS_THREAT not in classes: continue\n",
    "            idx_threat = classes.index(COND_CLASS_THREAT)\n",
    "            \n",
    "            mask_css = (y_binary == COND_CLASS_SAFE)\n",
    "            if np.sum(mask_css) == 0: continue\n",
    "            probs_css = probs_all[mask_css, idx_threat]\n",
    "            \n",
    "            # Metrics\n",
    "            # 1. Entropy\n",
    "            p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n",
    "            trial_entropies = [entropy([p, 1-p], base=2) for p in p_clean]\n",
    "            \n",
    "            # 2. Kurtosis (Fisher's definition, Normal = 0.0)\n",
    "            k_val = kurtosis(probs_css, fisher=True)\n",
    "            \n",
    "            # 3. Variance\n",
    "            v_val = np.var(probs_css)\n",
    "            \n",
    "            res['sub'].append(sub)\n",
    "            res['entropy'].append(np.mean(trial_entropies))\n",
    "            res['kurtosis'].append(k_val)\n",
    "            res['variance'].append(v_val)\n",
    "            res['probabilities'].append(probs_css)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print(f\"  ! Subject {sub} failed: {e}\")\n",
    "            pass\n",
    "            \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_ext_data ---\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets: raise ValueError(f\"{group_key} missing.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compare_metric ---\n",
    "def compare_metric(vec1, vec2, metric_name):\n",
    "    print(f\"\\n--- Metric: {metric_name} ---\")\n",
    "    if len(vec1) == 0 or len(vec2) == 0:\n",
    "        print(\"  ! Insufficient data.\")\n",
    "        return 1.0\n",
    "        \n",
    "    print(f\"  > SAD Mean: {np.mean(vec1):.3f}\")\n",
    "    print(f\"  > HC Mean:  {np.mean(vec2):.3f}\")\n",
    "    \n",
    "    t, p, _, _ = perm_ttest_ind(vec1, vec2, n_perm=N_PERMUTATION)\n",
    "    sig = \"*\" if p < 0.05 else \"ns\"\n",
    "    print(f\"  > Comparison: t={t:.3f}, p={p:.4f} ({sig})\")\n",
    "    return p\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_lme ---\n",
    "def run_lme(formula, data, title):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    # Groups='Subject' handles random intercepts per subject\n",
    "    # If design is between-subject, this converges to GLM/ANOVA but handles missingness better\n",
    "    md = smf.mixedlm(formula, data, groups=data[\"Subject\"]) \n",
    "    try:\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        \n",
    "        # Extract Interaction P-Value safely\n",
    "        term = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n",
    "        if term in mdf.pvalues:\n",
    "            p_val = mdf.pvalues[term]\n",
    "            print(f\"  >>> Interaction P-Value: {p_val:.5f} {'*' if p_val < 0.05 else ''}\")\n",
    "            return p_val\n",
    "        else:\n",
    "            print(\"  ! Interaction term not found in model results.\")\n",
    "            return 1.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ! Model Convergence Failed: {e}\")\n",
    "        return 1.0\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_drift_metrics ---\n",
    "def calc_drift_metrics(X_start_phase, y_start_phase, X_tgt_phase, y_tgt_phase, \n",
    "                       cond_start, cond_target, mask, sub_id):\n",
    "    # Mask & Center (Phase-wise centering)\n",
    "    X_s = X_start_phase[:, mask]\n",
    "    \n",
    "    X_t = X_tgt_phase[:, mask]\n",
    "    \n",
    "    # Target Centroid\n",
    "    mask_tgt = (y_tgt_phase == cond_target)\n",
    "    if np.sum(mask_tgt) < 2: return None\n",
    "    P_target = np.mean(X_t[mask_tgt], axis=0)\n",
    "    \n",
    "    # Trajectory\n",
    "    mask_lrn = (y_start_phase == cond_start)\n",
    "    idx_lrn = np.where(mask_lrn)[0]\n",
    "    if len(idx_lrn) < 4: return None\n",
    "    \n",
    "    cutoff = len(idx_lrn) // 2\n",
    "    P_start = np.mean(X_s[idx_lrn[:cutoff]], axis=0)\n",
    "    P_end = np.mean(X_s[idx_lrn[cutoff:]], axis=0)\n",
    "    \n",
    "    # Vectors\n",
    "    V_axis = P_target - P_start\n",
    "    V_drift = P_end - P_start\n",
    "    \n",
    "    nA, nD = norm(V_axis), norm(V_drift)\n",
    "    if nA == 0 or nD == 0: return None\n",
    "    \n",
    "    dot = np.dot(V_drift, V_axis)\n",
    "    return {'Cosine': dot / (nA * nD), 'Projection': dot / nA}\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: plot_interaction ---\n",
    "def plot_interaction(ax, df, domain, metric, p_val):\n",
    "    data = df[df[\"Domain\"] == domain]\n",
    "    if data.empty: return\n",
    "    \n",
    "    # Error bars = Standard Error (se)\n",
    "    # This approximates within-subject error visualization for group means\n",
    "    sns.pointplot(data=data, x='Drug', y=metric, hue='Group', \n",
    "                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "                  dodge=0.15, markers=['o', 's'], linestyles=['-', '--'], \n",
    "                  capsize=0.1, err_kws={'linewidth': 2.5}, scale=1.2, \n",
    "                  errorbar='se', ax=ax)\n",
    "    \n",
    "    ax.set_title(f\"{domain} - {metric}\")\n",
    "    ax.axhline(0, color='gray', ls='--', alpha=0.5)\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    \n",
    "    if p_val < 0.05:\n",
    "        ax.text(0.5, 0.9, f\"Interaction p={p_val:.3f}\", transform=ax.transAxes, \n",
    "                ha='center', fontweight='bold', color='black')\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_metrics_for_subject ---\n",
    "def calc_metrics_for_subject(X, y, sub_id, feature_mask, C_param=1.0):\n",
    "    # 1. Mask & Center\n",
    "    X_m = X[:, feature_mask]\n",
    "    \n",
    "    # 2. Filter Binary Classes\n",
    "    mask_bin = np.isin(y, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n",
    "    X_bin, y_bin = X_m[mask_bin], y[mask_bin]\n",
    "    \n",
    "    if len(y_bin) < MIN_TRIALS_PER_SUBJECT: return None\n",
    "    \n",
    "    try:\n",
    "        # 3. CV Probabilities\n",
    "        model = build_binary_pipeline()\n",
    "        model.set_params(classification__C=C_param)\n",
    "        cv = get_cv(y_binary, np.full(len(y_binary), sub), n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            model,\n",
    "            method=\"sigmoid\",\n",
    "            cv=3\n",
    "        )\n",
    "        probs_all = cross_val_predict(calib_model, X_bin, y_bin, groups=np.full(len(y_bin), sub_id), cv=cv, method='predict_proba', n_jobs=1)\n",
    "        \n",
    "        # 4. Extract Safety Cue Probabilities\n",
    "        classes = sorted(np.unique(y_bin))\n",
    "        if COND_CLASS_THREAT not in classes: return None\n",
    "        idx_threat = classes.index(COND_CLASS_THREAT)\n",
    "        \n",
    "        mask_css = (y_bin == COND_CLASS_SAFE)\n",
    "        if np.sum(mask_css) == 0: return None\n",
    "        \n",
    "        # Prob(Threat | Safety Cue)\n",
    "        probs_css = probs_all[mask_css, idx_threat]\n",
    "        \n",
    "        # --- Metrics ---\n",
    "        # A. Entropy (Uncertainty)\n",
    "        p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n",
    "        ents = [entropy([p, 1-p], base=2) for p in p_clean]\n",
    "        val_ent = np.mean(ents)\n",
    "        \n",
    "        # B. Kurtosis (Sharpness) - Fisher's (Normal=0)\n",
    "        val_kurt = kurtosis(probs_css, fisher=True)\n",
    "        \n",
    "        # C. Variance (Spread)\n",
    "        val_var = np.var(probs_css)\n",
    "        \n",
    "        return {'Entropy': val_ent, 'Kurtosis': val_kurt, 'Variance': val_var}\n",
    "        \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: plot_metric ---\n",
    "def plot_metric(ax, metric, p_val):\n",
    "    sns.pointplot(data=df_metrics, x='Drug', y=metric, hue='Group', \n",
    "                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "                  dodge=0.2, markers=['o', 's'], linestyles=['-', '--'], \n",
    "                  capsize=0.1, errorbar='se', scale=1.1, ax=ax)\n",
    "    \n",
    "    ax.set_title(f\"{metric}\")\n",
    "    ax.set_ylabel(metric)\n",
    "    if metric == \"Entropy\": ax.set_ylabel(\"Entropy (Uncertainty)\")\n",
    "    if metric == \"Kurtosis\": ax.set_ylabel(\"Kurtosis (Sharpness)\")\n",
    "    \n",
    "    # Annotate Significance\n",
    "    if p_val < 0.05:\n",
    "        ax.text(0.5, 0.9, f\"Interaction\\np={p_val:.3f}\", transform=ax.transAxes, \n",
    "                ha='center', fontweight='bold', color='black')\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_forced_choice_acc ---\n",
    "\n",
    "    # 2. Center (Subject-wise)\n",
    "    \n",
    "    # 3. Get Decision Values\n",
    "    scores = model.decision_function(X_f)\n",
    "    \n",
    "    # 4. Aggregate Scores per Subject\n",
    "    df_scores = pd.DataFrame({'sub': s_f, 'cond': y_f, 'score': scores})\n",
    "    means = df_scores.groupby(['sub', 'cond'])['score'].mean().unstack()\n",
    "    \n",
    "    valid_subs = means.dropna().index\n",
    "    means = means.loc[valid_subs]\n",
    "    \n",
    "    # 5. Calculate Accuracy\n",
    "    pos_idx = np.where(model.classes_ == COND_THREAT)[0][0]\n",
    "    accs = []\n",
    "    \n",
    "    for sub in means.index:\n",
    "        s_threat = means.loc[sub, COND_THREAT]\n",
    "        s_safe = means.loc[sub, COND_SAFE]\n",
    "        \n",
    "        if pos_idx == 1: correct = s_threat > s_safe\n",
    "        else: correct = s_threat < s_safe\n",
    "        accs.append(1.0 if correct else 0.0)\n",
    "        \n",
    "    return accs\n",
    "    \n",
    "print(\"Cell 4: Updated to use Pairwise Forced-Choice for evaluation.\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# version 0\n# # Cell 5: Data Preparation & Subsetting (Optimized: Center -> Filter)\n# # Task: 1. Split data by subject.\n# #       2. Center FULL subject data (to preserve true baseline).\n# #       3. Filter for CSS/CSR conditions.\n# #       4. Organize into Groups (SAD/HC).\n\n# print(\"--- Cell 5: Data Preparation & Subsetting (Center -> Filter) ---\")\n\n# import numpy as np\n# import pandas as pd\n\n# # =============================================================================\n# # 0. Helper: Group Assignment Logic\n# # =============================================================================\n# if 'meta' in locals():\n#     # Standardize IDs\n#     meta['subject_id'] = meta['subject_id'].astype(str).str.strip()\n#     sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n#     print(f\"Metadata loaded for {len(sub_to_meta)} subjects.\")\n# else:\n#     raise ValueError(\"Metadata 'meta' not found. Please run Cell 3.\")\n\n# def get_group_key(sub_id):\n#     \"\"\"Returns 'Group_Drug' key (e.g., 'SAD_Placebo') for a subject ID.\"\"\"\n#     s_str = str(sub_id).strip()\n    \n#     # Try different ID formats\n#     conds = None\n#     if s_str in sub_to_meta: conds = sub_to_meta[s_str]\n#     elif f\"sub-{s_str}\" in sub_to_meta: conds = sub_to_meta[f\"sub-{s_str}\"]\n#     elif s_str.replace(\"sub-\", \"\") in sub_to_meta: conds = sub_to_meta[s_str.replace(\"sub-\", \"\")]\n    \n#     if conds:\n#         return f\"{conds['Group']}_{conds['Drug']}\"\n#     return None\n\n# # =============================================================================\n# # 1. Processing Logic (Subject-Wise Operation)\n# # =============================================================================\n# group_keys = [\"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"]\n\n# def process_phase_data(X_all, y_all, sub_all, phase_name):\n#     print(f\"\\nProcessing {phase_name} Phase...\")\n#     if X_all is None: return {k: None for k in group_keys}\n    \n#     # Storage for results\n#     grouped_data = {k: {'X': [], 'y': [], 'sub': []} for k in group_keys}\n    \n#     # 1. Identify Unique Subjects\n#     unique_subs = np.unique(sub_all)\n#     print(f\"  > Found {len(unique_subs)} unique subjects.\")\n    \n#     count_missing_meta = 0\n    \n#     for sub in unique_subs:\n#         # 2. Get Group Key\n#         g_key = get_group_key(sub)\n#         if not g_key:\n#             count_missing_meta += 1\n#             continue\n            \n#         # 3. Extract Subject's FULL Data\n#         mask_sub = (sub_all == sub)\n#         X_sub_full = X_all[mask_sub]\n#         y_sub_full = y_all[mask_sub]\n        \n#         # 4. CENTER DATA (Full Subject Mean)\n#         #    We subtract the mean of ALL trials (CS+, CS-, etc.) to preserve true baseline\n#         sub_mean = np.mean(X_sub_full, axis=0)\n#         X_sub_centered = X_sub_full - sub_mean\n        \n#         # 5. FILTER CONDITIONS (Keep only CSS / CSR)\n#         mask_cond = np.isin(y_sub_full, [\"CSS\", \"CSR\"])\n        \n#         if np.sum(mask_cond) > 0:\n#             grouped_data[g_key]['X'].append(X_sub_centered[mask_cond])\n#             grouped_data[g_key]['y'].append(y_sub_full[mask_cond])\n#             # Create subject ID array matching the filtered length\n#             grouped_data[g_key]['sub'].append(np.full(np.sum(mask_cond), sub))\n            \n#     if count_missing_meta > 0:\n#         print(f\"  ! Warning: {count_missing_meta} subjects missing metadata skipped.\")\n\n#     # 6. Final Assembly\n#     final_output = {}\n#     for key in group_keys:\n#         if len(grouped_data[key]['X']) > 0:\n#             final_output[key] = {\n#                 \"X\": np.vstack(grouped_data[key]['X']),\n#                 \"y\": np.concatenate(grouped_data[key]['y']),\n#                 \"sub\": np.concatenate(grouped_data[key]['sub'])\n#             }\n#             n_sub = len(np.unique(final_output[key]['sub']))\n#             print(f\"  [{key}] {phase_name}: {n_sub} subjects | Matrix: {final_output[key]['X'].shape}\")\n#         else:\n#             final_output[key] = None\n#             print(f\"  [{key}] {phase_name}: No data.\")\n            \n#     return final_output\n\n# # =============================================================================\n# # 2. Variable Detection\n# # =============================================================================\n# if 'X_ext' not in locals(): raise ValueError(\"X_ext missing. Run Cell 2.\")\n    \n# # Handle Reinstatement variable naming\n# if 'X_rst' in locals():\n#     X_rein, y_rein, sub_rein = X_rst, y_rst, sub_rst\n# elif 'X_reinst' in locals():\n#     X_rein, y_rein, sub_rein = X_reinst, y_reinst, sub_reinst\n# else:\n#     print(\"  ! Reinstatement data missing.\")\n#     X_rein, y_rein, sub_rein = None, None, None\n\n# # =============================================================================\n# # 3. Execute\n# # =============================================================================\n# ext_subsets = process_phase_data(X_ext, y_ext, sub_ext, \"Extinction\")\n# rst_subsets = process_phase_data(X_rein, y_rein, sub_rein, \"Reinstatement\")\n\n# # Structure Results\n# data_subsets = {}\n# for key in group_keys:\n#     data_subsets[key] = {\n#         \"ext\": ext_subsets.get(key),\n#         \"rst\": rst_subsets.get(key)\n#     }\n\n# print(\"\\nCell 5 Complete. Data is Centered (Full-Session) and Filtered.\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 5: Data Preparation & Subsetting (Optimized: Center -> Filter)\n# Task: 1. Split data by subject.\n#       2. Center FULL subject data (to preserve true baseline).\n#       3. Filter for CSS/CSR conditions.\n#       4. Organize into Groups (SAD/HC).\n\nprint(\"--- Cell 5: Data Preparation & Subsetting (Center -> Filter) ---\")\n\nimport numpy as np\nimport pandas as pd\n\n# =============================================================================\n# 0. Helper: Group Assignment Logic\n# =============================================================================\nif 'meta' in locals():\n    # Standardize IDs\n    meta['subject_id'] = meta['subject_id'].astype(str).str.strip()\n    sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n    print(f\"Metadata loaded for {len(sub_to_meta)} subjects.\")\nelse:\n    raise ValueError(\"Metadata 'meta' not found. Please run Cell 3.\")\n\ngroup_keys = [\"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"]\n\nif 'X_ext' not in locals(): raise ValueError(\"X_ext missing. Run Cell 2.\")\n    \n# Handle Reinstatement variable naming\nif 'X_rst' in locals():\n    X_rein, y_rein, sub_rein = X_rst, y_rst, sub_rst\nelif 'X_reinst' in locals():\n    X_rein, y_rein, sub_rein = X_reinst, y_reinst, sub_reinst\nelse:\n    print(\"  ! Reinstatement data missing.\")\n    X_rein, y_rein, sub_rein = None, None, None\n\n# =============================================================================\n# 3. Execute\n# =============================================================================\next_subsets = process_phase_data(X_ext, y_ext, sub_ext, \"Extinction\")\nrst_subsets = process_phase_data(X_rein, y_rein, sub_rein, \"Reinstatement\")\n\n# Structure Results\ndata_subsets = {}\nfor key in group_keys:\n    data_subsets[key] = {\n        \"ext\": ext_subsets.get(key),\n        \"rst\": rst_subsets.get(key)\n    }\n\nprint(\"\\nCell 5 Complete. Data is Centered (Full-Session) and Filtered.\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 6: Analysis 1.1 - Neural Dissociation Execution\n# Protocol: SAD -> HC\n# Updates:\n#   - Uses 'run_pairwise_decoding_analysis' (Standard Accuracy).\n#   - Functional Specificity Heatmap uses Mean CV Accuracy for diagonals (Evaluation).\n#   - Cross-Decoding uses the 'final_model' (Refitted on full data) on the other group.\n#   - Hyperparameter selected from 20 values (0.01-100) using training data only.\n#   - 5-fold CV, repeated 10 times with different splits; mean performance reported.\n#   - Forced-choice accuracy used to mitigate inter-site activation differences.\n\nprint(\"--- Running Analysis 1.1: Neural Dissociation ---\")\n\ntarget_param = 'classification__C'  # Variable for the hyperparameter key\n\n# =============================================================================\n# 0. Data Slicing\n# =============================================================================\n# Load Data\ntry:\n    X_hc, y_hc, sub_hc = get_extinction_data(\"HC_Placebo\")\n    X_sad, y_sad, sub_sad = get_extinction_data(\"SAD_Placebo\")\n    print(f\"Data Loaded: SAD (n={len(np.unique(sub_sad))}), HC (n={len(np.unique(sub_hc))})\")\nexcept ValueError as e:\n    print(f\"CRITICAL ERROR: {e}\")\n    raise\n\n# =============================================================================\n# TEST 1: Baseline Neural Discriminability (Self-Decoding)\n# =============================================================================\nprint(\"\\n--- TEST 1: Baseline Neural Discriminability ---\")\n\nprint(\"Processing SAD...\")\nres_sad_dict = run_pairwise_decoding_analysis(X_sad, y_sad, sub_sad, n_repeats=N_REPEATS)\nbest_c_sad = res_sad_dict[list(res_sad_dict.keys())[0]]['model'].get_params()[target_param]\nprint(f\"  > Best {target_param} for SAD: {best_c_sad}\")\n\nprint(\"Processing HC...\")\nres_hc_dict = run_pairwise_decoding_analysis(X_hc, y_hc, sub_hc, n_repeats=N_REPEATS)\nbest_c_hc = res_hc_dict[list(res_hc_dict.keys())[0]]['model'].get_params()[target_param]\nprint(f\"  > Best {target_param} for HC: {best_c_hc}\")\n\n# Select the target contrast (CSS vs CSR)\npair_key = \"CSR vs CSS\" if \"CSR vs CSS\" in res_sad_dict else \"CSS vs CSR\"\nif pair_key not in res_sad_dict or pair_key not in res_hc_dict:\n    raise ValueError(f\"Contrast {pair_key} not found. Check if CSS/CSR labels exist.\")\n\nres_sad = res_sad_dict[pair_key]\nres_hc = res_hc_dict[pair_key]\n\n# Permutation Test (Comparing Observed CV Score against Null CV Scores)\nprint(f\"Running Permutation Test (Self-Decoding, {N_PERMUTATION} iter)...\")\niters_per_job = N_PERMUTATION // N_JOBS\nperm_acc_sad = np.concatenate(Parallel(n_jobs=N_JOBS)(delayed(run_perm_simple)(X_sad, y_sad, sub_sad, iters_per_job) for _ in range(N_JOBS)))\nperm_acc_hc = np.concatenate(Parallel(n_jobs=N_JOBS)(delayed(run_perm_simple)(X_hc, y_hc, sub_hc, iters_per_job) for _ in range(N_JOBS)))\n\n# =============================================================================\n# TEST 2: Functional Specificity (Cross-Decoding)\n# =============================================================================\nprint(\"\\n--- TEST 2: Functional Specificity ---\")\n# Logic: Use Final Refit Model (Trained on All A) -> Predict All B -> Avg Subject Accuracy\n\n# A. SAD Model -> HC Data\nmodel_sad = res_sad['model'] # This is the Refit model\n# 'run_cross_decoding' calculates raw accuracy per subject\naccs_sad2hc = run_cross_decoding(model_sad, X_hc, y_hc, sub_hc, model_sad.classes_)\nmean_sad2hc = np.mean(accs_sad2hc)\nprint(f\"  > SAD Model -> HC Data: {mean_sad2hc:.4f}\")\n\n# B. HC Model -> SAD Data\nmodel_hc = res_hc['model']\naccs_hc2sad = run_cross_decoding(model_hc, X_sad, y_sad, sub_sad, model_hc.classes_)\nmean_hc2sad = np.mean(accs_hc2sad)\nprint(f\"  > HC Model -> SAD Data: {mean_hc2sad:.4f}\")\n\n# Permutation Test (Cross-Decoding)\nprint(f\"Running Permutation Test (Cross-Decoding, {N_PERMUTATION} iter)...\")\nperm_sad2hc = np.concatenate(Parallel(n_jobs=N_JOBS)(\n    delayed(run_cross_perm)(model_sad, X_hc, y_hc, sub_hc, iters_per_job) for _ in range(N_JOBS)))\np_sad2hc = np.mean(perm_sad2hc >= mean_sad2hc)\n\nperm_hc2sad = np.concatenate(Parallel(n_jobs=N_JOBS)(\n    delayed(run_cross_perm)(model_hc, X_sad, y_sad, sub_sad, iters_per_job) for _ in range(N_JOBS)))\np_hc2sad = np.mean(perm_hc2sad >= mean_hc2sad)\n\n# =============================================================================\n# TEST 3: Spatial Specificity\n# =============================================================================\nprint(\"\\n--- TEST 3: Spatial Specificity ---\")\nmap_sad, map_hc = res_sad['haufe_pattern'], res_hc['haufe_pattern']\nobs_sim = cosine_similarity(map_sad.reshape(1, -1), map_hc.reshape(1, -1))[0][0]\n\n# Prepare Data for Permutation (Combine groups)\nX_comb = np.concatenate([X_sad, X_hc])\ny_comb = np.concatenate([y_sad, y_hc])\nsub_comb = np.concatenate([sub_sad, sub_hc])\n\nall_sub_maps, all_sub_groups = [], []\nperm_pipe = build_binary_pipeline(); perm_pipe.set_params(classification__C=1.0)\n\n# Pre-compute subject maps\nprint(f\"Pre-computing {len(np.unique(sub_comb))} individual subject maps...\")\nfor sub in np.unique(sub_comb):\n    mask = sub_comb == sub\n    perm_pipe.fit(X_comb[mask], y_comb[mask])\n    W = perm_pipe.named_steps['classification'].coef_\n    # Calculate Covariance (Scaler handles centered input)\n    cov = np.cov(X_comb[mask], rowvar=False)\n    A = cov @ W.T\n    \n    if perm_pipe.classes_[1] == 'CSS': A = -A \n    all_sub_maps.append(A.flatten())\n    all_sub_groups.append(\"SAD\" if sub in sub_sad else \"HC\")\n\n# Run Spatial Permutation\nprint(f\"Running Spatial Permutation ({N_PERMUTATION} iter)...\")\nperm_sims = np.array(Parallel(n_jobs=N_JOBS)(delayed(run_spatial_perm)(i, np.array(all_sub_maps), np.array(all_sub_groups)) for i in range(N_PERMUTATION)))\n\np_sim_spatial = 2 * min(np.mean(perm_sims <= obs_sim), np.mean(perm_sims >= obs_sim))\n\n# =============================================================================\n# VISUALIZATION\n# =============================================================================\nprint(\"\\n--- Generating Plots ---\")\nsns.set_context(\"poster\")\n\nfig = plt.figure(figsize=(20, 12))\ngs = fig.add_gridspec(2, 2, height_ratios=[1, 1.2])\n\n# Row 1: Self-Decoding (Permutation Distribution)\np_sad = plot_dist_with_thresh(perm_acc_sad, res_sad['accuracy'], fig.add_subplot(gs[0, 0]), \n                              f\"SAD Self-Decoding (CV Acc: {res_sad['accuracy']:.2f})\")\np_hc = plot_dist_with_thresh(perm_acc_hc, res_hc['accuracy'], fig.add_subplot(gs[0, 1]), \n                             f\"HC Self-Decoding (CV Acc: {res_hc['accuracy']:.2f})\")\n\n# Row 2: Matrices\n# Functional Specificity\nax3 = fig.add_subplot(gs[1, 0])\n\n# Matrix: [CV Accuracy] vs [Mean Cross Accuracy]\n# Diagonals: Generalization within group (CV)\n# Off-Diagonals: Generalization across groups (Cross-Decoding)\nfunc_matrix = np.array([\n    [res_sad['accuracy'], mean_sad2hc], \n    [mean_hc2sad, res_hc['accuracy']]\n])\nfunc_pvals = np.array([[p_sad, p_sad2hc], [p_hc2sad, p_hc]])\n\nannot_func = np.empty_like(func_matrix, dtype=object)\nfor i in range(2):\n    for j in range(2):\n        val_str = f\"{func_matrix[i, j]:.3f}\"\n        sig_str = \"*\" if func_pvals[i, j] < 0.05 else \"\"\n        annot_func[i, j] = f\"{val_str}\\n({sig_str})\"\n\nsns.heatmap(func_matrix, annot=annot_func, fmt=\"\", cmap=\"RdBu_r\", center=0.5, vmin=0.3, vmax=0.9, cbar=True,\n            xticklabels=['Test SAD', 'Test HC'], yticklabels=['Train SAD', 'Train HC'], ax=ax3)\nax3.set_title(\"Functional Specificity\\n(Standard Accuracy)\")\n\n# Spatial Specificity\nax4 = fig.add_subplot(gs[1, 1])\nspatial_matrix = np.array([[1.0, obs_sim], [obs_sim, 1.0]])\nspatial_pvals = np.array([[0.0, p_sim_spatial], [p_sim_spatial, 0.0]])\nannot_spatial = np.empty_like(spatial_matrix, dtype=object)\nfor i in range(2):\n    for j in range(2):\n        star = \"*\" if (spatial_pvals[i, j] < 0.05 and i != j) else \"\"\n        annot_spatial[i, j] = f\"{spatial_matrix[i, j]:.3f}\\n{star}\"\n\nsns.heatmap(spatial_matrix, annot=annot_spatial, fmt=\"\", cmap=\"RdBu_r\", center=0, vmin=-1, vmax=1, cbar=True,\n            xticklabels=['SAD Map', 'HC Map'], yticklabels=['SAD Map', 'HC Map'], ax=ax4)\nax4.set_title(\"Spatial Specificity\")\n\nplt.tight_layout()\nplt.show()\n\n# Save Results\nresults_11 = {\n    \"acc_sad_cv\": res_sad['accuracy'], \n    \"p_sad\": p_sad, \n    \"acc_hc_cv\": res_hc['accuracy'], \n    \"p_hc\": p_hc, \n    \"func_matrix\": func_matrix, \n    \"sim_spatial\": obs_sim, \n    \"p_sim\": p_sim_spatial,\n    \"map_sad\": map_sad, \n    \"map_hc\": map_hc\n}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# # Whole-brain version\n# # Cell 7: Voxel-wise Spatial Topology & Visualization\n# # Context: Voxel-wise analysis using Haufe Transforms & Permutation Testing.\n# # Fix: Loads specific ROI mask if available, or handles unmasking errors gracefully.\n\n# print(\"--- Cell 7: Running Voxel-wise Spatial Analysis ---\")\n\n# import os\n# import nibabel as nib\n# import numpy as np\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# from nilearn import plotting, image, masking\n# from statsmodels.stats.multitest import multipletests\n# from sklearn.base import clone\n# from sklearn.utils import resample, shuffle\n# from joblib import Parallel, delayed\n\n# # =============================================================================\n# # 0. Setup & Dependency Check\n# # =============================================================================\n# # 1. Check for Results\n# if 'res_sad' not in locals() or 'res_hc' not in locals():\n#     raise ValueError(\"Analysis results ('res_sad', 'res_hc') not found. Please run Cell 6 first.\")\n\n# # 2. Check for Data\n# if 'X_sad' not in locals():\n#     print(\"Loading data from 'data_subsets'...\")\n#     try:\n#         d_s = data_subsets[\"SAD_Placebo\"][\"ext\"]\n#         d_h = data_subsets[\"HC_Placebo\"][\"ext\"]\n#         X_sad, y_sad, sub_sad = d_s[\"X\"], d_s[\"y\"], d_s[\"sub\"]\n#         X_hc, y_hc, sub_hc = d_h[\"X\"], d_h[\"y\"], d_h[\"sub\"]\n#     except Exception:\n#         raise ValueError(\"Data missing. Please run Cell 5.\")\n\n# # 3. MASK HANDLING (CRITICAL FIX)\n# # We need the mask that matches X_sad.shape[1]\n# # Option A: Try to find a specific ROI mask in data root\n# roi_mask_path = os.path.join(data_root, \"mask.nii.gz\") # Adjust this name if your mask is named differently!\n# std_mask_path = '/Users/xiaoqianxiao/fsl/data/standard/MNI152_T1_2mm_brain_mask.nii.gz'\n\n# mask_img = None\n# if os.path.exists(roi_mask_path):\n#     print(f\"  > Loading Data Specific Mask: {roi_mask_path}\")\n#     mask_img = nib.load(roi_mask_path)\n#     # Check size match\n#     if np.sum(mask_img.get_fdata() > 0) != X_sad.shape[1]:\n#         print(f\"  ! WARNING: Mask size ({np.sum(mask_img.get_fdata()>0)}) != Feature size ({X_sad.shape[1]}). Visualization will be skipped.\")\n#         mask_img = None\n# elif os.path.exists(std_mask_path):\n#     print(f\"  > Loading Standard Mask: {std_mask_path}\")\n#     temp_mask = nib.load(std_mask_path)\n#     # Only use if sizes match (unlikely for ROI analysis, but good check)\n#     if np.sum(temp_mask.get_fdata() > 0) == X_sad.shape[1]:\n#         mask_img = temp_mask\n#     else:\n#         print(f\"  ! Standard mask size mismatch ({np.sum(temp_mask.get_fdata()>0)} vs {X_sad.shape[1]}).\")\n#         print(\"  ! Skipping 'unmask' visualization to prevent crash.\")\n\n# # 4. Config\n# alpha_val = thresh_hold_p if 'thresh_hold_p' in locals() else 0.05\n# fdr_alpha = 1 - alpha_val if alpha_val > 0.5 else alpha_val\n# print(f\"FDR Alpha Level: {fdr_alpha}\")\n\n# # =============================================================================\n# # 1. Analysis Helper Functions\n# # =============================================================================\n# def compute_haufe_binary_robust(model, X):\n#     scores = model.decision_function(X)\n#     return np.dot((X - np.mean(X, axis=0)).T, scores - np.mean(scores)) / (X.shape[0] - 1)\n\n# def get_robust_weights(X, y, subjects, pipeline, n_boot=10):\n#     unique_subs = np.unique(subjects)\n#     accumulated_weights = np.zeros(X.shape[1])\n#     for i in range(n_boot):\n#         boot_subs = resample(unique_subs, replace=True, random_state=i)\n#         X_boot_list, y_boot_list = [], []\n#         for sub in boot_subs:\n#             mask = (subjects == sub)\n#             X_sub = X[mask]\n#             X_boot_list.append(X_sub - np.mean(X_sub, axis=0))\n#             y_boot_list.append(y[mask])\n#         X_boot = np.vstack(X_boot_list)\n#         y_boot = np.hstack(y_boot_list)\n        \n#         clf = clone(pipeline)\n#         clf.fit(X_boot, y_boot)\n#         accumulated_weights += compute_haufe_binary_robust(clf, X_boot)\n#     return accumulated_weights / n_boot\n\n# def run_wen_paper_analysis_voxelwise(X, y, subjects, pipeline_template, best_C, n_permutations):\n#     print(f\"  Estimating Weights ({n_permutations} perms)...\")\n#     pipe = clone(pipeline_template); pipe.set_params(classification__C=best_C)\n#     obs_weights = get_robust_weights(X, y, subjects, pipe, n_boot=10)\n    \n#     def run_null(i):\n#         y_shuff = shuffle(y, random_state=i)\n#         return get_robust_weights(X, y_shuff, subjects, pipe, n_boot=1)\n\n#     null_weights_list = Parallel(n_jobs=N_JOBS, verbose=1)(delayed(run_null)(i) for i in range(n_permutations))\n#     null_weights = np.array(null_weights_list)\n    \n#     null_mean = np.mean(null_weights, axis=0)\n#     null_std = np.std(null_weights, axis=0)\n#     z_scores = (obs_weights - null_mean) / (null_std + 1e-12)\n    \n#     n_extreme = np.sum(np.abs(null_weights) >= np.abs(obs_weights), axis=0)\n#     p_values = (n_extreme + 1) / (n_permutations + 1)\n#     reject, _, _, _ = multipletests(p_values, alpha=fdr_alpha, method='fdr_bh')\n    \n#     return z_scores, reject\n\n# # =============================================================================\n# # 2. Execution\n# # =============================================================================\n# groups = {\n#     'SAD': {'X': X_sad, 'y': y_sad, 'sub': sub_sad, 'res': res_sad}, \n#     'HC':  {'X': X_hc,  'y': y_hc,  'sub': sub_hc,  'res': res_hc}\n# }\n# target_pair = ['CSR', 'CSS']\n# sns.set_context(\"poster\")\n\n# spatial_results = {}\n\n# for name, data in groups.items():\n#     print(f\"\\nAnalyzing {name}...\")\n#     mask_cls = np.isin(data['y'], target_pair)\n#     X_curr = data['X'][mask_cls]\n#     y_curr = data['y'][mask_cls]\n#     sub_curr = data['sub'][mask_cls]\n    \n#     z_scores, sig_mask = run_wen_paper_analysis_voxelwise(\n#         X_p, y_curr, sub_curr, build_binary_pipeline(), data['res']['best_C'], N_PERMUTATION\n#     )\n    \n#     dummy_pipe = build_binary_pipeline(); dummy_pipe.fit(X_p, y_curr)\n#     if dummy_pipe.classes_[0] == 'CSR': z_scores = -z_scores\n    \n#     spatial_results[f\"{name} Placebo\"] = {'z_scores': z_scores, 'sig_mask': sig_mask}\n    \n#     n_sig = np.sum(sig_mask)\n#     print(f\"Significant Voxels: {n_sig} ({(n_sig/len(z_scores))*100:.2f}%)\")\n    \n#     # VISUALIZATION BLOCK (Protected)\n#     if n_sig > 0:\n#         if mask_img is not None:\n#             try:\n#                 z_map_masked = z_scores * sig_mask\n#                 z_img = masking.unmask(z_map_masked, mask_img)\n#                 fig = plt.figure(figsize=(16, 6))\n#                 plotting.plot_glass_brain(\n#                     z_img, threshold=1.96, plot_abs=False, display_mode='lyrz', \n#                     colorbar=True, vmin=-5, vmax=5, cmap='RdBu_r', \n#                     title=f\"{name}: FDR < {fdr_alpha}\", figure=fig\n#                 )\n#                 plt.show()\n                \n#             except Exception as e:\n#                 print(f\"  ! Visualization failed: {e}\")\n#         else:\n#             print(\"  ! Mask not available. Skipping glass brain plot.\")\n\n# print(\"--- Cell 7 Complete (Spatial Results Stored) ---\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 7: Voxel-wise Spatial Topology & Visualization (ROI Reconstruction)\n# Context: Voxel-wise analysis using Haufe Transforms.\n# Fix: Reconstructs whole-brain maps by \"painting\" Z-scores back into individual ROI masks.\n\nprint(\"--- Cell 7: Running Voxel-wise Spatial Analysis (ROI Reconstruction) ---\")\n\n\n# =============================================================================\n# 0. Setup & Configuration\n# =============================================================================\n# 1. ROI Configuration\nROI_DIR = \"/Users/xiaoqianxiao/tool/parcellation/Gillian_anatomically_constrained\"\nROI_ORDER = [\n    'left_acc', 'left_amygdala', 'left_hippocampus', 'left_insula', 'left_vmpfc',\n    'right_acc', 'right_amygdala', 'right_hippocampus', 'right_insula', 'right_vmpfc'\n]\n\n# 2. Check for Results\nif 'res_sad' not in locals() or 'res_hc' not in locals():\n    raise ValueError(\"Analysis results ('res_sad', 'res_hc') not found. Please run Cell 6 first.\")\n\n# 3. Check for Data\nif 'X_sad' not in locals():\n    print(\"Loading data from 'data_subsets'...\")\n    try:\n        d_s = data_subsets[\"SAD_Placebo\"][\"ext\"]\n        d_h = data_subsets[\"HC_Placebo\"][\"ext\"]\n        X_sad, y_sad, sub_sad = d_s[\"X\"], d_s[\"y\"], d_s[\"sub\"]\n        X_hc, y_hc, sub_hc = d_h[\"X\"], d_h[\"y\"], d_h[\"sub\"]\n    except Exception:\n        raise ValueError(\"Data missing. Please run Cell 5.\")\n\n# 4. Config\nalpha_val = thresh_hold_p if 'thresh_hold_p' in locals() else 0.05\nfdr_alpha = 1 - alpha_val if alpha_val > 0.5 else alpha_val\nprint(f\"FDR Alpha Level: {fdr_alpha}\")\n\n# =============================================================================\n# 1. Helper: ROI Map Reconstruction\n# =============================================================================\ndef reconstruct_roi_map(flat_data, roi_names, roi_dir):\n    \"\"\"\n    Paints a 1D array of values back into a 3D brain volume by iterating \n    through the specific list of ROI masks.\n    \"\"\"\n    # 1. Determine Reference Space (Load first mask)\n    first_mask_path = glob.glob(os.path.join(roi_dir, f\"*{roi_names[0]}*.nii*\"))[0]\n    ref_img = nib.load(first_mask_path)\n    affine = ref_img.affine\n    final_vol = np.zeros(ref_img.shape)\n    \n    current_idx = 0\n    \n    # 2. Iterate and Paint\n    for name in roi_names:\n        # Find file (handle potential suffixes like .nii or .nii.gz)\n        fpaths = glob.glob(os.path.join(roi_dir, f\"*{name}*.nii*\"))\n        if not fpaths:\n            print(f\"  ! Error: Mask for '{name}' not found in {roi_dir}\")\n            return None\n        \n        mask_img = nib.load(fpaths[0])\n        mask_data = mask_img.get_fdata() > 0 # Boolean mask\n        n_voxels = np.sum(mask_data)\n        \n        # Check if we have enough data left\n        if current_idx + n_voxels > len(flat_data):\n            print(f\"  ! Error: Data mismatch. Feature vector too short for ROI {name}.\")\n            return None\n            \n        # Extract chunk and paint\n        roi_values = flat_data[current_idx : current_idx + n_voxels]\n        final_vol[mask_data] = roi_values # Place values in 3D space\n        \n        current_idx += n_voxels\n        \n    # Check if data was fully consumed\n    if current_idx != len(flat_data):\n         print(f\"  ! Warning: {len(flat_data) - current_idx} features were unused (Feature vector longer than ROIs).\")\n\n    return nib.Nifti1Image(final_vol, affine)\n\n# =============================================================================\n# 2. Analysis Helper Functions (Haufe)\n# =============================================================================\ndef compute_haufe_binary_robust(model, X):\n    scores = model.decision_function(X)\n    return np.dot((X - np.mean(X, axis=0)).T, scores - np.mean(scores)) / (X.shape[0] - 1)\n\ndef get_robust_weights(X, y, subjects, pipeline, n_boot=10):\n    unique_subs = np.unique(subjects)\n    accumulated_weights = np.zeros(X.shape[1])\n    for i in range(n_boot):\n        boot_subs = resample(unique_subs, replace=True, random_state=i)\n        X_boot_list, y_boot_list = [], []\n        for sub in boot_subs:\n            mask = (subjects == sub)\n            X_sub = X[mask]\n            X_boot_list.append(X_sub - np.mean(X_sub, axis=0))\n            y_boot_list.append(y[mask])\n        X_boot = np.vstack(X_boot_list)\n        y_boot = np.hstack(y_boot_list)\n        \n        clf = clone(pipeline)\n        clf.fit(X_boot, y_boot)\n        accumulated_weights += compute_haufe_binary_robust(clf, X_boot)\n    return accumulated_weights / n_boot\n\ndef run_wen_paper_analysis_voxelwise(X, y, subjects, pipeline_template, best_C, n_permutations):\n    print(f\"  Estimating Weights ({n_permutations} perms)...\")\n    pipe = clone(pipeline_template); pipe.set_params(classification__C=best_C)\n    obs_weights = get_robust_weights(X, y, subjects, pipe, n_boot=10)\n    \n    def run_null(i):\n        y_shuff = shuffle(y, random_state=i)\n        return get_robust_weights(X, y_shuff, subjects, pipe, n_boot=1)\n\n    null_weights_list = Parallel(n_jobs=N_JOBS, verbose=1)(delayed(run_null)(i) for i in range(n_permutations))\n    null_weights = np.array(null_weights_list)\n    \n    null_mean = np.mean(null_weights, axis=0)\n    null_std = np.std(null_weights, axis=0)\n    z_scores = (obs_weights - null_mean) / (null_std + 1e-12)\n    \n    n_extreme = np.sum(np.abs(null_weights) >= np.abs(obs_weights), axis=0)\n    p_values = (n_extreme + 1) / (n_permutations + 1)\n    reject, _, _, _ = multipletests(p_values, alpha=fdr_alpha, method='fdr_bh')\n    \n    return z_scores, reject\n\n# =============================================================================\n# 3. Execution\n# =============================================================================\ngroups = {\n    'SAD': {'X': X_sad, 'y': y_sad, 'sub': sub_sad, 'res': res_sad}, \n    'HC':  {'X': X_hc,  'y': y_hc,  'sub': sub_hc,  'res': res_hc}\n}\ntarget_pair = ['CSR', 'CSS']\nsns.set_context(\"poster\")\n\nspatial_results = {}\n\nfor name, data in groups.items():\n    print(f\"\\nAnalyzing {name}...\")\n    mask_cls = np.isin(data['y'], target_pair)\n    X_curr = data['X'][mask_cls]\n    y_curr = data['y'][mask_cls]\n    sub_curr = data['sub'][mask_cls]\n    \n    # Run Analysis\n    z_scores, sig_mask = run_wen_paper_analysis_voxelwise(\n        X_curr, y_curr, sub_curr, build_binary_pipeline(), data['res']['best_C'], N_PERMUTATION\n    )\n    \n    # Direction correction (Ensure CSR is positive)\n    dummy_pipe = build_binary_pipeline(); dummy_pipe.fit(X_curr, y_curr)\n    if dummy_pipe.classes_[0] == 'CSR': z_scores = -z_scores\n    \n    spatial_results[f\"{name} Placebo\"] = {'z_scores': z_scores, 'sig_mask': sig_mask}\n    \n    n_sig = np.sum(sig_mask)\n    print(f\"Significant Voxels: {n_sig} ({(n_sig/len(z_scores))*100:.2f}%)\")\n    \n    # VISUALIZATION (Reconstruct Map)\n    if n_sig > 0:\n        try:\n            # Mask Z-scores\n            z_masked = z_scores * sig_mask\n            \n            # Reconstruct 3D Nifti from 1D array using ROI list\n            print(\"  > Reconstructing 3D map from ROI masks...\")\n            z_img = reconstruct_roi_map(z_masked, ROI_ORDER, ROI_DIR)\n            \n            if z_img is not None:\n                fig = plt.figure(figsize=(16, 6))\n                plotting.plot_glass_brain(\n                    z_img, \n                    threshold=1.96, \n                    plot_abs=False, \n                    display_mode='lyrz', \n                    colorbar=True, \n                    vmin=-5, vmax=5, \n                    cmap='RdBu_r', \n                    title=f\"{name}: FDR < {fdr_alpha}\", \n                    figure=fig\n                )\n                plt.show()\n                \n        except Exception as e:\n            print(f\"  ! Visualization failed: {e}\")\n            import traceback\n            traceback.print_exc()\n\nprint(\"--- Cell 7 Complete (Spatial Results Stored) ---\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 8: Feature Importance (Permutation) & Mask Generation\n# Objective: Identify task-relevant voxels/regions using Permutation Importance.\n# Context: Used as the primary feature selector for downstream analysis (Cell 9 & 10).\n\nprint(\"--- Cell 8: Generating Permutation Importance Masks ---\")\n# =============================================================================\n# 0. Setup & Dependency Checks\n# =============================================================================\n# 1. Check for Results (Models) from Cell 6\nif 'res_sad' not in locals() or 'res_hc' not in locals():\n    raise ValueError(\"Models ('res_sad', 'res_hc') not found. Please run Cell 6 first.\")\n\n# 2. Check for Data (Global or Nested)\n# We ensure X_sad/X_hc are available, reloading from data_subsets if necessary.\nif 'X_sad' not in locals():\n    print(\"  > Reloading extinction data from 'data_subsets'...\")\n    try:\n        X_sad = data_subsets[\"SAD_Placebo\"][\"ext\"][\"X\"]\n        y_sad = data_subsets[\"SAD_Placebo\"][\"ext\"][\"y\"]\n        sub_sad = data_subsets[\"SAD_Placebo\"][\"ext\"][\"sub\"]\n        \n        X_hc = data_subsets[\"HC_Placebo\"][\"ext\"][\"X\"]\n        y_hc = data_subsets[\"HC_Placebo\"][\"ext\"][\"y\"]\n        sub_hc = data_subsets[\"HC_Placebo\"][\"ext\"][\"sub\"]\n    except (KeyError, TypeError):\n        raise ValueError(\"Data missing. Please run Cell 5 (Data Prep).\")\n\n# 3. Check for ROI Labels\nif 'parcel_names_ext' not in locals():\n    print(\"  ! WARNING: 'parcel_names_ext' not found. Using generic feature indices for plotting.\")\n    parcel_names_ext = [f\"Feat_{i}\" for i in range(X_sad.shape[1])]\n\n# Settings\ntarget_pair = ['CSR', 'CSS']\nn_repeats = 100 # Number of permutation iterations for importance\nimportance_masks = {}\nimportance_scores = {}\n\n# =============================================================================\n# 1. Compute Importance for SAD\n# =============================================================================\nprint(\"1. Computing Importance for SAD Placebo...\")\n\n# Slice Data (CSR vs CSS only)\nmask_sad = np.isin(y_sad, target_pair)\nX_sad_p = X_sad[mask_sad]\ny_sad_p = y_sad[mask_sad]\nsub_sad_p = sub_sad[mask_sad]\n\n# Compute Importance (CV-based)\nimp_sad_mean = compute_perm_importance_cv(\n    res_sad['model'], X_sad_p, y_sad_p, sub_sad_p,\n    n_repeats=n_repeats, n_splits=SUBJECT_CV_SPLITS\n)\n\n# Define Mask: Top 5% most important voxels\nPERCENTILE_THRESH = 95\nthr_sad = np.percentile(imp_sad_mean, PERCENTILE_THRESH)\nmask_sad_sig = imp_sad_mean >= thr_sad\nimportance_masks['SAD'] = mask_sad_sig\nimportance_scores['SAD'] = imp_sad_mean\n\nprint(f\"   > SAD: Found {np.sum(mask_sad_sig)} predictive voxels (Top 5%, thr={thr_sad:.6f}).\")\n\n# =============================================================================\n# 2. Compute Importance for HC\n# =============================================================================\nprint(\"2. Computing Importance for HC Placebo...\")\n\n# Slice Data\nmask_hc = np.isin(y_hc, target_pair)\nX_hc_p = X_hc[mask_hc]\ny_hc_p = y_hc[mask_hc]\nsub_hc_p = sub_hc[mask_hc]\n\n# Compute Importance (CV-based)\nimp_hc_mean = compute_perm_importance_cv(\n    res_hc['model'], X_hc_p, y_hc_p, sub_hc_p,\n    n_repeats=n_repeats, n_splits=SUBJECT_CV_SPLITS\n)\n\n# Define Mask: Top 5% most important voxels\nthr_hc = np.percentile(imp_hc_mean, PERCENTILE_THRESH)\nmask_hc_sig = imp_hc_mean >= thr_hc\nimportance_masks['HC'] = mask_hc_sig\nimportance_scores['HC'] = imp_hc_mean\n\nprint(f\"   > HC:  Found {np.sum(mask_hc_sig)} predictive voxels (Top 5%, thr={thr_hc:.6f}).\")\n\n# =============================================================================\n# 3. Visualization (River Plot)\n# =============================================================================\nprint(\"3. Generating River Plot...\")\n\n# Prepare dictionary for plotting function\nplot_data = {\n    'SAD Placebo': imp_sad_mean,\n    'HC Placebo': imp_hc_mean\n}\n\n# Use the helper function from Cell 4\n# Assumes make_river_plot_importance handles the figure creation\ntry:\n    make_river_plot_importance(\n        plot_data,\n        parcel_names_ext,\n        top_k=20,  # Show top 20 most important features per group\n        title=\"Neural Signatures (Permutation Importance)\"\n    )\nexcept Exception as e:\n    print(f\"  ! Visualization skipped due to error: {e}\")\n\nprint(\"Cell 8: Importance masks generated and stored in 'importance_masks'.\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 9: Analysis 1.2 - Static Representational Topology (Top 5% | Centroid)\n# Objective: Characterize the stable organization of the social learning space.\n# Constraint: Top 5% most predictive features per group.\n# Method: Cross-validated Mahalanobis (crossnobis) distance with shrinkage covariance, averaged over split-half repeats.\n# Tests: Group Comparison (SAD vs HC) AND One-Sample Test (Dist > 0).\n\nprint(\"--- Running Analysis 1.2: Static Representational Topology (Top 5% | Centroid) ---\")\n\nfrom scipy.stats import ttest_1samp\n\n# Global Constants\nRDM_CONDITIONS = [\"CS-\", \"CSS\", \"CSR\"] \nPERCENTILE_THRESH = TOP_PCT  # Top 5%\n\n# =============================================================================\n# 0. Feature Selection (Top 5%)\n# =============================================================================\nprint(f\"\\n[Step 0] Selecting Top {100-PERCENTILE_THRESH}% Neural Features...\")\n\nif 'importance_scores' not in locals() or not importance_scores:\n    raise ValueError(\"Importance scores not found! Please run Cell 8 first.\")\n\ndef get_top_percentile_mask(scores, percentile):\n    thresh = np.percentile(scores, percentile)\n    mask = scores >= thresh\n    mask = mask & (scores > 0) # Ensure positive contribution\n    return mask, thresh\n\nscores_sad = importance_scores['SAD']\nmask_sad_top5, thresh_sad = get_top_percentile_mask(scores_sad, PERCENTILE_THRESH)\n\nscores_hc = importance_scores['HC']\nmask_hc_top5, thresh_hc = get_top_percentile_mask(scores_hc, PERCENTILE_THRESH)\n\nprint(f\"  > SAD Top 5% Network: {np.sum(mask_sad_top5)} voxels (Threshold: {thresh_sad:.5f})\")\nprint(f\"  > HC Top 5% Network:  {np.sum(mask_hc_top5)} voxels (Threshold: {thresh_hc:.5f})\")\n\n# =============================================================================\n# 1. Data Preparation (Recovering CS-)\n# =============================================================================\nprint(\"\\n[Step 1] Preparing Centroid Data...\")\n\n# Validate Source Data\nif 'X_ext' not in locals() or 'y_ext' not in locals():\n    raise ValueError(\"Global 'X_ext' variables missing. Cannot retrieve CS- trials (Cell 5 filtered them out).\")\n\n# Retrieve Subject Lists from the Nested Dictionary (created in Cell 5)\n# structure: data_subsets['Group']['ext']['sub']\ntry:\n    known_hc = np.unique(data_subsets[\"HC_Placebo\"][\"ext\"][\"sub\"])\n    known_sad = np.unique(data_subsets[\"SAD_Placebo\"][\"ext\"][\"sub\"])\nexcept (KeyError, TypeError):\n    raise ValueError(\"Data structure mismatch. Ensure Cell 5 generated 'data_subsets' with ['ext'] keys.\")\n\n# Create a temporary group mapping array matching the global X_ext\ngroup_ext = np.array([\"Unknown\"] * len(sub_ext), dtype=object)\ngroup_ext[np.isin(sub_ext, known_hc)] = \"HC\"\ngroup_ext[np.isin(sub_ext, known_sad)] = \"SAD\"\n\n# Filter Global Data for RDM Conditions\nmask_conds = np.isin(y_ext, RDM_CONDITIONS)\nX_raw = X_ext[mask_conds]\ny_raw = y_ext[mask_conds]\nsub_raw = sub_ext[mask_conds]\ngrp_raw = group_ext[mask_conds]\n\n# Split by Group\nmask_sad_grp = (grp_raw == \"SAD\")\nmask_hc_grp = (grp_raw == \"HC\")\n\n# Slice Features (Apply the Top 5% Masks)\nX_sad_12 = X_raw[mask_sad_grp][:, mask_sad_top5]\ny_sad_12 = y_raw[mask_sad_grp]\nsub_sad_12 = sub_raw[mask_sad_grp]\n\nX_hc_12 = X_raw[mask_hc_grp][:, mask_hc_top5]\ny_hc_12 = y_raw[mask_hc_grp]\nsub_hc_12 = sub_raw[mask_hc_grp]\n\nprint(f\"  > SAD Matrix (Top 5%): {X_sad_12.shape} | HC Matrix (Top 5%): {X_hc_12.shape}\")\n\n# =============================================================================\n# 2. Centroid RDM Calculation\n# =============================================================================\ndef calculate_crossnobis_rdm(X, y, subjects, conditions, n_repeats=CROSSNOBIS_REPEATS, random_state=RANDOM_STATE):\n    \"\"\"Crossnobis RDM per subject with Ledoit-Wolf shrinkage, averaged over repeats.\"\"\"\n    unique_subs = np.unique(subjects); rdms = []; sub_ids = []\n    rng = np.random.default_rng(random_state)\n\n    for sub in unique_subs:\n        mask_sub = (subjects == sub)\n        X_sub = X[mask_sub]\n        y_sub = y[mask_sub]\n\n        rdm_accum = None\n        valid_reps = 0\n\n        for rep in range(n_repeats):\n            # Build split-half means per condition\n            means_a = {}\n            means_b = {}\n            ok = True\n            for cond in conditions:\n                idx = np.where(y_sub == cond)[0]\n                if len(idx) < 2:\n                    ok = False\n                    break\n                idx = idx.copy()\n                rng.shuffle(idx)\n                half = len(idx) // 2\n                idx_a = idx[:half]\n                idx_b = idx[half:]\n                if len(idx_a) == 0 or len(idx_b) == 0:\n                    ok = False\n                    break\n                means_a[cond] = np.mean(X_sub[idx_a], axis=0)\n                means_b[cond] = np.mean(X_sub[idx_b], axis=0)\n            if not ok:\n                continue\n\n            # Estimate noise covariance from residuals (all trials, condition-demeaned)\n            resid = []\n            for cond in conditions:\n                idx = np.where(y_sub == cond)[0]\n                cond_mean = np.mean(X_sub[idx], axis=0)\n                resid.append(X_sub[idx] - cond_mean)\n            resid = np.vstack(resid)\n            cov = LedoitWolf().fit(resid).covariance_\n            prec = np.linalg.pinv(cov)\n\n            # Crossnobis distance matrix\n            n = len(conditions)\n            rdm = np.zeros((n, n))\n            for i in range(n):\n                for j in range(i + 1, n):\n                    c_i = conditions[i]; c_j = conditions[j]\n                    d_a = means_a[c_i] - means_a[c_j]\n                    d_b = means_b[c_i] - means_b[c_j]\n                    dist = float(d_a.T @ prec @ d_b)\n                    rdm[i, j] = dist\n                    rdm[j, i] = dist\n\n            if rdm_accum is None:\n                rdm_accum = rdm\n            else:\n                rdm_accum += rdm\n            valid_reps += 1\n\n        if valid_reps == 0:\n            continue\n        rdm_mean = rdm_accum / valid_reps\n        rdms.append(rdm_mean)\n        sub_ids.append(sub)\n\n    return np.array(rdms), np.array(sub_ids)\n\n# Compute RDMs\nprint(f\"  Calculating Centroid RDMs (Conditions: {RDM_CONDITIONS}) with {CROSSNOBIS_REPEATS} split-half repeats...\")\nrdms_sad, subs_sad_rdm = calculate_crossnobis_rdm(X_sad_12, y_sad_12, sub_sad_12, RDM_CONDITIONS)\nrdms_hc, subs_hc_rdm = calculate_crossnobis_rdm(X_hc_12, y_hc_12, sub_hc_12, RDM_CONDITIONS)\n\nprint(f\"  > Computed RDMs: SAD (n={len(subs_sad_rdm)}), HC (n={len(subs_hc_rdm)})\")\n\n# =============================================================================\n# 3. Metrics & Statistical Tests\n# =============================================================================\n# Conditions: 0=CS-, 1=CSS, 2=CSR\nidx_cs_minus, idx_css, idx_csr = 0, 1, 2\n\ndef extract_metrics(rdms):\n    # Metric A: Threat (CSR) vs Safety (CSS)\n    m_a = rdms[:, idx_csr, idx_css] \n    # Metric B: Safety (CSS) vs Baseline (CS-)\n    m_b = rdms[:, idx_css, idx_cs_minus] \n    return m_a, m_b\n\nvec_a_sad, vec_b_sad = extract_metrics(rdms_sad)\nvec_a_hc, vec_b_hc = extract_metrics(rdms_hc)\n\nprint(\"\\n[Step 3] Statistical Testing...\")\n\n# --- Helper for One-Sample Test (Significantly > 0?) ---\ndef one_sample_test(data, name):\n    # Test if distance is greater than 0\n    t_val, p_val = ttest_1samp(data, 0, alternative='greater')\n    sig = \"*\" if p_val < 0.05 else \"ns\"\n    print(f\"  > {name}: Mean={np.mean(data):.3f}, t={t_val:.3f}, p={p_val:.4f} ({sig})\")\n    return p_val\n\n# Metric A: Threat Distance (The Canyon)\nprint(\"\\nMetric A: Threat (CSR) vs Safety (CSS) Distance\")\np_a_sad_0 = one_sample_test(vec_a_sad, \"SAD (Dist > 0)\")\np_a_hc_0 = one_sample_test(vec_a_hc, \"HC  (Dist > 0)\")\n\nprint(\"  > Group Comparison (SAD vs HC):\")\nt_a, p_a, m_a_sad, m_a_hc = perm_ttest_ind(vec_a_sad, vec_a_hc, n_perm=N_PERMUTATION)\nprint(f\"    Diff: SAD={m_a_sad:.3f}, HC={m_a_hc:.3f} | t={t_a:.3f}, p={p_a:.4f}\")\n\n# Metric B: Safety Distance (The Collapse)\nprint(\"\\nMetric B: Safety (CSS) vs Background (CS-) Distance\")\np_b_sad_0 = one_sample_test(vec_b_sad, \"SAD (Dist > 0)\")\np_b_hc_0 = one_sample_test(vec_b_hc, \"HC  (Dist > 0)\")\n\nprint(\"  > Group Comparison (SAD vs HC):\")\nt_b, p_b, m_b_sad, m_b_hc = perm_ttest_ind(vec_b_sad, vec_b_hc, n_perm=N_PERMUTATION)\nprint(f\"    Diff: SAD={m_b_sad:.3f}, HC={m_b_hc:.3f} | t={t_b:.3f}, p={p_b:.4f}\")\n\n# =============================================================================\n# 4. Visualization\n# =============================================================================\nsns.set_context(\"poster\")\nfig = plt.figure(figsize=(24, 8))\ngs = fig.add_gridspec(1, 3)\n\n# Heatmaps\nax1 = fig.add_subplot(gs[0, 0])\nsns.heatmap(np.mean(rdms_sad, axis=0), annot=True, fmt=\".2f\", cmap=\"viridis\", vmin=0, vmax=1.2, \n            xticklabels=RDM_CONDITIONS, yticklabels=RDM_CONDITIONS, ax=ax1, cbar=False)\nax1.set_title(f\"SAD Topology (Top 5%)\\n(n={len(subs_sad_rdm)})\")\n\nax2 = fig.add_subplot(gs[0, 1])\nsns.heatmap(np.mean(rdms_hc, axis=0), annot=True, fmt=\".2f\", cmap=\"viridis\", vmin=0, vmax=1.2,\n            xticklabels=RDM_CONDITIONS, yticklabels=RDM_CONDITIONS, ax=ax2)\nax2.set_title(f\"HC Topology (Top 5%)\\n(n={len(subs_hc_rdm)})\")\n\n# Violins\nax3 = fig.add_subplot(gs[0, 2])\ndf_res = pd.DataFrame({\n    'Group': ['SAD']*len(vec_a_sad) + ['HC']*len(vec_a_hc) + ['SAD']*len(vec_b_sad) + ['HC']*len(vec_b_hc),\n    'Distance': np.concatenate([vec_a_sad, vec_a_hc, vec_b_sad, vec_b_hc]),\n    'Metric': ['A: Threat Dist']*len(vec_a_sad) + ['A: Threat Dist']*len(vec_a_hc) + \n              ['B: Safety Dist']*len(vec_b_sad) + ['B: Safety Dist']*len(vec_b_hc)\n})\nsns.violinplot(data=df_res, x='Metric', y='Distance', hue='Group', \n               split=True, inner='quartile', palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=ax3)\nax3.set_title(\"Topological Metrics (Centroid)\")\nax3.set_ylabel(\"Crossnobis Distance\")\n\n# Annotate Group Differences\ny_max = df_res['Distance'].max()\nif p_a < 0.05: ax3.text(0, y_max + 0.05, f'* (p={p_a:.3f})', ha='center', fontsize=18)\nif p_b < 0.05: ax3.text(1, y_max + 0.05, f'* (p={p_b:.3f})', ha='center', fontsize=18)\n\n# Annotate Sig > 0 (Below X Axis)\ndef get_sig_star(p): return \"*\" if p < 0.05 else \"ns\"\n\n# For Metric A\nax3.text(-0.2, -0.15, f\"SAD: {get_sig_star(p_a_sad_0)}\", transform=ax3.get_xaxis_transform(), ha='center', fontsize=14, color='#c44e52')\nax3.text(0.2, -0.15, f\"HC: {get_sig_star(p_a_hc_0)}\", transform=ax3.get_xaxis_transform(), ha='center', fontsize=14, color='#4c72b0')\n\n# For Metric B\nax3.text(0.8, -0.15, f\"SAD: {get_sig_star(p_b_sad_0)}\", transform=ax3.get_xaxis_transform(), ha='center', fontsize=14, color='#c44e52')\nax3.text(1.2, -0.15, f\"HC: {get_sig_star(p_b_hc_0)}\", transform=ax3.get_xaxis_transform(), ha='center', fontsize=14, color='#4c72b0')\n\nplt.tight_layout()\nplt.show()\n\n# Store Results\nresults_12 = {\n    \"rdms_sad\": rdms_sad, \"rdms_hc\": rdms_hc, \n    \"metric_a_stats\": (t_a, p_a), \"metric_b_stats\": (t_b, p_b),\n    \"features_sad\": np.sum(mask_sad_top5), \"features_hc\": np.sum(mask_hc_top5),\n    \"one_sample_stats\": {\"p_a_sad\": p_a_sad_0, \"p_a_hc\": p_a_hc_0, \"p_b_sad\": p_b_sad_0, \"p_b_hc\": p_b_hc_0}\n}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 10: Analysis 1.3 - Dynamic Representational Drift (Top 5% Features)\n# Objective: Quantify plasticity magnitude (Projection) and fidelity (Cosine).\n# Target Definitions:\n#   - Safety:  Extinction CSS -> Extinction CS-\n#   - Threat:  Extinction CSR -> Reinstatement CSR\n# Feature Selection: Top 5% Importance (Permutation Scores)\n\nprint(\"--- Running Analysis 1.3: Dynamic Representational Drift (Top 5% Features) ---\")\n\nimport pandas as pd\nimport statsmodels.api as sm\nfrom numpy.linalg import norm\nfrom scipy.stats import ttest_1samp, ttest_ind, levene, shapiro, mannwhitneyu\n\n# Constants\nCOND_SAFETY_TARGET = \"CS-\"\nCOND_SAFETY_LEARN = \"CSS\"\nCOND_THREAT_LEARN = \"CSR\"\n\n# =============================================================================\n# 0. Feature Selection & Data Loading\n# =============================================================================\nprint(f\"\\n[Step 0] Setup & Data Loading...\")\n\nif 'importance_scores' not in locals(): \n    raise ValueError(\"Run Cell 8 first.\")\n\n# 1. Select Top 5% Features\ndef get_top_percentile_mask(scores, percentile):\n    thresh = np.percentile(scores, percentile)\n    mask = (scores >= thresh) & (scores > 0) # Ensure strictly positive & top tier\n    return mask, thresh\n\nmask_sad, t_sad = get_top_percentile_mask(importance_scores['SAD'], PERCENTILE_THRESH)\nmask_hc, t_hc = get_top_percentile_mask(importance_scores['HC'], PERCENTILE_THRESH)\n\nprint(f\"  > SAD Top 5% Network: {np.sum(mask_sad)} voxels (Thresh={t_sad:.4f})\")\nprint(f\"  > HC Top 5% Network:  {np.sum(mask_hc)} voxels (Thresh={t_hc:.4f})\")\n\n# 2. Load Data Helpers (Nested Dictionary Access)\ndef get_phase_data(group, phase):\n    try:\n        d = data_subsets[group][phase]\n        if d is None: return None, None, None\n        return d[\"X\"], d[\"y\"], d[\"sub\"]\n    except KeyError:\n        return None, None, None\n\n# Load Extinction (Start/Learning Phase)\nX_ext_sad, y_ext_sad, sub_ext_sad = get_phase_data(\"SAD_Placebo\", \"ext\")\nX_ext_hc, y_ext_hc, sub_ext_hc = get_phase_data(\"HC_Placebo\", \"ext\")\n\n# Load Reinstatement (Target Phase for Threat)\nX_rst_sad, y_rst_sad, sub_rst_sad = get_phase_data(\"SAD_Placebo\", \"rst\")\nX_rst_hc, y_rst_hc, sub_rst_hc = get_phase_data(\"HC_Placebo\", \"rst\")\n\n# Validate Reinstatement Data\nif X_rst_sad is None or X_rst_hc is None:\n    print(\"  ! WARNING: Reinstatement data missing. Threat analysis will fallback to Extinction (Trivial).\")\n    X_rst_sad, y_rst_sad, sub_rst_sad = X_ext_sad, y_ext_sad, sub_ext_sad\n    X_rst_hc, y_rst_hc, sub_rst_hc = X_ext_hc, y_ext_hc, sub_ext_hc\n\n# Handle CS- (Safety Target) - likely missing from subsets, need global X_ext\nif 'X_ext' in locals():\n    X_global, y_global, sub_global = X_ext, y_ext, sub_ext\nelse:\n    print(\"  ! WARNING: Global X_ext missing. Safety Target (CS-) might be unavailable.\")\n    X_global, y_global, sub_global = X_ext_sad, y_ext_sad, sub_ext_sad\n\n# =============================================================================\n# 1. Vector Calculation Helper (Cross-Phase Support)\n# =============================================================================\ndef calculate_plasticity_vectors(\n    X_learn, y_learn, sub_learn,   # Data for Learning Trajectory (Start -> End)\n    X_targ, y_targ, sub_targ,      # Data for Target Definition\n    feature_mask, \n    cond_learn,                    # Condition changing (e.g., CSS or CSR)\n    cond_target_label              # Label of the target (e.g., CS- or CSR)\n):\n    \"\"\"\n    Calculates projection of learning (in X_learn) onto axis towards Target (in X_targ).\n    \"\"\"\n    # 1. Apply Feature Mask & Centering\n    # Note: Center phases separately to remove global session shifts (drift correction)\n    \n    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n    res = {'sub': [], 'projection': [], 'cosine': [], 'init_dist': []}\n    \n    for sub in unique_subs:\n        # Slice Learning Data (The Drift)\n        m_l = (sub_learn == sub); xl = X_learn[m_l]; yl = y_learn[m_l]\n        \n        # Slice Target Data (The Goal)\n        m_t = (sub_targ == sub); xt = X_targ[m_t]; yt = y_targ[m_t]\n        \n        # A. Define Target Centroid (P_target)\n        mask_tgt_cond = (yt == cond_target_label)\n        if np.sum(mask_tgt_cond) == 0: continue\n        P_target = np.mean(xt[mask_tgt_cond], axis=0)\n        \n        # B. Define Start & End (Learning Phase)\n        mask_lrn_cond = (yl == cond_learn)\n        idx_lrn = np.where(mask_lrn_cond)[0]\n        if len(idx_lrn) < 2: continue\n        \n        cutoff = len(idx_lrn) // 2\n        # Early Learning\n        P_start = np.mean(xl[idx_lrn[:cutoff]], axis=0)\n        # Late Learning\n        P_end = np.mean(xl[idx_lrn[cutoff:]], axis=0)\n        \n        # C. Define Vectors\n        # Axis: From Start (Ext) -> Target (Reinstatement or CS-)\n        V_axis = P_target - P_start\n        # Drift: Actual change during learning\n        V_drift = P_end - P_start\n        \n        norm_axis = norm(V_axis)\n        norm_drift = norm(V_drift)\n        \n        if norm_axis == 0 or norm_drift == 0: continue\n        \n        dot_prod = np.dot(V_drift, V_axis)\n        \n        # Scalar Projection (Magnitude)\n        projection = dot_prod / norm_axis\n        \n        # Cosine Similarity (Fidelity)\n        cosine = dot_prod / (norm_drift * norm_axis)\n        \n        res['sub'].append(sub)\n        res['projection'].append(projection)\n        res['cosine'].append(cosine)\n        res['init_dist'].append(norm_axis)\n        \n    return pd.DataFrame(res)\n\n# =============================================================================\n# 2. Execution\n# =============================================================================\nprint(\"\\n[Step 2] Calculating Vectors...\")\n\n# A. Safety Learning (CSS -> CS-)\n# Both Start and Target are in Extinction (or Global)\nprint(\"  > Safety Analysis: Start=CSS(Ext) -> Target=CS-(Ext)\")\ndf_safe_sad = calculate_plasticity_vectors(\n    X_ext_sad, y_ext_sad, sub_ext_sad,     # Learn: Extinction\n    X_global, y_global, sub_global,        # Target: Global (contains CS-)\n    mask_sad, COND_SAFETY_LEARN, COND_SAFETY_TARGET\n)\ndf_safe_hc = calculate_plasticity_vectors(\n    X_ext_hc, y_ext_hc, sub_ext_hc, \n    X_global, y_global, sub_global, \n    mask_hc, COND_SAFETY_LEARN, COND_SAFETY_TARGET\n)\n\n# B. Threat Maintenance (CSR -> Reinstatement CSR)\n# Start is Extinction, Target is REINSTATEMENT\nprint(\"  > Threat Analysis: Start=CSR(Ext) -> Target=CSR(Reinstatement)\")\ndf_threat_sad = calculate_plasticity_vectors(\n    X_ext_sad, y_ext_sad, sub_ext_sad,     # Learn: Extinction\n    X_rst_sad, y_rst_sad, sub_rst_sad,     # Target: Reinstatement\n    mask_sad, COND_THREAT_LEARN, COND_THREAT_LEARN \n)\ndf_threat_hc = calculate_plasticity_vectors(\n    X_ext_hc, y_ext_hc, sub_ext_hc, \n    X_rst_hc, y_rst_hc, sub_rst_hc, \n    mask_hc, COND_THREAT_LEARN, COND_THREAT_LEARN\n)\n\n# =============================================================================\n# 3. Statistics & Visualization\n# =============================================================================\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Combine for plotting\ndef tag_df(df, grp, cond):\n    if df.empty: return df\n    d = df.copy(); d['Group'] = grp; d['Condition'] = cond\n    return d\n\ndf_plot = pd.concat([\n    tag_df(df_safe_sad, 'SAD', 'Safety'), tag_df(df_safe_hc, 'HC', 'Safety'),\n    tag_df(df_threat_sad, 'SAD', 'Threat'), tag_df(df_threat_hc, 'HC', 'Threat')\n])\n\nif df_plot.empty:\n    print(\"! No data generated. Check inputs.\")\nelse:\n    print(f\"\\n[Step 3] Generated {len(df_plot)} subject vectors.\")\n    \n    sns.set_context(\"poster\")\n    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n    \n    # 1. Projection (Magnitude)\n    sns.barplot(data=df_plot, x='Condition', y='projection', hue='Group', \n                palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=axes[0,0], \n                capsize=.1, errorbar='se')\n    axes[0,0].axhline(0, color='k', ls='--')\n    axes[0,0].set_title(\"Magnitude (Scalar Projection)\")\n    \n    # 2. Cosine (Fidelity)\n    sns.barplot(data=df_plot, x='Condition', y='cosine', hue='Group', \n                palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=axes[0,1], \n                capsize=.1, errorbar='se')\n    axes[0,1].axhline(0, color='k', ls='--')\n    axes[0,1].set_title(\"Directional Fidelity (Cosine)\")\n    \n    # 3. Stats (Printout)\n    print(\"\\n--- Statistical Summary (SAD vs HC) ---\")\n    for cond in ['Safety', 'Threat']:\n        print(f\"\\nCondition: {cond}\")\n        for met in ['projection', 'cosine']:\n            d_s = df_plot[(df_plot['Condition']==cond) & (df_plot['Group']=='SAD')][met]\n            d_h = df_plot[(df_plot['Condition']==cond) & (df_plot['Group']=='HC')][met]\n            \n            # One-sample t-test (vs 0)\n            if len(d_s)>1: \n                t0_s, p0_s = ttest_1samp(d_s, 0, alternative='greater')\n                print(f\"  > SAD > 0 ({met}): t={t0_s:.3f}, p={p0_s:.4f}\")\n            if len(d_h)>1:\n                t0_h, p0_h = ttest_1samp(d_h, 0, alternative='greater')\n                print(f\"  > HC  > 0 ({met}): t={t0_h:.3f}, p={p0_h:.4f}\")\n\n            # Group Diff\n            if len(d_s)>1 and len(d_h)>1:\n                t, p = ttest_ind(d_s, d_h)\n                sig = \"*\" if p < 0.05 else \"ns\"\n                print(f\"  > Group Diff ({met}): t={t:.3f}, p={p:.4f} {sig}\")\n\n    # 4. Scatter (Init Dist vs Projection)\n    sns.scatterplot(data=df_plot, x='init_dist', y='projection', hue='Group', style='Condition', \n                    palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, alpha=0.7, ax=axes[1,0], s=100)\n    axes[1,0].axhline(0, color='k', ls='--')\n    axes[1,0].set_title(\"Learning vs Initial Distance\")\n    \n    axes[1,1].axis('off') # Empty slot\n    plt.tight_layout()\n    plt.show()\n\nresults_13 = {'safe_sad': df_safe_sad, 'threat_sad': df_threat_sad}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 10: Analysis 1.3 - Dynamic Representational Drift (Single-Trial Trajectories)\n# Objective: Visualize plasticity trial-by-trial using Top 5% Features.\n# Method: Project every trial onto the Ideal Axis (Start -> Target).\n#   - Score 0 = Resembles Early Extinction (Start)\n#   - Score 1 = Resembles Target (CS- or Reinstated CSR)\n\nprint(\"--- Running Analysis 1.3: Single-Trial Trajectories (Top 5%) ---\")\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom numpy.linalg import norm\n\n# Constants\nCOND_SAFETY_TARGET = \"CS-\"\nCOND_SAFETY_LEARN = \"CSS\"\nCOND_THREAT_LEARN = \"CSR\"\nBLOCK_SIZE = 1  # Group trials for smoother plotting (1 = Raw Single Trial)\n\n# =============================================================================\n# 0. Feature Selection (Top 5% Positive)\n# =============================================================================\nprint(f\"\\n[Step 0] Selecting Top {100-PERCENTILE_THRESH}% Features...\")\n\nif 'importance_scores' not in locals(): \n    raise ValueError(\"Run Cell 8 first.\")\n\n# --- FIXED FUNCTION ---\ndef get_top_percentile_mask(scores, percentile):\n    thresh = np.percentile(scores, percentile)\n    mask = (scores >= thresh) & (scores > 0)\n    return mask, thresh  # Now returns TWO values\n\nmask_sad, t_sad = get_top_percentile_mask(importance_scores['SAD'], PERCENTILE_THRESH)\nmask_hc, t_hc = get_top_percentile_mask(importance_scores['HC'], PERCENTILE_THRESH)\n\nprint(f\"  > SAD Top 5%: {np.sum(mask_sad)} voxels (Thresh: {t_sad:.4f})\")\nprint(f\"  > HC Top 5%:  {np.sum(mask_hc)} voxels (Thresh: {t_hc:.4f})\")\n\n# =============================================================================\n# 1. Data Loading (Extinction & Reinstatement)\n# =============================================================================\ndef get_phase_data(group, phase):\n    try:\n        d = data_subsets[group][phase]\n        if d is None: return None, None, None\n        return d[\"X\"], d[\"y\"], d[\"sub\"]\n    except KeyError:\n        return None, None, None\n\n# Load Start Data (Extinction)\nX_ext_sad, y_ext_sad, sub_ext_sad = get_phase_data(\"SAD_Placebo\", \"ext\")\nX_ext_hc, y_ext_hc, sub_ext_hc = get_phase_data(\"HC_Placebo\", \"ext\")\n\n# Load Target Data (Reinstatement)\nX_rst_sad, y_rst_sad, sub_rst_sad = get_phase_data(\"SAD_Placebo\", \"rst\")\nX_rst_hc, y_rst_hc, sub_rst_hc = get_phase_data(\"HC_Placebo\", \"rst\")\n\n# Check Reinstatement Availability\nif X_rst_sad is None:\n    print(\"  ! WARNING: Reinstatement data missing. Using Extinction as placeholder.\")\n    X_rst_sad, y_rst_sad, sub_rst_sad = X_ext_sad, y_ext_sad, sub_ext_sad\n    X_rst_hc, y_rst_hc, sub_rst_hc = X_ext_hc, y_ext_hc, sub_ext_hc\n\n# Check Global Availability (for CS-)\nif 'X_ext' in locals():\n    X_glob, y_glob, sub_glob = X_ext, y_ext, sub_ext\nelse:\n    # Fallback to group data if global is missing\n    X_glob, y_glob, sub_glob = X_ext_sad, y_ext_sad, sub_ext_sad\n\n# =============================================================================\n# 2. Trajectory Calculation Helper\n# =============================================================================\ndef calc_trajectory(\n    X_learn, y_learn, sub_learn,    # The trials we want to project (the \"Movie\")\n    X_targ, y_targ, sub_targ,       # The dataset containing the Goal State\n    mask, \n    cond_learn,                     # Condition to track (e.g., CSS)\n    cond_target_label               # Label of Goal State (e.g., CS- or CSR)\n):\n    # Center Data separately to remove session effects\n    \n    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n    res = {'sub': [], 'trial': [], 'score': []}\n    \n    for sub in unique_subs:\n        # 1. Get Subject Data\n        xl = X_learn[sub_learn == sub]; yl = y_learn[sub_learn == sub]\n        xt = X_targ[sub_targ == sub]; yt = y_targ[sub_targ == sub]\n        \n        # 2. Define Start Point (Early Learning)\n        # We define \"Start\" as the centroid of the FIRST HALF of the learning trials\n        mask_l = (yl == cond_learn)\n        trials_l = xl[mask_l]\n        if len(trials_l) < 2: continue\n        \n        cutoff = max(1, len(trials_l) // 2)\n        P_start = np.mean(trials_l[:cutoff], axis=0)\n        \n        # 3. Define Target Point\n        mask_t = (yt == cond_target_label)\n        if np.sum(mask_t) == 0: continue\n        P_target = np.mean(xt[mask_t], axis=0)\n        \n        # 4. Define Axis\n        V_axis = P_target - P_start\n        sq_norm = np.dot(V_axis, V_axis)\n        if sq_norm == 0: continue\n        \n        # 5. Project Each Trial\n        # Logic: Score = ((Trial - Start) . Axis) / ||Axis||^2\n        # This normalizes the progress: 0.0 = Start, 1.0 = Target\n        \n        # We center the trials relative to the Start Point of this specific axis\n        trials_centered = trials_l - P_start\n        \n        scores = np.dot(trials_centered, V_axis) / sq_norm\n        \n        for i, s in enumerate(scores):\n            res['sub'].append(sub)\n            res['trial'].append(i + 1)\n            res['score'].append(s)\n            \n    return pd.DataFrame(res)\n\n# =============================================================================\n# 3. Execute Analysis\n# =============================================================================\nprint(\"\\n[Step 2] Calculating Single-Trial Trajectories...\")\n\n# A. Safety Learning\n# Axis: Early CSS (Ext) --> CS- Centroid (Ext/Global)\nprint(\"  > Safety: CSS Trials projecting onto [Early CSS -> CS-]\")\ndf_safe_sad = calc_trajectory(X_ext_sad, y_ext_sad, sub_ext_sad, X_glob, y_glob, sub_glob, mask_sad, COND_SAFETY_LEARN, COND_SAFETY_TARGET)\ndf_safe_hc = calc_trajectory(X_ext_hc, y_ext_hc, sub_ext_hc, X_glob, y_glob, sub_glob, mask_hc, COND_SAFETY_LEARN, COND_SAFETY_TARGET)\n\n# B. Threat Maintenance\n# Axis: Early CSR (Ext) --> Reinstated CSR Centroid (Rst)\nprint(\"  > Threat: CSR Trials projecting onto [Early CSR -> Reinstated CSR]\")\ndf_threat_sad = calc_trajectory(X_ext_sad, y_ext_sad, sub_ext_sad, X_rst_sad, y_rst_sad, sub_rst_sad, mask_sad, COND_THREAT_LEARN, COND_THREAT_LEARN)\ndf_threat_hc = calc_trajectory(X_ext_hc, y_ext_hc, sub_ext_hc, X_rst_hc, y_rst_hc, sub_rst_hc, mask_hc, COND_THREAT_LEARN, COND_THREAT_LEARN)\n\n# =============================================================================\n# Detailed Statistics\n# =============================================================================\ndef run_detailed_stats(df_sad, df_hc, label):\n    if df_sad.empty or df_hc.empty: return pd.DataFrame()\n    \n    trials = sorted(list(set(df_sad['trial'].unique()) & set(df_hc['trial'].unique())))\n    results = []\n    \n    for t in trials:\n        s_vals = df_sad[df_sad['trial'] == t]['score'].values\n        h_vals = df_hc[df_hc['trial'] == t]['score'].values\n        \n        # A. SAD > 0\n        t_s, p_s = ttest_1samp(s_vals, 0, alternative='greater')\n        df_s = len(s_vals) - 1\n        \n        # B. HC > 0\n        t_h, p_h = ttest_1samp(h_vals, 0, alternative='greater')\n        df_h = len(h_vals) - 1\n        \n        # C. SAD != HC\n        t_d, p_d = ttest_ind(s_vals, h_vals)\n        df_d = len(s_vals) + len(h_vals) - 2\n        \n        results.append({\n            'Trial': t,\n            'SAD_t': t_s, 'SAD_df': df_s, 'SAD_p': p_s,\n            'HC_t': t_h, 'HC_df': df_h, 'HC_p': p_h,\n            'Diff_t': t_d, 'Diff_df': df_d, 'Diff_p': p_d\n        })\n        \n    stats_df = pd.DataFrame(results)\n    \n    # FDR Correction\n    if not stats_df.empty:\n        _, stats_df['SAD_p_fdr'], _, _ = multipletests(stats_df['SAD_p'], alpha=0.05, method='fdr_bh')\n        _, stats_df['HC_p_fdr'], _, _ = multipletests(stats_df['HC_p'], alpha=0.05, method='fdr_bh')\n        _, stats_df['Diff_p_fdr'], _, _ = multipletests(stats_df['Diff_p'], alpha=0.05, method='fdr_bh')\n        \n    print(f\"\\n--- Statistics: {label} ---\")\n    # Print significant trials (Diff)\n    sig_diff = stats_df[stats_df['Diff_p_fdr'] < 0.05]\n    if not sig_diff.empty:\n        print(\"Significant Group Differences (FDR < 0.05):\")\n        print(sig_diff[['Trial', 'Diff_t', 'Diff_df', 'Diff_p', 'Diff_p_fdr']].to_string(index=False))\n    else:\n        print(\"No significant group differences found (FDR corrected).\")\n        \n    return stats_df\n\nprint(\"\\n[Step 3] Calculating Statistics...\")\nstats_safe = run_detailed_stats(df_safe_sad, df_safe_hc, \"Safety Learning\")\nstats_threat = run_detailed_stats(df_threat_sad, df_threat_hc, \"Threat Maintenance\")\n# =============================================================================\n# 4. Visualization\n# =============================================================================\ndef prepare_plot(df_sad, df_hc, name):\n    if df_sad.empty and df_hc.empty: return pd.DataFrame()\n    d_list = []\n    if not df_sad.empty:\n        d1 = df_sad.copy(); d1['Group'] = 'SAD'; d_list.append(d1)\n    if not df_hc.empty:\n        d2 = df_hc.copy();  d2['Group'] = 'HC'; d_list.append(d2)\n    \n    if not d_list: return pd.DataFrame()\n    \n    df = pd.concat(d_list)\n    df['Condition'] = name\n    # Bin trials if needed\n    if BLOCK_SIZE > 1:\n        df['trial'] = ((df['trial'] - 1) // BLOCK_SIZE) + 1\n    return df\n\ndf_safe = prepare_plot(df_safe_sad, df_safe_hc, \"Safety Learning\")\ndf_threat = prepare_plot(df_threat_sad, df_threat_hc, \"Threat Maintenance\")\n\nif df_safe.empty and df_threat.empty:\n    print(\"! No data to plot.\")\nelse:\n    sns.set_context(\"poster\")\n    fig, axes = plt.subplots(1, 2, figsize=(22, 9), sharey=True)\n    \n    # 1. Safety Plot\n    if not df_safe.empty:\n        sns.lineplot(data=df_safe, x='trial', y='score', hue='Group', \n                     palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, \n                     lw=3, marker=\"o\", err_style=\"band\", ax=axes[0])\n        axes[0].set_title(\"A. Safety Trajectory\\n(Target = CS-)\")\n        axes[0].set_ylabel(\"Similarity Score (0=Start, 1=Target)\")\n        axes[0].axhline(0, color='gray', ls='--', label='Start (Fear)')\n        axes[0].axhline(1, color='#2ca02c', ls='-', lw=2, label='Target (CS-)')\n        axes[0].legend(loc='upper left')\n\n    # 2. Threat Plot\n    if not df_threat.empty:\n        sns.lineplot(data=df_threat, x='trial', y='score', hue='Group', \n                     palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, \n                     lw=3, marker=\"s\", err_style=\"band\", ax=axes[1])\n        axes[1].set_title(\"B. Threat Maintenance\\n(Target = Early Half Reinstated CSR)\")\n        axes[1].set_xlabel(f\"Trial (Block Size: {BLOCK_SIZE})\")\n        axes[1].axhline(0, color='gray', ls='--', label='Start (Ext Early)')\n        axes[1].axhline(1, color='#d62728', ls='-', lw=2, label='Target (Early Half Reinstated CSR)')\n        axes[1].legend(loc='upper left')\n    \n    plt.tight_layout()\n    plt.show()\n\nresults_13 = {\n    'stats_safe': stats_safe, \n    'stats_threat': stats_threat,\n    'data_safe': df_safe,\n    'data_threat': df_threat\n}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 11: Analysis 1.4 - Decision Boundary Characteristics (Self-Network with Stats)\n",
    "# Objective: Quantify \"Cognitive Certainty\" (Entropy) and \"Decision Sharpness\" (Kurtosis) \n",
    "#            using each group's NATIVE feature network.\n",
    "# Method: Cross-Validated Probability Extraction (Fixed Optimal C).\n",
    "\n",
    "print(\"--- Running Analysis 1.4: Self-Network Statistics (Entropy, Kurtosis, Variance) ---\")\n",
    "\n",
    "# Constants\n",
    "COND_CLASS_THREAT = \"CSR\"\n",
    "COND_CLASS_SAFE = \"CSS\"\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup Feature Masks (Native) & Best Params\n",
    "# =============================================================================\n",
    "if 'importance_scores' not in locals(): \n",
    "    raise ValueError(\"Run Cell 8 first to generate 'importance_scores'.\")\n",
    "\n",
    "def get_significant_mask(scores): \n",
    "    return scores > 0\n",
    "\n",
    "mask_sad_native = get_significant_mask(importance_scores['SAD'])\n",
    "mask_hc_native = get_significant_mask(importance_scores['HC'])\n",
    "\n",
    "if 'subject_best_params' not in locals():\n",
    "    print(\"  > 'subject_best_params' not found. Using default C=1.0.\")\n",
    "    # Fallback default\n",
    "    subject_best_params = {}\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Calculation Helper (Entropy, Kurtosis, Variance)\n",
    "# =============================================================================\n",
    "def calculate_distribution_stats(X, y, subjects, feature_mask, best_params_dict):\n",
    "    # Slice Features & Center\n",
    "    X_masked = X[:, feature_mask]\n",
    "    \n",
    "    unique_subs = np.unique(subjects)\n",
    "    res = {'sub': [], 'entropy': [], 'kurtosis': [], 'variance': [], 'probabilities': [], 'brier': [], 'calib': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        c_val = best_params_dict.get(sub, 1.0)\n",
    "        mask_sub = (subjects == sub)\n",
    "        X_sub = X_masked[mask_sub]; y_sub = y[mask_sub]\n",
    "        \n",
    "        # Filter Boundary Classes\n",
    "        mask_binary = np.isin(y_sub, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n",
    "        X_binary = X_sub[mask_binary]; y_binary = y_sub[mask_binary]\n",
    "        \n",
    "        if len(y_binary) < 10: continue\n",
    "        \n",
    "        try:\n",
    "            # Configure Model\n",
    "            fixed_model = build_binary_pipeline()\n",
    "            fixed_model.set_params(classification__C=c_val)\n",
    "            \n",
    "            # Cross-Validation\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "            calib_model = CalibratedClassifierCV(\n",
    "                fixed_model,\n",
    "                method=\"sigmoid\",\n",
    "                cv=3\n",
    "            )\n",
    "            probs_all = cross_val_predict(calib_model, X_binary, y_binary, cv=cv, method='predict_proba', n_jobs=1)\n",
    "            \n",
    "            # Extract Safety Cue Probabilities (P(Threat | Safety Cue))\n",
    "            classes = sorted(np.unique(y_binary))\n",
    "            if COND_CLASS_THREAT not in classes: continue\n",
    "            idx_threat = classes.index(COND_CLASS_THREAT)\n",
    "            \n",
    "            mask_css = (y_binary == COND_CLASS_SAFE)\n",
    "            if np.sum(mask_css) == 0: continue\n",
    "            probs_css = probs_all[mask_css, idx_threat]\n",
    "            \n",
    "            # Metrics\n",
    "            # Calibration Metrics\n",
    "            y_bin_threat = (y_binary == COND_CLASS_THREAT).astype(int)\n",
    "            brier = brier_score_loss(y_bin_threat, probs_all[:, idx_threat])\n",
    "            frac_pos, mean_pred = calibration_curve(y_bin_threat, probs_all[:, idx_threat], n_bins=CALIB_BINS, strategy='uniform')\n",
    "            # 1. Entropy\n",
    "            p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n",
    "            trial_entropies = [entropy([p, 1-p], base=2) for p in p_clean]\n",
    "            \n",
    "            # 2. Kurtosis (Fisher's definition, Normal = 0.0)\n",
    "            k_val = kurtosis(probs_css, fisher=True)\n",
    "            \n",
    "            # 3. Variance\n",
    "            v_val = np.var(probs_css)\n",
    "            \n",
    "            res['sub'].append(sub)\n",
    "            res['entropy'].append(np.mean(trial_entropies))\n",
    "            res['kurtosis'].append(k_val)\n",
    "            res['variance'].append(v_val)\n",
    "            res['probabilities'].append(probs_css)\n",
    "            res['brier'].append(brier)\n",
    "            res['calib'].append({'frac_pos': frac_pos, 'mean_pred': mean_pred})\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print(f\"  ! Subject {sub} failed: {e}\")\n",
    "            pass\n",
    "            \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Execution (Self-Network)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Calculating Statistics (Native Networks)...\")\n",
    "\n",
    "# --- UPDATED DATA LOADING FROM CELL 5 STRUCTURE ---\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets or data_subsets[group_key]['ext'] is None:\n",
    "        raise ValueError(f\"Extinction data for {group_key} missing. Check Cell 5.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "# Load SAD Data\n",
    "X_sad, y_sad, sub_sad = get_ext_data(\"SAD_Placebo\")\n",
    "# Load HC Data\n",
    "X_hc, y_hc, sub_hc = get_ext_data(\"HC_Placebo\")\n",
    "\n",
    "# SAD Analysis (Native)\n",
    "print(\"  > Analyzing SAD Placebo...\")\n",
    "df_sad_stats = calculate_distribution_stats(\n",
    "    X_sad, y_sad, sub_sad, \n",
    "    mask_sad_native, subject_best_params\n",
    ")\n",
    "\n",
    "# HC Analysis (Native)\n",
    "print(\"  > Analyzing HC Placebo...\")\n",
    "df_hc_stats = calculate_distribution_stats(\n",
    "    X_hc, y_hc, sub_hc, \n",
    "    mask_hc_native, subject_best_params\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Statistical Comparison\n",
    "# =============================================================================\n",
    "def compare_metric(vec1, vec2, metric_name):\n",
    "    print(f\"\\n--- Metric: {metric_name} ---\")\n",
    "    if len(vec1) == 0 or len(vec2) == 0:\n",
    "        print(\"  ! Insufficient data.\")\n",
    "        return 1.0\n",
    "        \n",
    "    print(f\"  > SAD Mean: {np.mean(vec1):.3f}\")\n",
    "    print(f\"  > HC Mean:  {np.mean(vec2):.3f}\")\n",
    "    \n",
    "    t, p, _, _ = perm_ttest_ind(vec1, vec2, n_perm=N_PERMUTATION)\n",
    "    sig = \"*\" if p < 0.05 else \"ns\"\n",
    "    print(f\"  > Comparison: t={t:.3f}, p={p:.4f} ({sig})\")\n",
    "    return p\n",
    "\n",
    "print(\"\\n--- RESULTS: Self-Network Decision Statistics ---\")\n",
    "p_ent = compare_metric(df_sad_stats['entropy'], df_hc_stats['entropy'], \"Entropy (Uncertainty)\")\n",
    "p_kurt = compare_metric(df_sad_stats['kurtosis'], df_hc_stats['kurtosis'], \"Kurtosis (Sharpness)\")\n",
    "p_var = compare_metric(df_sad_stats['variance'], df_hc_stats['variance'], \"Variance (Spread)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Visualization\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\")\n",
    "fig = plt.figure(figsize=(24, 8))\n",
    "gs = fig.add_gridspec(1, 3)\n",
    "\n",
    "# A. Entropy (Violin)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "if not df_sad_stats.empty and not df_hc_stats.empty:\n",
    "    df_ent_plot = pd.concat([\n",
    "        pd.DataFrame({'Val': df_sad_stats['entropy'], 'Group': 'SAD'}),\n",
    "        pd.DataFrame({'Val': df_hc_stats['entropy'], 'Group': 'HC'})\n",
    "    ])\n",
    "    sns.violinplot(data=df_ent_plot, x='Group', y='Val', palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=ax1)\n",
    "    ax1.set_title(\"Uncertainty (Entropy)\")\n",
    "    ax1.set_ylabel(\"Shannon Entropy (bits)\")\n",
    "    if p_ent < 0.05: ax1.text(0.5, df_ent_plot['Val'].max(), f'* p={p_ent:.3f}', ha='center', fontsize=16)\n",
    "\n",
    "# B. Kurtosis (Box)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "if not df_sad_stats.empty and not df_hc_stats.empty:\n",
    "    df_kurt_plot = pd.concat([\n",
    "        pd.DataFrame({'Val': df_sad_stats['kurtosis'], 'Group': 'SAD'}),\n",
    "        pd.DataFrame({'Val': df_hc_stats['kurtosis'], 'Group': 'HC'})\n",
    "    ])\n",
    "    sns.boxplot(data=df_kurt_plot, x='Group', y='Val', palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=ax2)\n",
    "    ax2.set_title(\"Sharpness (Kurtosis)\")\n",
    "    ax2.set_ylabel(\"Fisher Kurtosis\")\n",
    "    if p_kurt < 0.05: ax2.text(0.5, df_kurt_plot['Val'].max(), f'* p={p_kurt:.3f}', ha='center', fontsize=16)\n",
    "\n",
    "# C. Density (Distribution)\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "if not df_sad_stats.empty and not df_hc_stats.empty:\n",
    "    probs_sad = np.concatenate(df_sad_stats['probabilities'].values)\n",
    "    probs_hc = np.concatenate(df_hc_stats['probabilities'].values)\n",
    "    sns.kdeplot(probs_sad, color='#c44e52', fill=True, label='SAD', bw_adjust=0.6, ax=ax3)\n",
    "    sns.kdeplot(probs_hc, color='#4c72b0', fill=True, label='HC', bw_adjust=0.6, ax=ax3)\n",
    "    ax3.set_title(\"Probability Distribution\")\n",
    "    ax3.set_xlabel(\"P(Threat) for Safety Cues\")\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_14_self = {'df_sad': df_sad_stats, 'df_hc': df_hc_stats}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 12: Analysis 2.1 - Safety Restoration & Threat Discrimination (Mixed Effects)\n# Objective: Test if Oxytocin rescues network topology in SAD.\n# Metrics:\n#   1. Safety Restoration: Dist(CSS, CS-) -> Should DECREASE (Return to baseline).\n#   2. Threat Discrimination: Dist(CSR, CSS) -> Should INCREASE (Better separation).\n# Statistical Model: Linear Mixed Effects (LME)\n#   Formula: Metric ~ Group * Drug\n#   Random Effect: 1 | Subject (Implicitly handles variance if repeated measures exist)\n\nprint(\"--- Running Analysis 2.1: Safety Restoration & Threat Discrimination (LME) ---\")\n\n# Constants\nCOND_SAFE_LEARN = \"CSS\"\nCOND_SAFE_BASE  = \"CS-\"\nCOND_THREAT     = \"CSR\"\n\n# =============================================================================\n# 0. Validate Masks from Cell 9\n# =============================================================================\nif 'mask_sad_top5' not in locals() or 'mask_hc_top5' not in locals():\n    raise ValueError(\"Top 5% Masks not found! Please run Cell 9 first.\")\n\n# =============================================================================\n# 1. Calculate Distances (Both Metrics)\n# =============================================================================\nsubgroups_21 = {\"SAD_Placebo\": [], \"SAD_Oxytocin\": [], \"HC_Placebo\": [], \"HC_Oxytocin\": []}\n\n# Link subjects to groups\nif 'sub_to_meta' not in locals():\n    if 'meta' in locals():\n        sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n    else:\n        raise ValueError(\"Metadata not found.\")\n\nfor sub in np.unique(sub_ext):\n    s_str = str(sub).strip()\n    if s_str in sub_to_meta: info = sub_to_meta[s_str]\n    elif f\"sub-{s_str}\" in sub_to_meta: info = sub_to_meta[f\"sub-{s_str}\"]\n    else: continue\n\n    key = f\"{info['Group']}_{info['Drug']}\"\n    if key in subgroups_21: subgroups_21[key].append(sub)\n\ndata_rows = []\nprint(\"  > Calculating distances (Metric A & Metric B)...\")\n\nfor key, subject_list in subgroups_21.items():\n    group, drug = key.split('_')\n    \n    # Select Native Mask\n    current_mask = mask_sad_top5 if group == \"SAD\" else mask_hc_top5\n        \n    for sub in subject_list:\n        mask_sub = (sub_ext == sub)\n        X_sub = X_ext[mask_sub]\n        y_sub = y_ext[mask_sub]\n        \n        # Apply Mask & Center\n        X_masked = X_sub[:, current_mask]\n        \n        # Extract Prototypes\n        idx_css = (y_sub == COND_SAFE_LEARN)\n        idx_cs_ = (y_sub == COND_SAFE_BASE)\n        idx_csr = (y_sub == COND_THREAT)\n        \n        if np.sum(idx_css) < 3 or np.sum(idx_cs_) < 3 or np.sum(idx_csr) < 3: continue\n        \n        p_css = np.mean(X_masked[idx_css], axis=0).reshape(1, -1)\n        p_cs_ = np.mean(X_masked[idx_cs_], axis=0).reshape(1, -1)\n        p_csr = np.mean(X_masked[idx_csr], axis=0).reshape(1, -1)\n        \n        # Metric 1: Safety Restoration (CSS vs CS-)\n        dist_safety = cdist(p_css, p_cs_, metric='correlation')[0][0]\n        \n        # Metric 2: Threat Discrimination (CSR vs CSS)\n        dist_threat = cdist(p_csr, p_css, metric='correlation')[0][0]\n            \n        data_rows.append({\n            \"Subject\": sub, \"Group\": group, \"Drug\": drug, \"Condition\": key,\n            \"Dist_Safety\": dist_safety,\n            \"Dist_Threat\": dist_threat\n        })\n\ndf_topo = pd.DataFrame(data_rows)\nprint(f\"  > Computed metrics for {len(df_topo)} subjects.\")\n\n# =============================================================================\n# 2. Statistical Tests (Linear Mixed Effects)\n# =============================================================================\nprint(\"\\n[Step 2] Testing for Interaction (Mixed Effects)...\")\n\ndef run_lme(formula, data, title):\n    print(f\"\\n--- {title} ---\")\n    # Groups='Subject' handles random intercepts per subject\n    # If design is between-subject, this converges to GLM/ANOVA but handles missingness better\n    md = smf.mixedlm(formula, data, groups=data[\"Subject\"]) \n    try:\n        mdf = md.fit()\n        print(mdf.summary())\n        \n        # Extract Interaction P-Value safely\n        term = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n        if term in mdf.pvalues:\n            p_val = mdf.pvalues[term]\n            print(f\"  >>> Interaction P-Value: {p_val:.5f} {'*' if p_val < 0.05 else ''}\")\n            return p_val\n        else:\n            print(\"  ! Interaction term not found in model results.\")\n            return 1.0\n            \n    except Exception as e:\n        print(f\"  ! Model Convergence Failed: {e}\")\n        return 1.0\n\n# Formula: Metric ~ Group * Drug\n# We set references explicitly: Group=HC, Drug=Placebo\nform_base = \"~ C(Group, Treatment(reference='HC')) * C(Drug, Treatment(reference='Placebo'))\"\n\n# Test 1: Safety Restoration\np_int_safe = run_lme(\"Dist_Safety \" + form_base, df_topo, \"Metric 1: Safety Restoration (CSS - CS-)\")\n\n# Test 2: Threat Discrimination\np_int_threat = run_lme(\"Dist_Threat \" + form_base, df_topo, \"Metric 2: Threat Discrimination (CSR - CSS)\")\n\n# =============================================================================\n# 3. Visualization\n# =============================================================================\nsns.set_context(\"poster\")\nfig, axes = plt.subplots(1, 2, figsize=(20, 9))\npal_group = {'SAD': '#c44e52', 'HC': '#4c72b0'}\n\n# Plot A: Safety Restoration\nsns.pointplot(data=df_topo, x='Drug', y='Dist_Safety', hue='Group', \n              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n              dodge=0.2, markers=['o', 's'], capsize=0.1, ax=axes[0])\nsns.stripplot(data=df_topo, x='Drug', y='Dist_Safety', hue='Group', \n              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n              dodge=True, alpha=0.4, jitter=True, legend=False, ax=axes[0])\n\naxes[0].set_title(\"A. Safety Restoration\\n(CSS vs CS-)\")\naxes[0].set_ylabel(\"Correlation Distance (Lower = Better)\")\nif p_int_safe < 0.05:\n    axes[0].text(0.5, 0.95, f\"Interaction: p={p_int_safe:.3f}\", transform=axes[0].transAxes, ha='center', fontweight='bold')\n\n# Plot B: Threat Discrimination\nsns.pointplot(data=df_topo, x='Drug', y='Dist_Threat', hue='Group', \n              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n              dodge=0.2, markers=['o', 's'], capsize=0.1, ax=axes[1])\nsns.stripplot(data=df_topo, x='Drug', y='Dist_Threat', hue='Group', \n              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n              dodge=True, alpha=0.4, jitter=True, legend=False, ax=axes[1])\n\naxes[1].set_title(\"B. Threat Discrimination\\n(CSR vs CSS)\")\naxes[1].set_ylabel(\"Correlation Distance (Higher = Better)\")\nif p_int_threat < 0.05:\n    axes[1].text(0.5, 0.95, f\"Interaction: p={p_int_threat:.3f}\", transform=axes[1].transAxes, ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nresults_21 = {'df': df_topo, 'p_safe': p_int_safe, 'p_threat': p_int_threat}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 13: Analysis 2.2 - Drift Efficiency (Safety & Threat Maintenance)\n# Objective: Test OXT effect on neural drift efficiency in the Core Top 5% Network.\n# Domains:\n#   1. Safety Learning:    CSS(Ext) -> CS-(Ext)\n#   2. Threat Maintenance: CSR(Ext) -> CSR(Reinst)\n# Stats: Linear Mixed Effects (LME)\n# Visualization: Line plots (Means \u00b1 SEM)\n\nprint(\"--- Running Analysis 2.2: Drift Efficiency (Means \u00b1 SEM) ---\")\n\n# Constants\nCOND_SAFE_TGT = \"CS-\"\nCOND_SAFE_LRN = \"CSS\"\nCOND_THREAT_LRN = \"CSR\"\nPERCENTILE_THRESH = 95  # Top 5%\n\n# =============================================================================\n# 0. Setup: Masks & Data Loading\n# =============================================================================\nprint(f\"\\n[Step 0] Setup & Data Loading...\")\n\nif 'importance_scores' not in locals(): \n    raise ValueError(\"Importance scores not found! Please run Cell 8 first.\")\n\ndef get_top_percentile_mask(scores, percentile):\n    thresh = np.percentile(scores, percentile)\n    return (scores >= thresh) & (scores > 0)\n\nmask_sad_core = get_top_percentile_mask(importance_scores['SAD'], PERCENTILE_THRESH)\nmask_hc_core = get_top_percentile_mask(importance_scores['HC'], PERCENTILE_THRESH)\nprint(f\"  > Core Masks: SAD={np.sum(mask_sad_core)}, HC={np.sum(mask_hc_core)}\")\n\n# Load Reinstatement Data\nX_rst_all, y_rst_all, sub_rst_all = None, None, None\nif 'X_reinst' in locals():\n    X_rst_all, y_rst_all, sub_rst_all = X_reinst, y_reinst, sub_reinst\nelse:\n    try:\n        xs, ys, ss = [], [], []\n        for grp in [\"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"]:\n            if grp in data_subsets and data_subsets[grp]['rst'] is not None:\n                d = data_subsets[grp]['rst']\n                xs.append(d['X']); ys.append(d['y']); ss.append(d['sub'])\n        if xs:\n            X_rst_all = np.vstack(xs)\n            y_rst_all = np.concatenate(ys)\n            sub_rst_all = np.concatenate(ss)\n    except:\n        print(\"  ! Threat analysis skipped (Reinstatement data missing).\")\n\n# =============================================================================\n# 1. Vector Calculation\n# =============================================================================\nsubgroups_22 = {\"SAD_Placebo\": [], \"SAD_Oxytocin\": [], \"HC_Placebo\": [], \"HC_Oxytocin\": []}\n\nif 'sub_to_meta' not in locals():\n    if 'meta' in locals():\n        sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n    else: raise ValueError(\"Metadata not found.\")\n\nfor sub in np.unique(sub_ext):\n    s_str = str(sub).strip()\n    if s_str in sub_to_meta: info = sub_to_meta[s_str]\n    elif f\"sub-{s_str}\" in sub_to_meta: info = sub_to_meta[f\"sub-{s_str}\"]\n    else: continue\n    key = f\"{info['Group']}_{info['Drug']}\"\n    if key in subgroups_22: subgroups_22[key].append(sub)\n\ndata_rows = []\nprint(\"\\n[Step 1] Calculating Drift Vectors...\")\n\ndef calc_drift_metrics(X_start_phase, y_start_phase, X_tgt_phase, y_tgt_phase, \n                       cond_start, cond_target, mask, sub_id):\n    # Mask & Center (Phase-wise centering)\n    X_s = X_start_phase[:, mask]\n    \n    X_t = X_tgt_phase[:, mask]\n    \n    # Target Centroid\n    mask_tgt = (y_tgt_phase == cond_target)\n    if np.sum(mask_tgt) < 2: return None\n    P_target = np.mean(X_t[mask_tgt], axis=0)\n    \n    # Trajectory\n    mask_lrn = (y_start_phase == cond_start)\n    idx_lrn = np.where(mask_lrn)[0]\n    if len(idx_lrn) < 4: return None\n    \n    cutoff = len(idx_lrn) // 2\n    P_start = np.mean(X_s[idx_lrn[:cutoff]], axis=0)\n    P_end = np.mean(X_s[idx_lrn[cutoff:]], axis=0)\n    \n    # Vectors\n    V_axis = P_target - P_start\n    V_drift = P_end - P_start\n    \n    nA, nD = norm(V_axis), norm(V_drift)\n    if nA == 0 or nD == 0: return None\n    \n    dot = np.dot(V_drift, V_axis)\n    return {'Cosine': dot / (nA * nD), 'Projection': dot / nA}\n\nfor key, subject_list in subgroups_22.items():\n    group, drug = key.split('_')\n    curr_mask = mask_sad_core if group == \"SAD\" else mask_hc_core\n    \n    for sub in subject_list:\n        m_ext = (sub_ext == sub)\n        X_e, y_e = X_ext[m_ext], y_ext[m_ext]\n        \n        # 1. Safety\n        res_safe = calc_drift_metrics(X_e, y_e, X_e, y_e, COND_SAFE_LRN, COND_SAFE_TGT, curr_mask, sub)\n        if res_safe:\n            data_rows.append({\"Subject\": sub, \"Group\": group, \"Drug\": drug, \"Domain\": \"Safety\", **res_safe})\n            \n        # 2. Threat\n        if X_rst_all is not None:\n            m_rst = (sub_rst_all == sub)\n            if np.sum(m_rst) > 0:\n                X_r, y_r = X_rst_all[m_rst], y_rst_all[m_rst]\n                res_threat = calc_drift_metrics(X_e, y_e, X_r, y_r, COND_THREAT_LRN, COND_THREAT_LRN, curr_mask, sub)\n                if res_threat:\n                    data_rows.append({\"Subject\": sub, \"Group\": group, \"Drug\": drug, \"Domain\": \"Threat\", **res_threat})\n\ndf_drift = pd.DataFrame(data_rows)\nprint(f\"  > Computed vectors for {len(df_drift['Subject'].unique())} subjects.\")\n\n# =============================================================================\n# 2. Statistics (LME)\n# =============================================================================\nprint(\"\\n[Step 2] Statistical Testing (LME)...\")\nlme_results = {}\n\nfor domain in [\"Safety\", \"Threat\"]:\n    if domain not in df_drift['Domain'].values: continue\n    df_sub = df_drift[df_drift[\"Domain\"] == domain].copy()\n    form_base = \"~ C(Group, Treatment(reference='HC')) * C(Drug, Treatment(reference='Placebo'))\"\n    \n    print(f\"\\n--- Domain: {domain} ---\")\n    for metric in [\"Cosine\", \"Projection\"]:\n        try:\n            md = smf.mixedlm(f\"{metric} {form_base}\", df_sub, groups=df_sub[\"Subject\"])\n            mdf = md.fit()\n            term = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n            p_val = mdf.pvalues.get(term, 1.0)\n            print(f\"  > {metric}: Interaction p={p_val:.4f} {'*' if p_val<0.05 else ''}\")\n            lme_results[f\"{domain}_{metric}\"] = p_val\n        except:\n            lme_results[f\"{domain}_{metric}\"] = 1.0\n\n# =============================================================================\n# 3. Visualization (Lines Only, Error=SE)\n# =============================================================================\nsns.set_context(\"poster\", font_scale=0.8)\nfig, axes = plt.subplots(2, 2, figsize=(18, 12))\npal_group = {'SAD': '#c44e52', 'HC': '#4c72b0'}\n\ndef plot_interaction(ax, df, domain, metric, p_val):\n    data = df[df[\"Domain\"] == domain]\n    if data.empty: return\n    \n    # Error bars = Standard Error (se)\n    # This approximates within-subject error visualization for group means\n    sns.pointplot(data=data, x='Drug', y=metric, hue='Group', \n                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n                  dodge=0.15, markers=['o', 's'], linestyles=['-', '--'], \n                  capsize=0.1, err_kws={'linewidth': 2.5}, scale=1.2, \n                  errorbar='se', ax=ax)\n    \n    ax.set_title(f\"{domain} - {metric}\")\n    ax.axhline(0, color='gray', ls='--', alpha=0.5)\n    ax.legend(loc='upper right', fontsize=12)\n    \n    if p_val < 0.05:\n        ax.text(0.5, 0.9, f\"Interaction p={p_val:.3f}\", transform=ax.transAxes, \n                ha='center', fontweight='bold', color='black')\n\n# Plot Grid\nplot_interaction(axes[0,0], df_drift, \"Safety\", \"Cosine\", lme_results.get(\"Safety_Cosine\", 1.0))\nplot_interaction(axes[0,1], df_drift, \"Safety\", \"Projection\", lme_results.get(\"Safety_Projection\", 1.0))\nplot_interaction(axes[1,0], df_drift, \"Threat\", \"Cosine\", lme_results.get(\"Threat_Cosine\", 1.0))\nplot_interaction(axes[1,1], df_drift, \"Threat\", \"Projection\", lme_results.get(\"Threat_Projection\", 1.0))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Note: Error bars represent Standard Error of the Mean (SEM).\")\nresults_22 = {'df': df_drift, 'stats': lme_results}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 14: Analysis 2.3 - The \"Probabilistic Opening\" Test (Entropy, Kurtosis, Variance)\n# Objective: Test if Oxytocin increases \"Cognitive Uncertainty\" in SAD.\n# Hypothesis: SAD-OXT will show HIGHER Entropy, LOWER Kurtosis, HIGHER Variance than SAD-PLC.\n# Method: Cross-Validated Probability Extraction -> Metrics.\n# Stats: Linear Mixed Effects (Metric ~ Group * Drug).\n\nprint(\"--- Running Analysis 2.3: Probabilistic Opening (Entropy, Kurtosis, Variance) ---\")\n\n# Constants\nCOND_CLASS_THREAT = \"CSR\"\nCOND_CLASS_SAFE = \"CSS\"\nRANDOM_STATE = 42\n\n# =============================================================================\n# 0. Setup: Masks & Data\n# =============================================================================\nif 'importance_scores' not in locals(): \n    raise ValueError(\"Importance scores missing. Run Cell 8.\")\n\n# Define Native Networks\ndef get_significant_mask(scores): return scores > 0\n\nmask_sad_native = get_significant_mask(importance_scores['SAD'])\nmask_hc_native = get_significant_mask(importance_scores['HC'])\nprint(f\"  > SAD Native Network: {np.sum(mask_sad_native)} voxels\")\nprint(f\"  > HC Native Network:  {np.sum(mask_hc_native)} voxels\")\n\n# Load Subject-Group-Drug Mapping\nif 'sub_to_meta' not in locals():\n    if 'meta' in locals():\n        sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n    else: raise ValueError(\"Metadata not found.\")\n\nsubgroups_23 = {\"SAD_Placebo\": [], \"SAD_Oxytocin\": [], \"HC_Placebo\": [], \"HC_Oxytocin\": []}\nfor sub in np.unique(sub_ext):\n    s_str = str(sub).strip()\n    if s_str in sub_to_meta: info = sub_to_meta[s_str]\n    elif f\"sub-{s_str}\" in sub_to_meta: info = sub_to_meta[f\"sub-{s_str}\"]\n    else: continue\n    \n    key = f\"{info['Group']}_{info['Drug']}\"\n    if key in subgroups_23: subgroups_23[key].append(sub)\n\n# =============================================================================\n# 1. Calculation Helper (All 3 Metrics)\n# =============================================================================\ndef calc_metrics_for_subject(X, y, sub_id, feature_mask, C_param=1.0):\n    # 1. Mask & Center\n    X_m = X[:, feature_mask]\n    \n    # 2. Filter Binary Classes\n    mask_bin = np.isin(y, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n    X_bin, y_bin = X_m[mask_bin], y[mask_bin]\n    \n    if len(y_bin) < 10: return None\n    \n    try:\n                # 3. Nested CV for C (within-subject)\n        outer_cv = get_cv(y_bin, np.full(len(y_bin), sub_id), n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n        inner_cv = get_cv(y_bin, np.full(len(y_bin), sub_id), n_splits=SUBJECT_INNER_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n        probs_all = np.zeros((len(y_bin), 2))\n\n        for train_idx, test_idx in outer_cv.split(X_bin, y_bin, groups=np.full(len(y_bin), sub_id)):\n            gs = GridSearchCV(build_binary_pipeline(), param_grid, cv=inner_cv, scoring='accuracy', n_jobs=1)\n            gs.fit(X_bin[train_idx], y_bin[train_idx], groups=np.full(len(train_idx), sub_id))\n            best_model = gs.best_estimator_\n            probs_all[test_idx] = best_model.predict_proba(X_bin[test_idx])\n\n        \n        # 4. Extract Safety Cue Probabilities\n        classes = sorted(np.unique(y_bin))\n        if COND_CLASS_THREAT not in classes: return None\n        idx_threat = classes.index(COND_CLASS_THREAT)\n        \n        mask_css = (y_bin == COND_CLASS_SAFE)\n        if np.sum(mask_css) == 0: return None\n        \n        # Prob(Threat | Safety Cue)\n        probs_css = probs_all[mask_css, idx_threat]\n        \n        # --- Metrics ---\n        # A. Entropy (Uncertainty)\n        p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n        ents = [entropy([p, 1-p], base=2) for p in p_clean]\n        val_ent = np.mean(ents)\n        \n        # B. Kurtosis (Sharpness) - Fisher's (Normal=0)\n        val_kurt = kurtosis(probs_css, fisher=True)\n        \n        # C. Variance (Spread)\n        val_var = np.var(probs_css)\n        \n        return {'Entropy': val_ent, 'Kurtosis': val_kurt, 'Variance': val_var}\n        \n    except Exception:\n        return None\n\n# =============================================================================\n# 2. Execution Loop\n# =============================================================================\ndata_rows = []\nprint(\"\\n[Step 1] Calculating Decision Metrics...\")\n\nif 'subject_best_params' not in locals(): subject_best_params = {}\n\nfor key, sub_list in subgroups_23.items():\n    group, drug = key.split('_')\n    curr_mask = mask_sad_native if group == \"SAD\" else mask_hc_native\n    \n    for sub in sub_list:\n        mask_s = (sub_ext == sub)\n        X_s, y_s = X_ext[mask_s], y_ext[mask_s]\n        \n        c_val = subject_best_params.get(sub, 1.0)\n        \n        res = calc_metrics_for_subject(X_s, y_s, sub, curr_mask, c_val)\n        \n        if res is not None:\n            data_rows.append({\n                \"Subject\": sub, \"Group\": group, \"Drug\": drug, \n                \"Entropy\": res['Entropy'], \n                \"Kurtosis\": res['Kurtosis'], \n                \"Variance\": res['Variance']\n            })\n\ndf_metrics = pd.DataFrame(data_rows)\nprint(f\"  > Computed metrics for {len(df_metrics)} subjects.\")\n\n# =============================================================================\n# 3. Statistical Testing (LME Loop)\n# =============================================================================\nprint(\"\\n[Step 2] Statistical Testing (LME for each metric)...\")\n\nstats_results = {}\nmetrics_list = [\"Entropy\", \"Kurtosis\", \"Variance\"]\n\nfor met in metrics_list:\n    print(f\"\\n--- Metric: {met} ---\")\n    try:\n        # LME: Metric ~ Group * Drug + (1|Subject)\n        md = smf.mixedlm(f\"{met} ~ C(Group, Treatment(reference='HC')) * C(Drug, Treatment(reference='Placebo'))\", \n                         df_metrics, groups=df_metrics[\"Subject\"])\n        mdf = md.fit()\n        print(mdf.summary())\n        \n        # Interaction P-Value\n        term_int = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n        p_val = mdf.pvalues.get(term_int, 1.0)\n        stats_results[met] = p_val\n        print(f\"  >>> Interaction p={p_val:.4f} {'*' if p_val < 0.05 else ''}\")\n        \n    except Exception as e:\n        print(f\"  ! Model Failed: {e}\")\n        stats_results[met] = 1.0\n\n# =============================================================================\n# 4. Visualization (Side-by-Side)\n# =============================================================================\nsns.set_context(\"poster\", font_scale=0.8)\nfig, axes = plt.subplots(1, 3, figsize=(24, 7))\npal_group = {'SAD': '#c44e52', 'HC': '#4c72b0'}\n\ndef plot_metric(ax, metric, p_val):\n    sns.pointplot(data=df_metrics, x='Drug', y=metric, hue='Group', \n                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n                  dodge=0.2, markers=['o', 's'], linestyles=['-', '--'], \n                  capsize=0.1, errorbar='se', scale=1.1, ax=ax)\n    \n    ax.set_title(f\"{metric}\")\n    ax.set_ylabel(metric)\n    if metric == \"Entropy\": ax.set_ylabel(\"Entropy (Uncertainty)\")\n    if metric == \"Kurtosis\": ax.set_ylabel(\"Kurtosis (Sharpness)\")\n    \n    # Annotate Significance\n    if p_val < 0.05:\n        ax.text(0.5, 0.9, f\"Interaction\\np={p_val:.3f}\", transform=ax.transAxes, \n                ha='center', fontweight='bold', color='black')\n\n# Plot all 3\nplot_metric(axes[0], \"Entropy\", stats_results[\"Entropy\"])\nplot_metric(axes[1], \"Kurtosis\", stats_results[\"Kurtosis\"])\nplot_metric(axes[2], \"Variance\", stats_results[\"Variance\"])\n\naxes[1].get_legend().remove()\naxes[2].get_legend().remove()\naxes[0].legend(loc='lower left', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\nresults_23 = {'df': df_metrics, 'stats': stats_results}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 15: Analysis 2.4 - Spatial Re-Alignment (The \"Normalizing\" Effect)\n",
    "# Objective: Test if OXT shifts SAD representations to align with the \"Healthy\" template.\n",
    "# Protocol: \n",
    "#   1. Retrieve the 'CSS vs CSR' model specifically from Analysis 1.1 (Cell 6).\n",
    "#   2. Cross-Decode on SAD-Placebo vs. SAD-Oxytocin (using full feature set).\n",
    "#   3. Metric: Standard Accuracy (matching Analysis 1.1).\n",
    "# Visualization: Accuracy Heatmap (Train HC -> Test SAD groups).\n",
    "\n",
    "print(\"--- Running Analysis 2.4: Spatial Re-Alignment (Using Analysis 1.1 Output) ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Constants\n",
    "COND_SAFE = \"CSS\"\n",
    "COND_THREAT = \"CSR\"\n",
    "LABELS = [COND_SAFE, COND_THREAT]\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup: Retrieve Correct Model from Cell 6 Results\n",
    "# =============================================================================\n",
    "# We need the specific model trained on Safety (CSS) vs Threat (CSR).\n",
    "target_contrast = \"CSS vs CSR\"\n",
    "alt_contrast = \"CSR vs CSS\"\n",
    "\n",
    "if 'res_hc_dict' in locals():\n",
    "    # Check which key exists in the dictionary\n",
    "    if target_contrast in res_hc_dict:\n",
    "        gold_model = res_hc_dict[target_contrast]['model']\n",
    "        print(f\"  > Retrieved Analysis 1.1 Model for: {target_contrast}\")\n",
    "    elif alt_contrast in res_hc_dict:\n",
    "        gold_model = res_hc_dict[alt_contrast]['model']\n",
    "        print(f\"  > Retrieved Analysis 1.1 Model for: {alt_contrast}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Analysis 1.1 results found, but '{target_contrast}' is missing.\\n\"\n",
    "                         f\"    Available keys: {list(res_hc_dict.keys())}\")\n",
    "else:\n",
    "    raise ValueError(\"Analysis 1.1 results ('res_hc_dict') not found. Please run Cell 6 first.\")\n",
    "\n",
    "# Verify Classes (Must be Safety/Threat)\n",
    "print(f\"  > Model Classes: {gold_model.classes_}\")\n",
    "if COND_THREAT not in gold_model.classes_ or COND_SAFE not in gold_model.classes_:\n",
    "    raise ValueError(f\"CRITICAL: The retrieved model was trained on {gold_model.classes_}, \"\n",
    "                     f\"but this analysis requires {LABELS}.\")\n",
    "\n",
    "# Data Loading Helper\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets: raise ValueError(f\"{group_key} missing.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "X_sad_plc, y_sad_plc, sub_sad_plc = get_ext_data(\"SAD_Placebo\")\n",
    "X_sad_oxt, y_sad_oxt, sub_sad_oxt = get_ext_data(\"SAD_Oxytocin\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Cross-Decoding (Standard Accuracy, matching Analysis 1.1)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 1] Cross-Decoding on SAD Subgroups (Standard Accuracy, matching Analysis 1.1)...\")\n",
    "\n",
    "# Filter to only the two classes of interest (CSS and CSR)\n",
    "mask_sad_plc = np.isin(y_sad_plc, LABELS)\n",
    "mask_sad_oxt = np.isin(y_sad_oxt, LABELS)\n",
    "\n",
    "X_sad_plc_filtered = X_sad_plc[mask_sad_plc]\n",
    "y_sad_plc_filtered = y_sad_plc[mask_sad_plc]\n",
    "sub_sad_plc_filtered = sub_sad_plc[mask_sad_plc]\n",
    "\n",
    "X_sad_oxt_filtered = X_sad_oxt[mask_sad_oxt]\n",
    "y_sad_oxt_filtered = y_sad_oxt[mask_sad_oxt]\n",
    "sub_sad_oxt_filtered = sub_sad_oxt[mask_sad_oxt]\n",
    "\n",
    "# Decision scores -> subject-level forced-choice accuracy\n",
    "scores_plc = gold_model.decision_function(X_sad_plc_filtered)\n",
    "scores_oxt = gold_model.decision_function(X_sad_oxt_filtered)\n",
    "\n",
    "scores_plc_2d = (\n",
    "    np.column_stack((-scores_plc, scores_plc))\n",
    "    if scores_plc.ndim == 1\n",
    "    else scores_plc\n",
    ")\n",
    "scores_oxt_2d = (\n",
    "    np.column_stack((-scores_oxt, scores_oxt))\n",
    "    if scores_oxt.ndim == 1\n",
    "    else scores_oxt\n",
    ")\n",
    "\n",
    "acc_sad_plc = compute_subject_forced_choice_accs(\n",
    "    y_sad_plc_filtered,\n",
    "    scores_plc_2d,\n",
    "    sub_sad_plc_filtered,\n",
    "    list(gold_model.classes_)\n",
    ")\n",
    "acc_sad_oxt = compute_subject_forced_choice_accs(\n",
    "    y_sad_oxt_filtered,\n",
    "    scores_oxt_2d,\n",
    "    sub_sad_oxt_filtered,\n",
    "    list(gold_model.classes_)\n",
    ")\n",
    "m_plc = np.mean(acc_sad_plc) if len(acc_sad_plc) > 0 else 0\n",
    "m_oxt = np.mean(acc_sad_oxt) if len(acc_sad_oxt) > 0 else 0\n",
    "\n",
    "print(f\"  > SAD-Placebo Acc (decoded by HC Model):  {m_plc:.1%} (n={len(acc_sad_plc)})\")\n",
    "print(f\"  > SAD-Oxytocin Acc (decoded by HC Model): {m_oxt:.1%} (n={len(acc_sad_oxt)})\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Statistical Comparison\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Statistical Test...\")\n",
    "if len(acc_sad_oxt) > 1 and len(acc_sad_plc) > 1:\n",
    "    # One-tailed t-test: OXT > Placebo\n",
    "    t_stat, p_val = ttest_ind(acc_sad_oxt, acc_sad_plc, alternative='greater')\n",
    "    sig_label = \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"  > Hypothesis (OXT > PLC): t={t_stat:.3f}, p={p_val:.4f} ({sig_label})\")\n",
    "else:\n",
    "    print(\"  ! Insufficient data for statistics.\")\n",
    "    p_val = 1.0; sig_label=\"nA\"\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Visualization (Heatmap)\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Prepare Matrix: 1 Row (Train HC) x 2 Cols (Test PLC, Test OXT)\n",
    "matrix_data = np.array([[m_plc, m_oxt]])\n",
    "\n",
    "# Annotation String\n",
    "annot_data = np.array([\n",
    "    [f\"{m_plc:.3f}\", f\"{m_oxt:.3f}\\n({sig_label})\"]\n",
    "])\n",
    "\n",
    "# Draw Heatmap\n",
    "sns.heatmap(matrix_data, annot=annot_data, fmt=\"\", cmap=\"RdBu_r\", \n",
    "            vmin=0.3, vmax=0.7, center=0.5, cbar=True,\n",
    "            xticklabels=['Test: SAD-Placebo', 'Test: SAD-Oxytocin'], \n",
    "            yticklabels=['Train: HC-Placebo (Anal 1.1)'], ax=ax)\n",
    "\n",
    "ax.set_title(f\"Analysis 2.4: Spatial Re-Alignment\\n(OXT vs PLC Improvement: p={p_val:.3f})\")\n",
    "plt.yticks(rotation=0) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\" - SAD-Placebo Accuracy ({m_plc:.1%}): How well the SAD brain fits the Healthy template naturally.\")\n",
    "print(f\" - SAD-Oxytocin Accuracy ({m_oxt:.1%}): How well it fits AFTER treatment.\")\n",
    "print(\" - A significant increase indicates OXT 'normalizes' the neural code for Threat vs Safety.\")\n",
    "\n",
    "results_24 = {'acc_plc': acc_sad_plc, 'acc_oxt': acc_sad_oxt, 'p_val': p_val, 'model': gold_model}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 16: Analysis 2.5 - Reverse Cross-Decoding (SAD Template -> HC)\n",
    "# Objective: Test if the \"Disordered\" SAD representation generalizes to Healthy brains.\n",
    "# Protocol:\n",
    "#   1. Train Model on SAD-Placebo (CSS vs CSR).\n",
    "#   2. Feature Selection: Full feature set.\n",
    "#   3. Test on HC-Placebo and HC-Oxytocin.\n",
    "#   4. Metric: Subject-level forced-choice accuracy from decision scores.\n",
    "# Hypothesis: Accuracy should be LOW (near chance), confirming \"Functional Specificity\".\n",
    "\n",
    "print(\"--- Running Analysis 2.5: Reverse Cross-Decoding (SAD -> HC) ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp, ttest_ind\n",
    "\n",
    "# Constants\n",
    "COND_SAFE = \"CSS\"\n",
    "COND_THREAT = \"CSR\"\n",
    "LABELS = [COND_SAFE, COND_THREAT]\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup: Full feature set (no mask)\n",
    "# =============================================================================\n",
    "print(\"  > Feature Space: Full feature set (no mask)\")\n",
    "\n",
    "# Data Loading Helper\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets: raise ValueError(f\"{group_key} missing.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "# Load Groups\n",
    "X_sad_plc, y_sad_plc, sub_sad_plc = get_ext_data(\"SAD_Placebo\")\n",
    "X_hc_plc, y_hc_plc, sub_hc_plc = get_ext_data(\"HC_Placebo\")\n",
    "X_hc_oxt, y_hc_oxt, sub_hc_oxt = get_ext_data(\"HC_Oxytocin\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Train SAD-Placebo Model (The \"Disordered\" Classifier)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 1] Training SAD-Placebo Model...\")\n",
    "\n",
    "# Filter for CSS vs CSR\n",
    "mask_train = np.isin(y_sad_plc, LABELS)\n",
    "X_train = X_sad_plc[mask_train]\n",
    "y_train = y_sad_plc[mask_train]\n",
    "s_train = sub_sad_plc[mask_train]\n",
    "\n",
    "# Center (Subject-wise)\n",
    "\n",
    "# Train Classifier\n",
    "sad_model = build_binary_pipeline()\n",
    "sad_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"  > Model Trained on {len(np.unique(s_train))} SAD subjects.\")\n",
    "print(f\"  > Classes: {sad_model.classes_}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Cross-Decode on HC Groups (Standard Accuracy, matching Analysis 1.1)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Testing on HC Subgroups (Subject-Level Forced-Choice)...\")\n",
    "\n",
    "# Apply feature mask and filter to labels of interest\n",
    "mask_hc_plc_labels = np.isin(y_hc_plc, LABELS)\n",
    "mask_hc_oxt_labels = np.isin(y_hc_oxt, LABELS)\n",
    "\n",
    "X_hc_plc_filtered = X_hc_plc[mask_hc_plc_labels]\n",
    "y_hc_plc_filtered = y_hc_plc[mask_hc_plc_labels]\n",
    "sub_hc_plc_filtered = sub_hc_plc[mask_hc_plc_labels]\n",
    "\n",
    "X_hc_oxt_filtered = X_hc_oxt[mask_hc_oxt_labels]\n",
    "y_hc_oxt_filtered = y_hc_oxt[mask_hc_oxt_labels]\n",
    "sub_hc_oxt_filtered = sub_hc_oxt[mask_hc_oxt_labels]\n",
    "\n",
    "scores_hc_plc = sad_model.decision_function(X_hc_plc_filtered)\n",
    "scores_hc_oxt = sad_model.decision_function(X_hc_oxt_filtered)\n",
    "\n",
    "scores_hc_plc_2d = (\n",
    "    np.column_stack((-scores_hc_plc, scores_hc_plc))\n",
    "    if scores_hc_plc.ndim == 1\n",
    "    else scores_hc_plc\n",
    ")\n",
    "scores_hc_oxt_2d = (\n",
    "    np.column_stack((-scores_hc_oxt, scores_hc_oxt))\n",
    "    if scores_hc_oxt.ndim == 1\n",
    "    else scores_hc_oxt\n",
    ")\n",
    "\n",
    "acc_hc_plc = compute_subject_forced_choice_accs(\n",
    "    y_hc_plc_filtered,\n",
    "    scores_hc_plc_2d,\n",
    "    sub_hc_plc_filtered,\n",
    "    list(sad_model.classes_)\n",
    ")\n",
    "acc_hc_oxt = compute_subject_forced_choice_accs(\n",
    "    y_hc_oxt_filtered,\n",
    "    scores_hc_oxt_2d,\n",
    "    sub_hc_oxt_filtered,\n",
    "    list(sad_model.classes_)\n",
    ")\n",
    "m_hc_plc = np.mean(acc_hc_plc) if len(acc_hc_plc) > 0 else 0\n",
    "m_hc_oxt = np.mean(acc_hc_oxt) if len(acc_hc_oxt) > 0 else 0\n",
    "\n",
    "print(f\"  > HC-Placebo Acc (decoded by SAD):  {m_hc_plc:.1%} (n={len(acc_hc_plc)})\")\n",
    "print(f\"  > HC-Oxytocin Acc (decoded by SAD): {m_hc_oxt:.1%} (n={len(acc_hc_oxt)})\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Statistical Comparison\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 3] Statistical Test (Vs Chance 50%)...\")\n",
    "\n",
    "# Test if HC-Placebo decoding is significantly above chance\n",
    "# If p > 0.05, it confirms SAD representations do NOT generalize to HC (High Specificity)\n",
    "t_chance, p_chance = ttest_1samp(acc_hc_plc, 0.5)\n",
    "sig_chance = \"*\" if p_chance < 0.05 else \"ns\"\n",
    "\n",
    "print(f\"  > SAD->HC Generalization (vs 50%): t={t_chance:.3f}, p={p_chance:.4f} ({sig_chance})\")\n",
    "print(\"    (Note: 'ns' is GOOD here -> implies disordered code is specific to SAD)\")\n",
    "\n",
    "# Compare HC-PLC vs HC-OXT (Exploratory)\n",
    "t_drug, p_drug = ttest_ind(acc_hc_oxt, acc_hc_plc)\n",
    "print(f\"  > Drug Effect in HC (OXT vs PLC): p={p_drug:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Visualization (Heatmap)\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "matrix_data = np.array([[m_hc_plc, m_hc_oxt]])\n",
    "annot_data = np.array([\n",
    "    [f\"{m_hc_plc:.3f}\\n({sig_chance} vs 0.5)\", f\"{m_hc_oxt:.3f}\"]\n",
    "])\n",
    "\n",
    "sns.heatmap(matrix_data, annot=annot_data, fmt=\"\", cmap=\"RdBu_r\", \n",
    "            vmin=0.3, vmax=0.7, center=0.5, cbar=True,\n",
    "            xticklabels=['Test: HC-Placebo', 'Test: HC-Oxytocin'], \n",
    "            yticklabels=['Train: SAD-Placebo'], ax=ax)\n",
    "\n",
    "ax.set_title(\"Analysis 2.5: Reverse Cross-Decoding\\n(Does SAD 'Disorder' generalize to Healthy?)\")\n",
    "plt.yticks(rotation=0) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_25 = {'acc_hc_plc': acc_hc_plc, 'acc_hc_oxt': acc_hc_oxt, 'model': sad_model}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 17: Searchlight RSM (CSR/CSS/CS-) + Early/Late Dynamics (Extinction & Reinstatement)\n# Objective: Identify regions sensitive to CSR/CSS/CS- via local RSM\n# and quantify early->late changes in extinction and reinstatement.\n# Add-ons:\n#   1) Group-specific maps (SAD/HC, OXT/PLC)\n#   2) Permutation testing for map significance + FDR correction\n#   3) Save NIfTI + ROI summary CSV outputs\n#   4) Group contrast maps (SAD-HC, OXT-PLC)\n#   5) Progress bars for permutation loops\n\nprint(\"--- Running Cell 17: Searchlight RSM (CSR/CSS/CS-) ---\")\n\nimport os\nimport numpy as np\nimport nibabel as nib\nimport glob\nimport pandas as pd\nfrom scipy.spatial import cKDTree\nfrom scipy.stats import pearsonr\nfrom statsmodels.stats.multitest import multipletests\nfrom nilearn import plotting\nfrom tqdm import tqdm\n\n# =============================================================================\n# 0. Configuration\n# =============================================================================\nROI_DIR = \"/Users/xiaoqianxiao/tool/parcellation/Gillian_anatomically_constrained\"\nROI_ORDER = [\n    'left_acc', 'left_amygdala', 'left_hippocampus', 'left_insula', 'left_vmpfc',\n    'right_acc', 'right_amygdala', 'right_hippocampus', 'right_insula', 'right_vmpfc'\n]\n\nCOND_LIST = [\"CSR\", \"CSS\", \"CS-\"]\nSEARCH_RADIUS = 2.5  # in voxels\nMIN_VOXELS = 20\nN_PERMUTATION_SEARCHLIGHT = 200\nALPHA_FDR = 0.05\n\n# Output\nif 'project_root' in locals():\n    out_dir = os.path.join(project_root, \"MRI/derivatives/fMRI_analysis/LSS\", \"results\", \"searchlight_rsm\")\nelse:\n    out_dir = \"/tmp/searchlight_rsm\"\nos.makedirs(out_dir, exist_ok=True)\n\nGROUPS_TO_RUN = [\n    \"ALL\",\n    \"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"\n]\n\n\n# =============================================================================\n# RAW NPZ LOAD (force CS- availability)\n# =============================================================================\nLOAD_RAW_NPZ = True\nif LOAD_RAW_NPZ:\n    project_root = \"/Users/xiaoqianxiao/projects/NARSAD\"\n    data_root = os.path.join(project_root, \"MRI/derivatives/fMRI_analysis/LSS\", \"firstLevel\", \"all_subjects/fear_network\")\n    phase2_npz_path = os.path.join(data_root, \"phase2_X_ext_y_ext_roi_voxels.npz\")\n    phase3_npz_path = os.path.join(data_root, \"phase3_X_reinst_y_reinst_roi_voxels.npz\")\n\n    phase2 = np.load(phase2_npz_path, allow_pickle=True)\n    X_ext = phase2[\"X_ext\"]\n    y_ext = phase2[\"y_ext\"]\n    sub_ext = phase2[\"subjects\"]\n\n    phase3 = np.load(phase3_npz_path, allow_pickle=True)\n    X_reinst = phase3[\"X_reinst\"]\n    y_reinst = phase3[\"y_reinst\"]\n    sub_reinst = phase3[\"subjects\"]\n\n\n\n# =============================================================================\n# Subject ID normalization (align meta and subjects)\n# =============================================================================\n\ndef normalize_subject_id(s):\n    s_str = str(s).strip()\n    # handle numpy floats like 123.0\n    if s_str.endswith('.0') and s_str.replace('.', '').isdigit():\n        s_str = s_str[:-2]\n    # remove leading 'sub-' if present\n    if s_str.startswith('sub-'):\n        s_str = s_str[4:]\n    return s_str\n\n# =============================================================================\n# META LOAD (force group mapping)\n# =============================================================================\nmeta_path = os.path.join(project_root, \"MRI/source_data/behav/drug_order.csv\")\nmeta = pd.read_csv(meta_path)\nmeta['subject_id'] = meta['subject_id'].astype(str).str.strip()\nsub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n# Normalized lookup (strip sub-, handle numeric ids)\nsub_to_meta_norm = {normalize_subject_id(k): v for k, v in sub_to_meta.items()}\n\n\n# =============================================================================\n\n# =============================================================================\n# 1. Build ROI-based voxel mapping (feature index -> voxel coord)\n# =============================================================================\nprint(\"[Step 1] Building feature-to-voxel mapping...\")\n\nroi_paths = []\nfor name in ROI_ORDER:\n    matches = glob.glob(os.path.join(ROI_DIR, f\"*{name}*.nii*\"))\n    if not matches:\n        raise FileNotFoundError(f\"ROI mask not found for: {name}\")\n    roi_paths.append(matches[0])\n\nref_img = nib.load(roi_paths[0])\nref_shape = ref_img.shape\ncoords = []\nfeature_idx = 0\nroi_feature_idx = {}\n\nfor name, p in zip(ROI_ORDER, roi_paths):\n    mask_img = nib.load(p)\n    mask_data = mask_img.get_fdata() > 0\n    inds = np.column_stack(np.where(mask_data))\n    roi_inds = []\n    for xyz in inds:\n        coords.append(xyz)\n        roi_inds.append(feature_idx)\n        feature_idx += 1\n    roi_feature_idx[name] = np.array(roi_inds, dtype=int)\n\ncoords = np.array(coords)\nprint(f\"  > Total voxels in ROI union: {coords.shape[0]}\")\n\n# =============================================================================\n# 2. Collect phase data across groups\n# =============================================================================\nprint(\"[Step 2] Collecting phase data...\")\n\ndef collect_phase_data(phase_key, group_key=None):\n    # Always use raw arrays loaded in this cell (includes CS-)\n    if phase_key == \"ext\":\n        X_all, y_all, sub_all = X_ext, y_ext, sub_ext\n    else:\n        X_all, y_all, sub_all = X_reinst, y_reinst, sub_reinst\n\n    xs, ys, subs = [], [], []\n    if group_key is None or group_key == \"ALL\":\n        # no filtering, return all subjects\n        return X_all, y_all, sub_all\n\n    group_iter = [group_key]\n\n    def get_group_key(sub_id):\n        s_str = normalize_subject_id(sub_id)\n        conds = None\n        if 'sub_to_meta_norm' in globals():\n            if s_str in sub_to_meta_norm: conds = sub_to_meta_norm[s_str]\n            elif s_str in sub_to_meta: conds = sub_to_meta[s_str]\n        if conds:\n            return f\"{conds['Group']}_{conds['Drug']}\"\n        return None\n\n    subjects = np.unique(sub_all)\n    for grp in group_iter:\n        sel_subs = [s for s in subjects if get_group_key(s) == grp]\n        if not sel_subs:\n            continue\n        mask = np.isin(sub_all, sel_subs)\n        xs.append(X_all[mask])\n        ys.append(y_all[mask])\n        subs.append(sub_all[mask])\n\n    if not xs:\n        return None, None, None\n    return np.vstack(xs), np.concatenate(ys), np.concatenate(subs)\n\n\n# =============================================================================\n# 2.5 Diagnostics: Trial counts and subject coverage\n# =============================================================================\nprint(\"[Step 2.5] Diagnostics: trial counts per condition...\")\n\ndef diagnose_phase(phase_key):\n    for group_key in GROUPS_TO_RUN:\n        X_p, y_p, sub_p = collect_phase_data(phase_key, group_key=group_key)\n        if X_p is None:\n            print(f\"  ! {phase_key} missing for {group_key}\")\n            continue\n        print(f\"  [{group_key} | {phase_key}] total trials: {len(y_p)}\")\n        for cond in COND_LIST:\n            count = int(np.sum(y_p == cond))\n            print(f\"    - {cond}: {count}\")\n        # per-subject counts\n        subs = np.unique(sub_p)\n        ok_2 = {c: 0 for c in COND_LIST}\n        ok_4 = {c: 0 for c in COND_LIST}\n        for s in subs:\n            mask = sub_p == s\n            for c in COND_LIST:\n                n = int(np.sum(y_p[mask] == c))\n                if n >= 2:\n                    ok_2[c] += 1\n                if n >= 4:\n                    ok_4[c] += 1\n        print(\"    subjects with >=2 trials per condition:\")\n        print(\"      \" + \", \".join([f\"{c}:{ok_2[c]}\" for c in COND_LIST]))\n        print(\"    subjects with >=4 trials per condition (needed for early/late split):\")\n        print(\"      \" + \", \".join([f\"{c}:{ok_4[c]}\" for c in COND_LIST]))\n\n# Run diagnostics for both phases\nfor phase_key in [\"ext\", \"rst\"]:\n    diagnose_phase(phase_key)\n\n\nprint(\"[Step 2.6] Mapping diagnostics...\")\ntry:\n    sample_subs = list(dict.fromkeys([normalize_subject_id(s) for s in sub_ext]))[:5]\n    sample_meta = list(sub_to_meta_norm.keys())[:5]\n    print(f\"  sample subjects: {sample_subs}\")\n    print(f\"  sample meta keys: {sample_meta}\")\n    for g in [\"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"]:\n        subs = np.unique(sub_ext)\n        matched = [s for s in subs if get_group_key(s) == g]\n        print(f\"  matched {g}: {len(matched)}\")\nexcept Exception as e:\n    print(f\"  ! mapping diagnostics failed: {e}\")\n\n# =============================================================================\n# 3. Build early/late condition vectors per subject\n# =============================================================================\nprint(\"[Step 3] Building condition vectors (early/late)...\")\n\ndef build_stage_vectors(X, y, sub, stage):\n    # Returns list of per-subject condition matrices (3 x n_features)\n    subjects = np.unique(sub)\n    subj_mats = []\n\n    for s in subjects:\n        rows = []\n        for cond in COND_LIST:\n            idx = np.where((sub == s) & (y == cond))[0]\n            if len(idx) < 2:\n                rows = []\n                break\n            split = len(idx) // 2\n            if stage == \"early\":\n                use_idx = idx[:split]\n            else:\n                use_idx = idx[split:]\n            if len(use_idx) == 0:\n                rows = []\n                break\n            rows.append(np.mean(X[use_idx], axis=0))\n        if rows:\n            subj_mats.append(np.vstack(rows))  # 3 x n_features\n    return subj_mats\n\n# =============================================================================\n# 4. Precompute searchlight neighborhoods\n# =============================================================================\nprint(\"[Step 4] Precomputing searchlight neighborhoods...\")\n\ntree = cKDTree(coords)\nneighbors = tree.query_ball_point(coords, r=SEARCH_RADIUS)\n\n# =============================================================================\n# 5. Searchlight RSM computation\n# =============================================================================\nprint(\"[Step 5] Running searchlight RSM...\")\n\ndef rsm_score_for_sphere(cond_mat, feat_idx):\n    # Compute mean off-diagonal dissimilarity for a 3xF condition matrix\n    if len(feat_idx) < MIN_VOXELS:\n        return np.nan\n    A = cond_mat[:, feat_idx]\n    r01 = pearsonr(A[0], A[1])[0]\n    r02 = pearsonr(A[0], A[2])[0]\n    r12 = pearsonr(A[1], A[2])[0]\n    return np.mean([1 - r01, 1 - r02, 1 - r12])\n\n\ndef compute_searchlight_map(subj_mats):\n    if not subj_mats:\n        return None\n    n_centers = coords.shape[0]\n    vals = np.full(n_centers, np.nan)\n    for c in range(n_centers):\n        feat_idx = neighbors[c]\n        subj_scores = []\n        for m in subj_mats:\n            s = rsm_score_for_sphere(m, feat_idx)\n            if not np.isnan(s):\n                subj_scores.append(s)\n        if subj_scores:\n            vals[c] = float(np.mean(subj_scores))\n    return vals\n\n# =============================================================================\n# 6. Permutation testing + FDR\n# =============================================================================\nprint(\"[Step 6] Permutation testing setup...\")\n\ndef permute_labels_within_subject(y, sub, rng):\n    y_perm = y.copy()\n    for s in np.unique(sub):\n        idx = np.where(sub == s)[0]\n        y_perm[idx] = rng.permutation(y_perm[idx])\n    return y_perm\n\n\ndef permutation_null_maps(X, y, sub, stage, n_perm=200):\n    rng = np.random.default_rng(42)\n    null_maps = []\n    for _ in tqdm(range(n_perm), desc=f\"Permuting ({stage})\", leave=False):\n        y_perm = permute_labels_within_subject(y, sub, rng)\n        mats = build_stage_vectors(X, y_perm, sub, stage)\n        m = compute_searchlight_map(mats)\n        if m is not None:\n            null_maps.append(m)\n    if not null_maps:\n        return None\n    return np.array(null_maps)\n\n\ndef pvals_and_fdr(null_maps, obs_map):\n    pvals = np.mean(null_maps >= obs_map, axis=0)\n    pvals_flat = pvals[~np.isnan(pvals)]\n    rej, p_fdr, _, _ = multipletests(pvals_flat, alpha=ALPHA_FDR, method='fdr_bh')\n    p_fdr_full = np.full_like(pvals, np.nan, dtype=float)\n    p_fdr_full[~np.isnan(pvals)] = p_fdr\n    return pvals, p_fdr_full\n\n# =============================================================================\n# 7. Compute early/late maps and deltas (by group)\n# =============================================================================\nprint(\"[Step 7] Computing maps for Extinction and Reinstatement (by group)...\")\n\nresults_maps = {}\nresults_pvals = {}\nresults_fdr = {}\n\nfor group_key in GROUPS_TO_RUN:\n    for phase_key, phase_name in [(\"ext\", \"Extinction\"), (\"rst\", \"Reinstatement\")]:\n        X_p, y_p, sub_p = collect_phase_data(phase_key, group_key=group_key)\n        if X_p is None:\n            print(f\"  ! {phase_name} data missing for {group_key}. Skipping.\")\n            continue\n\n        early_mats = build_stage_vectors(X_p, y_p, sub_p, \"early\")\n        late_mats = build_stage_vectors(X_p, y_p, sub_p, \"late\")\n\n        map_early = compute_searchlight_map(early_mats)\n        map_late = compute_searchlight_map(late_mats)\n\n        if map_early is None or map_late is None:\n            print(f\"  ! Not enough data for {phase_name}, {group_key}.\")\n            continue\n\n        delta = map_late - map_early\n\n        results_maps[(group_key, phase_key, \"early\")] = map_early\n        results_maps[(group_key, phase_key, \"late\")] = map_late\n        results_maps[(group_key, phase_key, \"delta\")] = delta\n\n        # Permutation p-values + FDR for early and late\n        null_early = permutation_null_maps(X_p, y_p, sub_p, \"early\", n_perm=N_PERMUTATION_SEARCHLIGHT)\n        null_late = permutation_null_maps(X_p, y_p, sub_p, \"late\", n_perm=N_PERMUTATION_SEARCHLIGHT)\n\n        if null_early is not None:\n            p_early, fdr_early = pvals_and_fdr(null_early, map_early)\n            results_pvals[(group_key, phase_key, \"early\")] = p_early\n            results_fdr[(group_key, phase_key, \"early\")] = fdr_early\n        if null_late is not None:\n            p_late, fdr_late = pvals_and_fdr(null_late, map_late)\n            results_pvals[(group_key, phase_key, \"late\")] = p_late\n            results_fdr[(group_key, phase_key, \"late\")] = fdr_late\n\n# =============================================================================\n# 8. Group contrasts\n# =============================================================================\nprint(\"[Step 8] Computing group contrasts...\")\n\ncontrast_maps = {}\n\ndef get_map(group, phase, stage):\n    return results_maps.get((group, phase, stage))\n\nfor phase_key in [\"ext\", \"rst\"]:\n    for stage in [\"early\", \"late\", \"delta\"]:\n        m_sad = get_map(\"SAD_Placebo\", phase_key, stage)\n        m_hc = get_map(\"HC_Placebo\", phase_key, stage)\n        m_oxt = get_map(\"SAD_Oxytocin\", phase_key, stage)\n        m_plc = get_map(\"SAD_Placebo\", phase_key, stage)\n        if m_sad is not None and m_hc is not None:\n            contrast_maps[(\"SADminusHC\", phase_key, stage)] = m_sad - m_hc\n        if m_oxt is not None and m_plc is not None:\n            contrast_maps[(\"OXTminusPLC\", phase_key, stage)] = m_oxt - m_plc\n\n# =============================================================================\n# 9. Write NIfTI, plot, and save ROI summaries\n# =============================================================================\nprint(\"[Step 9] Saving NIfTI and ROI summaries...\")\n\ndef to_nifti(vals, ref_img):\n    data = np.zeros(ref_shape)\n    data[:] = np.nan\n    for idx, v in enumerate(vals):\n        x, y, z = coords[idx]\n        data[x, y, z] = v\n    return nib.Nifti1Image(data, ref_img.affine)\n\nroi_rows = []\n\n# Save main maps\nfor key, vals in results_maps.items():\n    group_key, phase_key, stage = key\n    img = to_nifti(vals, ref_img)\n    fname = f\"rsm_{group_key}_{phase_key}_{stage}.nii.gz\"\n    nib.save(img, os.path.join(out_dir, fname))\n\n    title = f\"RSM {group_key} {phase_key.upper()} - {stage}\"\n    plotting.plot_stat_map(img, title=title, display_mode='ortho', threshold=np.nanpercentile(vals, 90))\n\n    # ROI summary\n    for roi_name, idxs in roi_feature_idx.items():\n        roi_rows.append({\n            \"group\": group_key,\n            \"phase\": phase_key,\n            \"stage\": stage,\n            \"roi\": roi_name,\n            \"mean_rsm\": float(np.nanmean(vals[idxs]))\n        })\n\n# Save p-value and FDR maps\nfor key, pvals in results_pvals.items():\n    group_key, phase_key, stage = key\n    img = to_nifti(pvals, ref_img)\n    fname = f\"rsm_pvals_{group_key}_{phase_key}_{stage}.nii.gz\"\n    nib.save(img, os.path.join(out_dir, fname))\n\nfor key, fdr in results_fdr.items():\n    group_key, phase_key, stage = key\n    img = to_nifti(fdr, ref_img)\n    fname = f\"rsm_fdr_{group_key}_{phase_key}_{stage}.nii.gz\"\n    nib.save(img, os.path.join(out_dir, fname))\n\n# Save contrast maps\nfor key, vals in contrast_maps.items():\n    contrast_name, phase_key, stage = key\n    img = to_nifti(vals, ref_img)\n    fname = f\"rsm_{contrast_name}_{phase_key}_{stage}.nii.gz\"\n    nib.save(img, os.path.join(out_dir, fname))\n    title = f\"RSM {contrast_name} {phase_key.upper()} - {stage}\"\n    plotting.plot_stat_map(img, title=title, display_mode='ortho', threshold=np.nanpercentile(vals, 90))\n\n# Save ROI summary CSV\nroi_df = pd.DataFrame(roi_rows)\nroi_csv = os.path.join(out_dir, \"rsm_roi_summary.csv\")\nroi_df.to_csv(roi_csv, index=False)\n\nprint(f\"Cell 17 complete: outputs saved to {out_dir}\")\n",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
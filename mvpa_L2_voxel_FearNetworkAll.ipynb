{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 1: Imports & basic config\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedGroupKFold, StratifiedKFold, GroupKFold, permutation_test_score, LeaveOneGroupOut, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.utils import resample, shuffle, resample\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "from nilearn import plotting, image, masking\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, ttest_1samp, ttest_ind, entropy, kurtosis\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List, Union\n",
    "import plotly.graph_objects as go\n",
    "# Nice plotting defaults\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5   # GroupKFold folds\n",
    "INNER_CV_SPLITS = 5     \n",
    "CS_LABELS = [\"CS-\", \"CSS\", \"CSR\"]  # the three CS types of interest\n",
    "N_JOBS = 1\n",
    "MAX_ITER = 5000\n",
    "thresh_hold_p = 1 - 0.05\n",
    "N_PERMUTATION = 5000\n",
    "#N_PERMUTATION = 1\n",
    "#N_REPEATS = 10\n",
    "N_REPEATS = 10\n",
    "CROSSNOBIS_REPEATS = 50\n",
    "SUBJECT_CV_SPLITS = 5\n",
    "SUBJECT_INNER_SPLITS = 3\n",
    "CALIB_BINS = 5\n",
    "TOP_PCT = 95\n",
    "LOW_PCT = 5\n",
    "TWO_TAIL_LOW = 2.5\n",
    "TWO_TAIL_HIGH = 97.5\n",
    "MIN_TRIALS_PER_SUBJECT = 10\n",
    "C_MIN_EXP = -2\n",
    "C_MAX_EXP = 2\n",
    "C_POINTS = 20"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_c_for_sub(sub_id):\n",
    "    group = get_group_for_sub(sub_id)\n",
    "    if group == \"SAD\" and best_c_sad is not None:\n",
    "        return float(best_c_sad)\n",
    "    if group == \"HC\" and best_c_hc is not None:\n",
    "        return float(best_c_hc)\n",
    "    return 1.0\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Calculation Helper (Entropy, Kurtosis, Variance)\n",
    "# =============================================================================\n",
    "\n",
    "def get_group_for_sub(sub_id):\n",
    "    if 'sub_to_meta' not in locals():\n",
    "        return None\n",
    "    s_str = str(sub_id).strip()\n",
    "    conds = None\n",
    "    if s_str in sub_to_meta:\n",
    "        conds = sub_to_meta[s_str]\n",
    "    elif f\"sub-{s_str}\" in sub_to_meta:\n",
    "        conds = sub_to_meta[f\"sub-{s_str}\"]\n",
    "    elif s_str.replace(\"sub-\", \"\") in sub_to_meta:\n",
    "        conds = sub_to_meta[s_str.replace(\"sub-\", \"\")]\n",
    "    if conds:\n",
    "        return conds.get(\"Group\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 2: Load phase2 (extinction) and phase3 (reinstatement) data\n",
    "# Update: Filters FEATURES to include only specific ROIs (Amygdala, Hippocampus, Insula, vmPFC, ACC).\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"--- Cell 2: Data Loading & ROI Filtering ---\")\n",
    "\n",
    "project_root = \"/Users/xiaoqianxiao/projects/NARSAD\"\n",
    "data_root = os.path.join(project_root, \"MRI/derivatives/fMRI_analysis/LSS\", \"firstLevel\", \"all_subjects/fear_network\")\n",
    "phase2_npz_path = os.path.join(data_root, \"phase2_X_ext_y_ext_roi_voxels.npz\")\n",
    "phase3_npz_path = os.path.join(data_root, \"phase3_X_reinst_y_reinst_roi_voxels.npz\") # Note: using 'reinst' variable name\n",
    "\n",
    "# Define the specific ROIs to keep\n",
    "TARGET_ROIS = [\n",
    "    'left_acc', 'left_amygdala', 'left_hippocampus', 'left_insula', 'left_vmpfc',\n",
    "    'right_acc', 'right_amygdala', 'right_hippocampus', 'right_insula', 'right_vmpfc'\n",
    "]\n",
    "\n",
    "# Load Files\n",
    "phase2_npz = np.load(phase2_npz_path, allow_pickle=True)\n",
    "phase3_npz = np.load(phase3_npz_path, allow_pickle=True)\n",
    "\n",
    "# ---- Helper: ROI Feature Selection ----\n",
    "def filter_features_by_roi(X, roi_names, roi_counts, target_list):\n",
    "    \"\"\"\n",
    "    Creates a boolean mask for voxels belonging to target ROIs and filters X.\n",
    "    Returns: Filtered X, Filtered Parcel Names\n",
    "    \"\"\"\n",
    "    feature_mask = []\n",
    "    new_parcel_names = []\n",
    "    \n",
    "    # Iterate through each ROI metadata entry\n",
    "    for name, count in zip(roi_names, roi_counts):\n",
    "        # Create labels for this ROI (e.g., \"left_amygdala_0\")\n",
    "        current_labels = [f\"{name}_{i}\" for i in range(count)]\n",
    "        \n",
    "        if name in target_list:\n",
    "            # Keep these voxels\n",
    "            feature_mask.extend([True] * count)\n",
    "            new_parcel_names.extend(current_labels)\n",
    "        else:\n",
    "            # Drop these voxels\n",
    "            feature_mask.extend([False] * count)\n",
    "            \n",
    "    feature_mask = np.array(feature_mask)\n",
    "    \n",
    "    # Apply mask to columns (features)\n",
    "    if X.shape[1] != len(feature_mask):\n",
    "        raise ValueError(f\"Shape mismatch: X has {X.shape[1]} features, but ROI counts imply {len(feature_mask)}.\")\n",
    "        \n",
    "    X_filtered = X[:, feature_mask]\n",
    "    \n",
    "    return X_filtered, new_parcel_names\n",
    "\n",
    "# ---- Process Phase 2 (Extinction) ----\n",
    "X_ext_raw = phase2_npz[\"X_ext\"]\n",
    "y_ext = phase2_npz[\"y_ext\"]\n",
    "sub_ext = phase2_npz[\"subjects\"]\n",
    "roi_names_ext = phase2_npz[\"roi_names\"]\n",
    "roi_counts_ext = phase2_npz[\"roi_voxel_counts\"]\n",
    "\n",
    "print(f\"Original Extinction Shape: {X_ext_raw.shape}\")\n",
    "\n",
    "# Apply ROI Filter\n",
    "X_ext, parcel_names_ext = filter_features_by_roi(X_ext_raw, roi_names_ext, roi_counts_ext, TARGET_ROIS)\n",
    "print(f\"Filtered Extinction Shape: {X_ext.shape} (kept {len(TARGET_ROIS)} ROIs)\")\n",
    "\n",
    "\n",
    "# ---- Process Phase 3 (Reinstatement) ----\n",
    "X_reinst_raw = phase3_npz[\"X_reinst\"]\n",
    "y_reinst = phase3_npz[\"y_reinst\"]\n",
    "sub_reinst = phase3_npz[\"subjects\"]\n",
    "roi_names_reinst = phase3_npz[\"roi_names\"]\n",
    "roi_counts_reinst = phase3_npz[\"roi_voxel_counts\"]\n",
    "\n",
    "# Apply ROI Filter\n",
    "X_reinst, parcel_names_reinst = filter_features_by_roi(X_reinst_raw, roi_names_reinst, roi_counts_reinst, TARGET_ROIS)\n",
    "print(f\"Filtered Reinstatement Shape: {X_reinst.shape}\")\n",
    "\n",
    "\n",
    "# ---- Filter for CS Trials Only ----\n",
    "# Constants (Define if not present)\n",
    "if 'CS_LABELS' not in locals(): CS_LABELS = [\"CS-\", \"CSS\", \"CSR\"]\n",
    "\n",
    "# Keep only CS-, CSS, CSR trials\n",
    "mask_ext = np.isin(y_ext, CS_LABELS)\n",
    "mask_reinst = np.isin(y_reinst, CS_LABELS)\n",
    "\n",
    "X_ext = X_ext[mask_ext]\n",
    "y_ext = y_ext[mask_ext]\n",
    "sub_ext = sub_ext[mask_ext]\n",
    "\n",
    "X_reinst = X_reinst[mask_reinst]\n",
    "y_reinst = y_reinst[mask_reinst]\n",
    "sub_reinst = sub_reinst[mask_reinst]\n",
    "\n",
    "print(\"\\nAfter CS filtering:\")\n",
    "print(\"Phase2 (Ext):\", X_ext.shape, np.unique(y_ext, return_counts=True))\n",
    "print(\"Phase3 (Reinst):\", X_reinst.shape, np.unique(y_reinst, return_counts=True))\n",
    "print(f\"Target ROIs included: {TARGET_ROIS}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3: Load subject-level metadata (Group, Drug, etc.)\n",
    "\n",
    "# Example: a CSV with one row per subject, columns like:\n",
    "#   subject_id, Group, Drug, Age, Sex, ...\n",
    "# where Group \u2208 {SAD, HC}, Drug \u2208 {OT, PLC} or similar\n",
    "meta_path = os.path.join(project_root, \"MRI/source_data/behav/drug_order.csv\")\n",
    "\n",
    "meta = pd.read_csv(meta_path)\n",
    "\n",
    "print(meta.head())\n",
    "print(meta.columns)\n",
    "\n",
    "# Basic sanity check: make sure subjects in X_ext/X_reinst exist in metadata\n",
    "unique_subs_ext = np.unique(sub_ext)\n",
    "unique_subs_reinst = np.unique(sub_reinst)\n",
    "\n",
    "print(\"Phase2 unique subjects:\", len(unique_subs_ext))\n",
    "print(\"Phase3 unique subjects:\", len(unique_subs_reinst))\n",
    "\n",
    "missing_in_meta_ext = [s for s in unique_subs_ext if s not in set(meta[\"subject_id\"])]\n",
    "missing_in_meta_reinst = [s for s in unique_subs_reinst if s not in set(meta[\"subject_id\"])]\n",
    "\n",
    "print(\"Missing in meta (phase2):\", missing_in_meta_ext)\n",
    "print(\"Missing in meta (phase3):\", missing_in_meta_reinst)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# cell 4 helper functions\n",
    "# =============================================================================\n",
    "# 1. Pipeline & Preprocessing\n",
    "# =============================================================================\n",
    "param_grid = {\n",
    "    'classification__C': np.logspace(C_MIN_EXP, C_MAX_EXP, C_POINTS)\n",
    "}\n",
    "\n",
    "# # Variables to keep things clean\n",
    "# prev_best_c = 0.0045\n",
    "# # We combine a broad search with a dense local search\n",
    "# broad_search = np.logspace(-4, 2, 10) \n",
    "# dense_zoom = np.logspace(np.log10(prev_best_c) - 1, np.log10(prev_best_c) + 1, 20)\n",
    "\n",
    "# # Combine and sort to ensure a clean progression for the solver\n",
    "# refined_c_range = np.unique(np.sort(np.concatenate([broad_search, dense_zoom])))\n",
    "\n",
    "# param_grid = {\n",
    "#     'classification__C': refined_c_range\n",
    "# }\n",
    "\n",
    "# print(f\"Total points to test: {len(refined_c_range)}\")\n",
    "\n",
    "\n",
    "\n",
    "# SEARCH_RANGE_START = -5\n",
    "# SEARCH_RANGE_END = 3\n",
    "# N_POINTS = 30\n",
    "\n",
    "# param_grid = {\n",
    "#     'classification__C': np.logspace(SEARCH_RANGE_START, SEARCH_RANGE_END, N_POINTS)\n",
    "# }\n",
    "# Constants for the updated pipeline\n",
    "SOLVER_TYPE = 'saga'           # Required for 'elasticnet' penalty\n",
    "ELASTIC_PENALTY = 'elasticnet'\n",
    "MAX_ITER_SAGA = 10000  # Saga needs more iterations to converge\n",
    "\n",
    "\n",
    "def build_binary_pipeline():\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        ('classification', LogisticRegression(\n",
    "            penalty='l2', \n",
    "            solver='lbfgs', \n",
    "            class_weight='balanced', \n",
    "            max_iter=MAX_ITER, \n",
    "            random_state=RANDOM_STATE, \n",
    "            n_jobs=1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#------------------------------\n",
    "#--- Function: get_cv ---\n",
    "def get_cv(y, groups=None, n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE):\n",
    "    \"\"\"Return StratifiedGroupKFold if multiple groups exist; otherwise StratifiedKFold.\"\"\"\n",
    "    if groups is None or len(np.unique(groups)) < 2:\n",
    "        return StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=(random_state if shuffle else None))\n",
    "    return StratifiedGroupKFold(n_splits=n_splits, shuffle=shuffle, random_state=(random_state if shuffle else None))\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "#\n",
    "#--- Function: get_top_percentile_mask ---\n",
    "def run_cross_decoding(model, X, y, groups, classes=None):\n",
    "    \"\"\"\n",
    "    Applies a pre-trained model to a new dataset and computes subject-level\n",
    "    forced-choice accuracy.\n",
    "    \"\"\"\n",
    "    scores = model.decision_function(X)\n",
    "    return compute_subject_forced_choice_accs(y, scores, groups, model.classes_)\n",
    "def run_perm_simple(X, y, groups, n_iters):\n",
    "    \"\"\"\n",
    "    Runs permutation testing iterations for a single job using\n",
    "    trial-wise forced-choice accuracy.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    y_shuffled = y.copy()\n",
    "\n",
    "    pipe = build_binary_pipeline()\n",
    "    cv = get_cv(y, groups, n_splits=N_SPLITS, shuffle=False)\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        np.random.shuffle(y_shuffled)\n",
    "        cv_scores = cross_val_score(\n",
    "            pipe,\n",
    "            X,\n",
    "            y_shuffled,\n",
    "            groups=groups,\n",
    "            cv=cv,\n",
    "            scoring=forced_choice_scorer,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        scores.append(float(np.mean(cv_scores)))\n",
    "\n",
    "    return scores\n",
    "def run_cross_perm(model, X, y, subs, n_iter):\n",
    "    \"\"\"Cross-decoding permutation using trial-wise forced-choice accuracy.\"\"\"\n",
    "    null_scores = []\n",
    "    mask_c = np.isin(y, model.classes_)\n",
    "    X_f = X[mask_c]\n",
    "    y_f = y[mask_c]\n",
    "\n",
    "    scores = model.decision_function(X_f)\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        y_shuff = np.random.permutation(y_f)\n",
    "        null_scores.append(compute_forced_choice_accuracy(y_shuff, scores, model.classes_))\n",
    "    return np.array(null_scores)\n",
    "def run_spatial_perm(seed, maps, groups):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    shuffled = rng.permutation(groups)\n",
    "    w_sad_p = np.mean(maps[shuffled == \"SAD\"], axis=0)\n",
    "    w_hc_p = np.mean(maps[shuffled == \"HC\"], axis=0)\n",
    "    return cosine_similarity(w_sad_p.reshape(1, -1), w_hc_p.reshape(1, -1))[0][0]\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_pairwise_decoding_analysis ---\n",
    "def run_pairwise_decoding_analysis(X, y, subjects, n_repeats=10):\n",
    "    X = np.array(X); y = np.array(y); subjects = np.array(subjects)\n",
    "    \n",
    "    classes = np.unique(y); pairs = list(combinations(classes, 2)); results = {}\n",
    "    \n",
    "    print(f\"\\n=== Starting Repeated Pairwise Decoding ({len(pairs)} pairs, {n_repeats} repeats) ===\")\n",
    "    \n",
    "    for c1, c2 in pairs:\n",
    "        pair_name = f\"{c1} vs {c2}\"; print(f\"\\n--- Analysis: {pair_name} ---\")\n",
    "        mask = np.isin(y, [c1, c2]); X_pair = X[mask]; y_pair = y[mask]; sub_pair = subjects[mask]\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # PHASE 1: EVALUATION (Repeated Nested CV with Forced-Choice)\n",
    "        # ---------------------------------------------------------------------\n",
    "        all_repeat_scores = []\n",
    "        \n",
    "        for r in range(n_repeats):\n",
    "            # Use a different random_state for each repeat to get different splits\n",
    "            # Important: shuffle=True is required for the seed to change the split\n",
    "            gkf_outer = get_cv(y_pair, sub_pair, n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE + r)\n",
    "            \n",
    "            repeat_scores = []\n",
    "            print(f\"  > Repeat {r+1}/{n_repeats}...\")\n",
    "            \n",
    "            for i, (train_idx, test_idx) in enumerate(gkf_outer.split(X_pair, y_pair, groups=sub_pair), 1):\n",
    "                cv_inner = get_cv(y_pair[train_idx], sub_pair[train_idx], n_splits=INNER_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE + r)\n",
    "                # Inner loop for hyperparameter tuning\n",
    "                gs = GridSearchCV(build_binary_pipeline(), param_grid, cv=cv_inner, scoring=forced_choice_scorer, n_jobs=N_JOBS)\n",
    "                gs.fit(X_pair[train_idx], y_pair[train_idx], groups=sub_pair[train_idx])\n",
    "                \n",
    "                best_model = gs.best_estimator_\n",
    "                \n",
    "                # Forced-Choice logic on the Outer Test Fold\n",
    "                raw_val = best_model.decision_function(X_pair[test_idx])\n",
    "                scores_2d = np.column_stack((-raw_val, raw_val)) if raw_val.ndim == 1 else raw_val\n",
    "                \n",
    "                val_df = pd.DataFrame(scores_2d, columns=best_model.classes_)\n",
    "                val_df['sub'] = sub_pair[test_idx]\n",
    "                val_df['y'] = y_pair[test_idx]\n",
    "                mean_val = val_df.groupby(['sub', 'y']).mean().reset_index()\n",
    "                \n",
    "                fold_fc_acc = compute_pairwise_forced_choice(\n",
    "                    mean_val['y'].values, \n",
    "                    mean_val[best_model.classes_].values, \n",
    "                    best_model.classes_\n",
    "                )\n",
    "                repeat_scores.append(fold_fc_acc)\n",
    "            \n",
    "            all_repeat_scores.extend(repeat_scores)\n",
    "            \n",
    "        avg_cv_acc = np.mean(all_repeat_scores)\n",
    "        std_cv_acc = np.std(all_repeat_scores) # Total variance across all repeats/folds\n",
    "        print(f\"  > Final Mean Forced-Choice Accuracy ({n_repeats} repeats): {avg_cv_acc:.4f} (+/- {std_cv_acc:.4f})\")\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # PHASE 2: MODEL GENERATION (Refit on Full Data)\n",
    "        # ---------------------------------------------------------------------\n",
    "        # For the final model, we still refit once using a stable inner CV\n",
    "        print(\"  > Generating final model (Refit on full data for Haufe patterns)...\")\n",
    "        cv_inner_final = get_cv(y_pair, sub_pair, n_splits=INNER_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        gs_final = GridSearchCV(build_binary_pipeline(), param_grid, cv=cv_inner_final, scoring=forced_choice_scorer, n_jobs=N_JOBS)\n",
    "        gs_final.fit(X_pair, y_pair, groups=sub_pair)\n",
    "        \n",
    "        final_model = gs_final.best_estimator_\n",
    "        \n",
    "        # Haufe Pattern calculation (using variables for stability)\n",
    "        W = final_model.named_steps['classification'].coef_\n",
    "        X_scaled = X_pair\n",
    "        A = np.cov(X_scaled, rowvar=False) @ W.T \n",
    "        \n",
    "        results[pair_name] = {\n",
    "            'model': final_model,\n",
    "            'accuracy': avg_cv_acc, \n",
    "            'std': std_cv_acc,\n",
    "            'best_C': gs_final.best_params_['classification__C'], \n",
    "            'haufe_pattern': A.flatten(), \n",
    "            'classes': final_model.classes_\n",
    "        }\n",
    "    return results\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: plot_dist_with_thresh ---\n",
    "def plot_dist_with_thresh(null_dist, obs_val, ax, title, tail='upper', color='gray'):\n",
    "    # Fallback thresholds if globals not defined\n",
    "    one_tail_high = globals().get('ONE_TAIL_HIGH', 95)\n",
    "    one_tail_low = globals().get('ONE_TAIL_LOW', 5)\n",
    "    two_tail_low = globals().get('TWO_TAIL_LOW', 2.5)\n",
    "    two_tail_high = globals().get('TWO_TAIL_HIGH', 97.5)\n",
    "    sns.histplot(null_dist, color='gray', stat='density', kde=True, alpha=0.4, ax=ax, label='Null Dist')\n",
    "    ax.axvline(obs_val, color='red', lw=2.5, label=f'Obs: {obs_val:.2f}')\n",
    "    if tail == 'upper':\n",
    "        thresh = np.percentile(null_dist, one_tail_high)\n",
    "        ax.axvline(thresh, color='blue', ls='--', lw=2)\n",
    "        p_val = np.mean(null_dist >= obs_val)\n",
    "    elif tail == 'lower':\n",
    "        thresh = np.percentile(null_dist, one_tail_low)\n",
    "        ax.axvline(thresh, color='blue', ls='--', lw=2)\n",
    "        p_val = np.mean(null_dist <= obs_val)\n",
    "    elif tail == 'two-tailed':\n",
    "        t_low = np.percentile(null_dist, two_tail_low)\n",
    "        t_high = np.percentile(null_dist, two_tail_high)\n",
    "        ax.axvline(t_low, color='blue', ls='--', lw=2)\n",
    "        ax.axvline(t_high, color='blue', ls='--', lw=2)\n",
    "        p_val = 2 * min(np.mean(null_dist <= obs_val), np.mean(null_dist >= obs_val))\n",
    "    else:\n",
    "        raise ValueError(f'Unknown tail: {tail}')\n",
    "    ax.set_title(f\"{title}\\n(p = {p_val:.4f})\")\n",
    "    ax.legend(loc='best', fontsize='small')\n",
    "    return p_val\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: make_river_plot_importance ---\n",
    "def make_river_plot_importance(importance_dict, feature_names, top_k=20, title=\"Neural Signatures\"):\n",
    "    # (Same as before)\n",
    "    pass \n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_group_key ---\n",
    "def get_group_key(sub_id):\n",
    "    \"\"\"Returns 'Group_Drug' key (e.g., 'SAD_Placebo') for a subject ID.\"\"\"\n",
    "    s_str = str(sub_id).strip()\n",
    "    \n",
    "    # Try different ID formats\n",
    "    conds = None\n",
    "    if s_str in sub_to_meta: conds = sub_to_meta[s_str]\n",
    "    elif f\"sub-{s_str}\" in sub_to_meta: conds = sub_to_meta[f\"sub-{s_str}\"]\n",
    "    elif s_str.replace(\"sub-\", \"\") in sub_to_meta: conds = sub_to_meta[s_str.replace(\"sub-\", \"\")]\n",
    "    \n",
    "    if conds:\n",
    "        return f\"{conds['Group']}_{conds['Drug']}\"\n",
    "    return None\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: process_phase_data ---\n",
    "def process_phase_data(X_all, y_all, sub_all, phase_name):\n",
    "    print(f\"\\nProcessing {phase_name} Phase...\")\n",
    "    if X_all is None: return {k: None for k in group_keys}\n",
    "    \n",
    "    # Storage for results\n",
    "    grouped_data = {k: {'X': [], 'y': [], 'sub': []} for k in group_keys}\n",
    "    \n",
    "    # 1. Identify Unique Subjects\n",
    "    unique_subs = np.unique(sub_all)\n",
    "    print(f\"  > Found {len(unique_subs)} unique subjects.\")\n",
    "    \n",
    "    count_missing_meta = 0\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # 2. Get Group Key\n",
    "        g_key = get_group_key(sub)\n",
    "        if not g_key:\n",
    "            count_missing_meta += 1\n",
    "            continue\n",
    "            \n",
    "        # 3. Extract Subject's FULL Data\n",
    "        mask_sub = (sub_all == sub)\n",
    "        X_sub_full = X_all[mask_sub]\n",
    "        y_sub_full = y_all[mask_sub]\n",
    "        \n",
    "        # 4. CENTER DATA (Full Subject Mean)\n",
    "        #    We subtract the mean of ALL trials (CS+, CS-, etc.) to preserve true baseline\n",
    "        sub_mean = np.mean(X_sub_full, axis=0)\n",
    "        X_sub_centered = X_sub_full - sub_mean\n",
    "        \n",
    "        # 5. FILTER CONDITIONS (Keep only CSS / CSR)\n",
    "        mask_cond = np.isin(y_sub_full, [\"CSS\", \"CSR\"])\n",
    "        \n",
    "        if np.sum(mask_cond) > 0:\n",
    "            grouped_data[g_key]['X'].append(X_sub_centered[mask_cond])\n",
    "            grouped_data[g_key]['y'].append(y_sub_full[mask_cond])\n",
    "            # Create subject ID array matching the filtered length\n",
    "            grouped_data[g_key]['sub'].append(np.full(np.sum(mask_cond), sub))\n",
    "            \n",
    "    if count_missing_meta > 0:\n",
    "        print(f\"  ! Warning: {count_missing_meta} subjects missing metadata skipped.\")\n",
    "\n",
    "    # 6. Final Assembly\n",
    "    final_output = {}\n",
    "    for key in group_keys:\n",
    "        if len(grouped_data[key]['X']) > 0:\n",
    "            final_output[key] = {\n",
    "                \"X\": np.vstack(grouped_data[key]['X']),\n",
    "                \"y\": np.concatenate(grouped_data[key]['y']),\n",
    "                \"sub\": np.concatenate(grouped_data[key]['sub'])\n",
    "            }\n",
    "            n_sub = len(np.unique(final_output[key]['sub']))\n",
    "            print(f\"  [{key}] {phase_name}: {n_sub} subjects | Matrix: {final_output[key]['X'].shape}\")\n",
    "        else:\n",
    "            final_output[key] = None\n",
    "            print(f\"  [{key}] {phase_name}: No data.\")\n",
    "            \n",
    "    return final_output\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_extinction_data ---\n",
    "def get_extinction_data(group_key):\n",
    "    if group_key not in data_subsets:\n",
    "        raise ValueError(f\"Group {group_key} missing from data_subsets.\")\n",
    "    \n",
    "    phase_data = data_subsets[group_key]['ext']\n",
    "    if phase_data is None:\n",
    "        raise ValueError(f\"Extinction data missing for {group_key}.\")\n",
    "        \n",
    "    # X is already centered from Cell 5\n",
    "    return phase_data[\"X\"], phase_data[\"y\"], phase_data[\"sub\"]\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: reconstruct_roi_map ---\n",
    "def reconstruct_roi_map(flat_data, roi_names, roi_dir):\n",
    "    \"\"\"\n",
    "    Paints a 1D array of values back into a 3D brain volume by iterating \n",
    "    through the specific list of ROI masks.\n",
    "    \"\"\"\n",
    "    # 1. Determine Reference Space (Load first mask)\n",
    "    first_mask_path = glob.glob(os.path.join(roi_dir, f\"*{roi_names[0]}*.nii*\"))[0]\n",
    "    ref_img = nib.load(first_mask_path)\n",
    "    affine = ref_img.affine\n",
    "    final_vol = np.zeros(ref_img.shape)\n",
    "    \n",
    "    current_idx = 0\n",
    "    \n",
    "    # 2. Iterate and Paint\n",
    "    for name in roi_names:\n",
    "        # Find file (handle potential suffixes like .nii or .nii.gz)\n",
    "        fpaths = glob.glob(os.path.join(roi_dir, f\"*{name}*.nii*\"))\n",
    "        if not fpaths:\n",
    "            print(f\"  ! Error: Mask for '{name}' not found in {roi_dir}\")\n",
    "            return None\n",
    "        \n",
    "        mask_img = nib.load(fpaths[0])\n",
    "        mask_data = mask_img.get_fdata() > 0 # Boolean mask\n",
    "        n_voxels = np.sum(mask_data)\n",
    "        \n",
    "        # Check if we have enough data left\n",
    "        if current_idx + n_voxels > len(flat_data):\n",
    "            print(f\"  ! Error: Data mismatch. Feature vector too short for ROI {name}.\")\n",
    "            return None\n",
    "            \n",
    "        # Extract chunk and paint\n",
    "        roi_values = flat_data[current_idx : current_idx + n_voxels]\n",
    "        final_vol[mask_data] = roi_values # Place values in 3D space\n",
    "        \n",
    "        current_idx += n_voxels\n",
    "        \n",
    "    # Check if data was fully consumed\n",
    "    if current_idx != len(flat_data):\n",
    "         print(f\"  ! Warning: {len(flat_data) - current_idx} features were unused (Feature vector longer than ROIs).\")\n",
    "\n",
    "    return nib.Nifti1Image(final_vol, affine)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compute_haufe_binary_robust ---\n",
    "def compute_haufe_binary_robust(model, X):\n",
    "    scores = model.decision_function(X)\n",
    "    return np.dot((X - np.mean(X, axis=0)).T, scores - np.mean(scores)) / (X.shape[0] - 1)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_robust_weights ---\n",
    "def get_robust_weights(X, y, subjects, pipeline, n_boot=10):\n",
    "    unique_subs = np.unique(subjects)\n",
    "    accumulated_weights = np.zeros(X.shape[1])\n",
    "    for i in range(n_boot):\n",
    "        boot_subs = resample(unique_subs, replace=True, random_state=i)\n",
    "        X_boot_list, y_boot_list = [], []\n",
    "        for sub in boot_subs:\n",
    "            mask = (subjects == sub)\n",
    "            X_sub = X[mask]\n",
    "            X_boot_list.append(X_sub - np.mean(X_sub, axis=0))\n",
    "            y_boot_list.append(y[mask])\n",
    "        X_boot = np.vstack(X_boot_list)\n",
    "        y_boot = np.hstack(y_boot_list)\n",
    "        \n",
    "        clf = clone(pipeline)\n",
    "        clf.fit(X_boot, y_boot)\n",
    "        accumulated_weights += compute_haufe_binary_robust(clf, X_boot)\n",
    "    return accumulated_weights / n_boot\n",
    "\n",
    "##------------------------------\n",
    "\n",
    "#--- Function: run_wen_paper_analysis_voxelwise ---\n",
    "def run_wen_paper_analysis_voxelwise(X, y, subjects, pipeline_template, best_C, n_permutations):\n",
    "    print(f\"  Estimating Weights ({n_permutations} perms)...\")\n",
    "    pipe = clone(pipeline_template); pipe.set_params(classification__C=best_C)\n",
    "    obs_weights = get_robust_weights(X, y, subjects, pipe, n_boot=10)\n",
    "    \n",
    "    def run_null(i):\n",
    "        y_shuff = shuffle(y, random_state=i)\n",
    "        return get_robust_weights(X, y_shuff, subjects, pipe, n_boot=1)\n",
    "\n",
    "    null_weights_list = Parallel(n_jobs=N_JOBS, verbose=1)(delayed(run_null)(i) for i in range(n_permutations))\n",
    "    null_weights = np.array(null_weights_list)\n",
    "    \n",
    "    null_mean = np.mean(null_weights, axis=0)\n",
    "    null_std = np.std(null_weights, axis=0)\n",
    "    z_scores = (obs_weights - null_mean) / (null_std + 1e-12)\n",
    "    \n",
    "    n_extreme = np.sum(np.abs(null_weights) >= np.abs(obs_weights), axis=0)\n",
    "    p_values = (n_extreme + 1) / (n_permutations + 1)\n",
    "    reject, _, _, _ = multipletests(p_values, alpha=fdr_alpha, method='fdr_bh')\n",
    "    \n",
    "    return z_scores, reject\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compute_pairwise_forced_choice ---\n",
    "def _force_choice_scores_to_2d(scores: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Ensure decision scores are 2D (n_samples, n_classes).\"\"\"\n",
    "    scores_arr = np.asarray(scores)\n",
    "    if scores_arr.ndim == 1:\n",
    "        scores_arr = np.column_stack((-scores_arr, scores_arr))\n",
    "    return scores_arr\n",
    "\n",
    "\n",
    "def forced_choice_predict(scores: np.ndarray, classes: Sequence[str]) -> np.ndarray:\n",
    "    \"\"\"Predict class labels via forced-choice (argmax of decision scores).\"\"\"\n",
    "    scores_2d = _force_choice_scores_to_2d(scores)\n",
    "    class_arr = np.asarray(classes)\n",
    "    if scores_2d.shape[1] != class_arr.shape[0]:\n",
    "        raise ValueError(\"Decision scores do not match class labels.\")\n",
    "    return class_arr[np.argmax(scores_2d, axis=1)]\n",
    "\n",
    "\n",
    "def compute_forced_choice_accuracy(\n",
    "    y_true: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    classes: Sequence[str],\n",
    ") -> float:\n",
    "    \"\"\"Compute trial-wise forced-choice accuracy from decision scores.\"\"\"\n",
    "    y_pred = forced_choice_predict(scores, classes)\n",
    "    return float(np.mean(y_true == y_pred))\n",
    "\n",
    "\n",
    "def compute_subject_forced_choice_accs(\n",
    "    y_true: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    subjects: np.ndarray,\n",
    "    classes: Sequence[str],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute per-subject forced-choice accuracies from decision scores.\"\"\"\n",
    "    y_pred = forced_choice_predict(scores, classes)\n",
    "    accs = []\n",
    "    for sub in np.unique(subjects):\n",
    "        mask = subjects == sub\n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "        accs.append(float(np.mean(y_true[mask] == y_pred[mask])))\n",
    "    return np.array(accs)\n",
    "\n",
    "\n",
    "def forced_choice_scorer(estimator, X, y) -> float:\n",
    "    \"\"\"Scorer wrapper for GridSearchCV/cross_val_score.\"\"\"\n",
    "    scores = estimator.decision_function(X)\n",
    "    return compute_forced_choice_accuracy(y, scores, estimator.classes_)\n",
    "\n",
    "def compute_perm_importance_simple(model, X, y, n_repeats=10):\n",
    "    \"\"\"\n",
    "    Calculates permutation importance for a model.\n",
    "    Returns: Mean importance decrease per feature.\n",
    "    \"\"\"\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    # We use 'accuracy' as the scoring metric to see which voxels contribute to decoding\n",
    "    result = permutation_importance(\n",
    "        model, X, y, n_repeats=n_repeats, random_state=42, n_jobs=-1, scoring=forced_choice_scorer\n",
    "    )\n",
    "    \n",
    "    return result.importances_mean\n",
    "\n",
    "def compute_perm_importance_cv(\n",
    "    model_template,\n",
    "    X,\n",
    "    y,\n",
    "    groups,\n",
    "    n_repeats=10,\n",
    "    n_splits=5\n",
    "):\n",
    "    \"\"\"Cross-validated permutation importance.\n",
    "\n",
    "    Fits a cloned model on each training fold and computes permutation\n",
    "    importance on the corresponding test fold to estimate generalization.\n",
    "    \"\"\"\n",
    "    from sklearn.inspection import permutation_importance\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    groups = np.asarray(groups)\n",
    "\n",
    "    cv = get_cv(y, groups, n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    fold_importances = []\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y, groups=groups):\n",
    "        model = clone(model_template)\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        result = permutation_importance(\n",
    "            model,\n",
    "            X[test_idx],\n",
    "            y[test_idx],\n",
    "            n_repeats=n_repeats,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=1,\n",
    "            scoring=forced_choice_scorer\n",
    "        )\n",
    "        fold_importances.append(result.importances_mean)\n",
    "\n",
    "    return np.mean(fold_importances, axis=0)\n",
    "\n",
    "##------------------------------\n",
    "\n",
    "#--- Function: calculate_centroid_rdm ---\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: extract_metrics ---\n",
    "def extract_metrics(rdms):\n",
    "    # Metric A: Threat (CSR) vs Safety (CSS)\n",
    "    m_a = rdms[:, idx_csr, idx_css] \n",
    "    # Metric B: Safety (CSS) vs Baseline (CS-)\n",
    "    m_b = rdms[:, idx_css, idx_cs_minus] \n",
    "    return m_a, m_b\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: one_sample_test ---\n",
    "def one_sample_test(data, name):\n",
    "    # Test if distance is greater than 0\n",
    "    t_val, p_val = ttest_1samp(data, 0, alternative='greater')\n",
    "    sig = \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"  > {name}: Mean={np.mean(data):.3f}, t={t_val:.3f}, p={p_val:.4f} ({sig})\")\n",
    "    return p_val\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: perm_ttest_ind ---\n",
    "def perm_ttest_ind(data1, data2, n_perm=N_PERMUTATION):\n",
    "    \"\"\"\n",
    "    Performs a permutation t-test for two independent samples.\n",
    "    Returns: t-stat, p-value, mean1, mean2\n",
    "    \"\"\"\n",
    "    from scipy.stats import ttest_ind\n",
    "    \n",
    "    # 1. Calculate observed t-statistic\n",
    "    t_obs, _ = ttest_ind(data1, data2)\n",
    "    \n",
    "    # 2. Permutation loop\n",
    "    pooled = np.concatenate([data1, data2])\n",
    "    n1 = len(data1)\n",
    "    null_dist = []\n",
    "    \n",
    "    rng = np.random.default_rng(42) # Fixed seed\n",
    "    \n",
    "    for _ in range(n_perm):\n",
    "        shuffled = rng.permutation(pooled)\n",
    "        # Split into two groups of same size as originals\n",
    "        g1 = shuffled[:n1]\n",
    "        g2 = shuffled[n1:]\n",
    "        \n",
    "        # Calculate t-stat for shuffled data\n",
    "        t_shuff, _ = ttest_ind(g1, g2)\n",
    "        null_dist.append(t_shuff)\n",
    "        \n",
    "    null_dist = np.array(null_dist)\n",
    "    \n",
    "    # 3. Calculate P-value (Two-tailed)\n",
    "    # Proportion of null t-stats more extreme than observed t\n",
    "    p_val = np.mean(np.abs(null_dist) >= np.abs(t_obs))\n",
    "    \n",
    "    return t_obs, p_val, np.mean(data1), np.mean(data2)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_sig_star ---\n",
    "def get_sig_star(p): return \"*\" if p < 0.05 else \"ns\"\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_phase_data ---\n",
    "def get_phase_data(group, phase):\n",
    "    try:\n",
    "        d = data_subsets[group][phase]\n",
    "        if d is None: return None, None, None\n",
    "        return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "    except KeyError:\n",
    "        return None, None, None\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calculate_plasticity_vectors ---\n",
    "def calculate_plasticity_vectors(\n",
    "    X_learn, y_learn, sub_learn,   # Data for Learning Trajectory (Start -> End)\n",
    "    X_targ, y_targ, sub_targ,      # Data for Target Definition\n",
    "    feature_mask, \n",
    "    cond_learn,                    # Condition changing (e.g., CSS or CSR)\n",
    "    cond_target_label              # Label of the target (e.g., CS- or CSR)\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates projection of learning (in X_learn) onto axis towards Target (in X_targ).\n",
    "    \"\"\"\n",
    "    # 1. Apply Feature Mask & Centering\n",
    "    # Note: Center phases separately to remove global session shifts (drift correction)\n",
    "    \n",
    "    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n",
    "    res = {'sub': [], 'projection': [], 'cosine': [], 'init_dist': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # Slice Learning Data (The Drift)\n",
    "        m_l = (sub_learn == sub); xl = X_L[m_l]; yl = y_learn[m_l]\n",
    "        \n",
    "        # Slice Target Data (The Goal)\n",
    "        m_t = (sub_targ == sub); xt = X_T[m_t]; yt = y_targ[m_t]\n",
    "        \n",
    "        # A. Define Target Centroid (P_target)\n",
    "        mask_tgt_cond = (yt == cond_target_label)\n",
    "        if np.sum(mask_tgt_cond) == 0: continue\n",
    "        P_target = np.mean(xt[mask_tgt_cond], axis=0)\n",
    "        \n",
    "        # B. Define Start & End (Learning Phase)\n",
    "        mask_lrn_cond = (yl == cond_learn)\n",
    "        idx_lrn = np.where(mask_lrn_cond)[0]\n",
    "        if len(idx_lrn) < 2: continue\n",
    "        \n",
    "        cutoff = len(idx_lrn) // 2\n",
    "        # Early Learning\n",
    "        P_start = np.mean(xl[idx_lrn[:cutoff]], axis=0)\n",
    "        # Late Learning\n",
    "        P_end = np.mean(xl[idx_lrn[cutoff:]], axis=0)\n",
    "        \n",
    "        # C. Define Vectors\n",
    "        # Axis: From Start (Ext) -> Target (Reinstatement or CS-)\n",
    "        V_axis = P_target - P_start\n",
    "        # Drift: Actual change during learning\n",
    "        V_drift = P_end - P_start\n",
    "        \n",
    "        norm_axis = norm(V_axis)\n",
    "        norm_drift = norm(V_drift)\n",
    "        \n",
    "        if norm_axis == 0 or norm_drift == 0: continue\n",
    "        \n",
    "        dot_prod = np.dot(V_drift, V_axis)\n",
    "        \n",
    "        # Scalar Projection (Magnitude)\n",
    "        projection = dot_prod / norm_axis\n",
    "        \n",
    "        # Cosine Similarity (Fidelity)\n",
    "        cosine = dot_prod / (norm_drift * norm_axis)\n",
    "        \n",
    "        res['sub'].append(sub)\n",
    "        res['projection'].append(projection)\n",
    "        res['cosine'].append(cosine)\n",
    "        res['init_dist'].append(norm_axis)\n",
    "        \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: tag_df ---\n",
    "def tag_df(df, grp, cond):\n",
    "    if df.empty: return df\n",
    "    d = df.copy(); d['Group'] = grp; d['Condition'] = cond\n",
    "    return d\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_trajectory ---\n",
    "def calc_trajectory(\n",
    "    X_learn, y_learn, sub_learn,    # The trials we want to project (the \"Movie\")\n",
    "    X_targ, y_targ, sub_targ,       # The dataset containing the Goal State\n",
    "    mask, \n",
    "    cond_learn,                     # Condition to track (e.g., CSS)\n",
    "    cond_target_label               # Label of Goal State (e.g., CS- or CSR)\n",
    "):\n",
    "    # Center Data separately to remove session effects\n",
    "    \n",
    "    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n",
    "    res = {'sub': [], 'trial': [], 'score': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # 1. Get Subject Data\n",
    "        xl = X_L[sub_learn == sub]; yl = y_learn[sub_learn == sub]\n",
    "        xt = X_T[sub_targ == sub]; yt = y_targ[sub_targ == sub]\n",
    "        \n",
    "        # 2. Define Start Point (Early Learning)\n",
    "        # We define \"Start\" as the centroid of the FIRST HALF of the learning trials\n",
    "        mask_l = (yl == cond_learn)\n",
    "        trials_l = xl[mask_l]\n",
    "        if len(trials_l) < 2: continue\n",
    "        \n",
    "        cutoff = max(1, len(trials_l) // 2)\n",
    "        P_start = np.mean(trials_l[:cutoff], axis=0)\n",
    "        \n",
    "        # 3. Define Target Point\n",
    "        mask_t = (yt == cond_target_label)\n",
    "        if np.sum(mask_t) == 0: continue\n",
    "        P_target = np.mean(xt[mask_t], axis=0)\n",
    "        \n",
    "        # 4. Define Axis\n",
    "        V_axis = P_target - P_start\n",
    "        sq_norm = np.dot(V_axis, V_axis)\n",
    "        if sq_norm == 0: continue\n",
    "        \n",
    "        # 5. Project Each Trial\n",
    "        # Logic: Score = ((Trial - Start) . Axis) / ||Axis||^2\n",
    "        # This normalizes the progress: 0.0 = Start, 1.0 = Target\n",
    "        \n",
    "        # We center the trials relative to the Start Point of this specific axis\n",
    "        trials_centered = trials_l - P_start\n",
    "        \n",
    "        scores = np.dot(trials_centered, V_axis) / sq_norm\n",
    "        \n",
    "        for i, s in enumerate(scores):\n",
    "            res['sub'].append(sub)\n",
    "            res['trial'].append(i + 1)\n",
    "            res['score'].append(s)\n",
    "            \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_detailed_stats ---\n",
    "def run_detailed_stats(df_sad, df_hc, label):\n",
    "    if df_sad.empty or df_hc.empty: return pd.DataFrame()\n",
    "    \n",
    "    trials = sorted(list(set(df_sad['trial'].unique()) & set(df_hc['trial'].unique())))\n",
    "    results = []\n",
    "    \n",
    "    for t in trials:\n",
    "        s_vals = df_sad[df_sad['trial'] == t]['score'].values\n",
    "        h_vals = df_hc[df_hc['trial'] == t]['score'].values\n",
    "        \n",
    "        # A. SAD > 0\n",
    "        t_s, p_s = ttest_1samp(s_vals, 0, alternative='greater')\n",
    "        df_s = len(s_vals) - 1\n",
    "        \n",
    "        # B. HC > 0\n",
    "        t_h, p_h = ttest_1samp(h_vals, 0, alternative='greater')\n",
    "        df_h = len(h_vals) - 1\n",
    "        \n",
    "        # C. SAD != HC\n",
    "        t_d, p_d = ttest_ind(s_vals, h_vals)\n",
    "        df_d = len(s_vals) + len(h_vals) - 2\n",
    "        \n",
    "        results.append({\n",
    "            'Trial': t,\n",
    "            'SAD_t': t_s, 'SAD_df': df_s, 'SAD_p': p_s,\n",
    "            'HC_t': t_h, 'HC_df': df_h, 'HC_p': p_h,\n",
    "            'Diff_t': t_d, 'Diff_df': df_d, 'Diff_p': p_d\n",
    "        })\n",
    "        \n",
    "    stats_df = pd.DataFrame(results)\n",
    "    \n",
    "    # FDR Correction\n",
    "    if not stats_df.empty:\n",
    "        _, stats_df['SAD_p_fdr'], _, _ = multipletests(stats_df['SAD_p'], alpha=0.05, method='fdr_bh')\n",
    "        _, stats_df['HC_p_fdr'], _, _ = multipletests(stats_df['HC_p'], alpha=0.05, method='fdr_bh')\n",
    "        _, stats_df['Diff_p_fdr'], _, _ = multipletests(stats_df['Diff_p'], alpha=0.05, method='fdr_bh')\n",
    "        \n",
    "    print(f\"\\n--- Statistics: {label} ---\")\n",
    "    # Print significant trials (Diff)\n",
    "    sig_diff = stats_df[stats_df['Diff_p_fdr'] < 0.05]\n",
    "    if not sig_diff.empty:\n",
    "        print(\"Significant Group Differences (FDR < 0.05):\")\n",
    "        print(sig_diff[['Trial', 'Diff_t', 'Diff_df', 'Diff_p', 'Diff_p_fdr']].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant group differences found (FDR corrected).\")\n",
    "        \n",
    "    return stats_df\n",
    "\n",
    "###------------------------------\n",
    "\n",
    "#--- Function: prepare_plot ---\n",
    "def prepare_plot(df_sad, df_hc, name):\n",
    "    if df_sad.empty and df_hc.empty: return pd.DataFrame()\n",
    "    d_list = []\n",
    "    if not df_sad.empty:\n",
    "        d1 = df_sad.copy(); d1['Group'] = 'SAD'; d_list.append(d1)\n",
    "    if not df_hc.empty:\n",
    "        d2 = df_hc.copy();  d2['Group'] = 'HC'; d_list.append(d2)\n",
    "    \n",
    "    if not d_list: return pd.DataFrame()\n",
    "    \n",
    "    df = pd.concat(d_list)\n",
    "    df['Condition'] = name\n",
    "    # Bin trials if needed\n",
    "    if BLOCK_SIZE > 1:\n",
    "        df['trial'] = ((df['trial'] - 1) // BLOCK_SIZE) + 1\n",
    "    return df\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_significant_mask ---\n",
    "def get_significant_mask(scores): return scores > 0\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calculate_distribution_stats ---\n",
    "def calculate_distribution_stats(X, y, subjects, feature_mask, best_params_dict):\n",
    "    # Slice Features & Center\n",
    "    X_masked = X[:, feature_mask]\n",
    "    \n",
    "    unique_subs = np.unique(subjects)\n",
    "    res = {'sub': [], 'entropy': [], 'kurtosis': [], 'variance': [], 'probabilities': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        c_val = best_params_dict.get(sub, 1.0)\n",
    "        mask_sub = (subjects == sub)\n",
    "        X_sub = X_masked[mask_sub]; y_sub = y[mask_sub]\n",
    "        \n",
    "        # Filter Boundary Classes\n",
    "        mask_binary = np.isin(y_sub, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n",
    "        X_binary = X_sub[mask_binary]; y_binary = y_sub[mask_binary]\n",
    "        \n",
    "        if len(y_binary) < MIN_TRIALS_PER_SUBJECT: continue\n",
    "        \n",
    "        try:\n",
    "            # Configure Model\n",
    "            fixed_model = build_binary_pipeline()\n",
    "            fixed_model.set_params(classification__C=c_val)\n",
    "            \n",
    "            # Cross-Validation\n",
    "            cv = get_cv(y_binary, np.full(len(y_binary), sub), n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "            calib_model = CalibratedClassifierCV(\n",
    "                fixed_model,\n",
    "                method=\"sigmoid\",\n",
    "                cv=3\n",
    "            )\n",
    "            probs_all = cross_val_predict(calib_model, X_binary, y_binary, groups=np.full(len(y_binary), sub), cv=cv, method='predict_proba', n_jobs=1)\n",
    "            \n",
    "            # Extract Safety Cue Probabilities (P(Threat | Safety Cue))\n",
    "            classes = sorted(np.unique(y_binary))\n",
    "            if COND_CLASS_THREAT not in classes: continue\n",
    "            idx_threat = classes.index(COND_CLASS_THREAT)\n",
    "            \n",
    "            mask_css = (y_binary == COND_CLASS_SAFE)\n",
    "            if np.sum(mask_css) == 0: continue\n",
    "            probs_css = probs_all[mask_css, idx_threat]\n",
    "            \n",
    "            # Metrics\n",
    "            # 1. Entropy\n",
    "            p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n",
    "            trial_entropies = [entropy([p, 1-p], base=2) for p in p_clean]\n",
    "            \n",
    "            # 2. Kurtosis (Fisher's definition, Normal = 0.0)\n",
    "            k_val = kurtosis(probs_css, fisher=True)\n",
    "            \n",
    "            # 3. Variance\n",
    "            v_val = np.var(probs_css)\n",
    "            \n",
    "            res['sub'].append(sub)\n",
    "            res['entropy'].append(np.mean(trial_entropies))\n",
    "            res['kurtosis'].append(k_val)\n",
    "            res['variance'].append(v_val)\n",
    "            res['probabilities'].append(probs_css)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print(f\"  ! Subject {sub} failed: {e}\")\n",
    "            pass\n",
    "            \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: get_ext_data ---\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets: raise ValueError(f\"{group_key} missing.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: compare_metric ---\n",
    "def compare_metric(vec1, vec2, metric_name):\n",
    "    print(f\"\\n--- Metric: {metric_name} ---\")\n",
    "    if len(vec1) == 0 or len(vec2) == 0:\n",
    "        print(\"  ! Insufficient data.\")\n",
    "        return 1.0\n",
    "        \n",
    "    print(f\"  > SAD Mean: {np.mean(vec1):.3f}\")\n",
    "    print(f\"  > HC Mean:  {np.mean(vec2):.3f}\")\n",
    "    \n",
    "    t, p, _, _ = perm_ttest_ind(vec1, vec2, n_perm=N_PERMUTATION)\n",
    "    sig = \"*\" if p < 0.05 else \"ns\"\n",
    "    print(f\"  > Comparison: t={t:.3f}, p={p:.4f} ({sig})\")\n",
    "    return p\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: run_lme ---\n",
    "def run_lme(formula, data, title):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    # Groups='Subject' handles random intercepts per subject\n",
    "    # If design is between-subject, this converges to GLM/ANOVA but handles missingness better\n",
    "    md = smf.mixedlm(formula, data, groups=data[\"Subject\"]) \n",
    "    try:\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        \n",
    "        # Extract Interaction P-Value safely\n",
    "        term = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n",
    "        if term in mdf.pvalues:\n",
    "            p_val = mdf.pvalues[term]\n",
    "            print(f\"  >>> Interaction P-Value: {p_val:.5f} {'*' if p_val < 0.05 else ''}\")\n",
    "            return p_val\n",
    "        else:\n",
    "            print(\"  ! Interaction term not found in model results.\")\n",
    "            return 1.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ! Model Convergence Failed: {e}\")\n",
    "        return 1.0\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_drift_metrics ---\n",
    "def calc_drift_metrics(X_start_phase, y_start_phase, X_tgt_phase, y_tgt_phase, \n",
    "                       cond_start, cond_target, mask, sub_id):\n",
    "    # Mask & Center (Phase-wise centering)\n",
    "    X_s = X_start_phase[:, mask]\n",
    "    \n",
    "    X_t = X_tgt_phase[:, mask]\n",
    "    \n",
    "    # Target Centroid\n",
    "    mask_tgt = (y_tgt_phase == cond_target)\n",
    "    if np.sum(mask_tgt) < 2: return None\n",
    "    P_target = np.mean(X_t[mask_tgt], axis=0)\n",
    "    \n",
    "    # Trajectory\n",
    "    mask_lrn = (y_start_phase == cond_start)\n",
    "    idx_lrn = np.where(mask_lrn)[0]\n",
    "    if len(idx_lrn) < 4: return None\n",
    "    \n",
    "    cutoff = len(idx_lrn) // 2\n",
    "    P_start = np.mean(X_s[idx_lrn[:cutoff]], axis=0)\n",
    "    P_end = np.mean(X_s[idx_lrn[cutoff:]], axis=0)\n",
    "    \n",
    "    # Vectors\n",
    "    V_axis = P_target - P_start\n",
    "    V_drift = P_end - P_start\n",
    "    \n",
    "    nA, nD = norm(V_axis), norm(V_drift)\n",
    "    if nA == 0 or nD == 0: return None\n",
    "    \n",
    "    dot = np.dot(V_drift, V_axis)\n",
    "    return {'Cosine': dot / (nA * nD), 'Projection': dot / nA}\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: plot_interaction ---\n",
    "def plot_interaction(ax, df, domain, metric, p_val):\n",
    "    data = df[df[\"Domain\"] == domain]\n",
    "    if data.empty: return\n",
    "    \n",
    "    # Error bars = Standard Error (se)\n",
    "    # This approximates within-subject error visualization for group means\n",
    "    sns.pointplot(data=data, x='Drug', y=metric, hue='Group', \n",
    "                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "                  dodge=0.15, markers=['o', 's'], linestyles=['-', '--'], \n",
    "                  capsize=0.1, err_kws={'linewidth': 2.5}, scale=1.2, \n",
    "                  errorbar='se', ax=ax)\n",
    "    \n",
    "    ax.set_title(f\"{domain} - {metric}\")\n",
    "    ax.axhline(0, color='gray', ls='--', alpha=0.5)\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    \n",
    "    if p_val < 0.05:\n",
    "        ax.text(0.5, 0.9, f\"Interaction p={p_val:.3f}\", transform=ax.transAxes, \n",
    "                ha='center', fontweight='bold', color='black')\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_metrics_for_subject ---\n",
    "def calc_metrics_for_subject(X, y, sub_id, feature_mask, C_param=1.0):\n",
    "    # 1. Mask & Center\n",
    "    X_m = X[:, feature_mask]\n",
    "    \n",
    "    # 2. Filter Binary Classes\n",
    "    mask_bin = np.isin(y, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n",
    "    X_bin, y_bin = X_m[mask_bin], y[mask_bin]\n",
    "    \n",
    "    if len(y_bin) < MIN_TRIALS_PER_SUBJECT: return None\n",
    "    \n",
    "    try:\n",
    "        # 3. CV Probabilities\n",
    "        model = build_binary_pipeline()\n",
    "        model.set_params(classification__C=C_param)\n",
    "        cv = get_cv(y_binary, np.full(len(y_binary), sub), n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        calib_model = CalibratedClassifierCV(\n",
    "            model,\n",
    "            method=\"sigmoid\",\n",
    "            cv=3\n",
    "        )\n",
    "        probs_all = cross_val_predict(calib_model, X_bin, y_bin, groups=np.full(len(y_bin), sub_id), cv=cv, method='predict_proba', n_jobs=1)\n",
    "        \n",
    "        # 4. Extract Safety Cue Probabilities\n",
    "        classes = sorted(np.unique(y_bin))\n",
    "        if COND_CLASS_THREAT not in classes: return None\n",
    "        idx_threat = classes.index(COND_CLASS_THREAT)\n",
    "        \n",
    "        mask_css = (y_bin == COND_CLASS_SAFE)\n",
    "        if np.sum(mask_css) == 0: return None\n",
    "        \n",
    "        # Prob(Threat | Safety Cue)\n",
    "        probs_css = probs_all[mask_css, idx_threat]\n",
    "        \n",
    "        # --- Metrics ---\n",
    "        # A. Entropy (Uncertainty)\n",
    "        p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n",
    "        ents = [entropy([p, 1-p], base=2) for p in p_clean]\n",
    "        val_ent = np.mean(ents)\n",
    "        \n",
    "        # B. Kurtosis (Sharpness) - Fisher's (Normal=0)\n",
    "        val_kurt = kurtosis(probs_css, fisher=True)\n",
    "        \n",
    "        # C. Variance (Spread)\n",
    "        val_var = np.var(probs_css)\n",
    "        \n",
    "        return {'Entropy': val_ent, 'Kurtosis': val_kurt, 'Variance': val_var}\n",
    "        \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: plot_metric ---\n",
    "def plot_metric(ax, metric, p_val):\n",
    "    sns.pointplot(data=df_metrics, x='Drug', y=metric, hue='Group', \n",
    "                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "                  dodge=0.2, markers=['o', 's'], linestyles=['-', '--'], \n",
    "                  capsize=0.1, errorbar='se', scale=1.1, ax=ax)\n",
    "    \n",
    "    ax.set_title(f\"{metric}\")\n",
    "    ax.set_ylabel(metric)\n",
    "    if metric == \"Entropy\": ax.set_ylabel(\"Entropy (Uncertainty)\")\n",
    "    if metric == \"Kurtosis\": ax.set_ylabel(\"Kurtosis (Sharpness)\")\n",
    "    \n",
    "    # Annotate Significance\n",
    "    if p_val < 0.05:\n",
    "        ax.text(0.5, 0.9, f\"Interaction\\np={p_val:.3f}\", transform=ax.transAxes, \n",
    "                ha='center', fontweight='bold', color='black')\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#--- Function: calc_forced_choice_acc ---\n",
    "\n",
    "    # 2. Center (Subject-wise)\n",
    "    \n",
    "    # 3. Get Decision Values\n",
    "    scores = model.decision_function(X_f)\n",
    "    \n",
    "    # 4. Aggregate Scores per Subject\n",
    "    df_scores = pd.DataFrame({'sub': s_f, 'cond': y_f, 'score': scores})\n",
    "    means = df_scores.groupby(['sub', 'cond'])['score'].mean().unstack()\n",
    "    \n",
    "    valid_subs = means.dropna().index\n",
    "    means = means.loc[valid_subs]\n",
    "    \n",
    "    # 5. Calculate Accuracy\n",
    "    pos_idx = np.where(model.classes_ == COND_THREAT)[0][0]\n",
    "    accs = []\n",
    "    \n",
    "    for sub in means.index:\n",
    "        s_threat = means.loc[sub, COND_THREAT]\n",
    "        s_safe = means.loc[sub, COND_SAFE]\n",
    "        \n",
    "        if pos_idx == 1: correct = s_threat > s_safe\n",
    "        else: correct = s_threat < s_safe\n",
    "        accs.append(1.0 if correct else 0.0)\n",
    "        \n",
    "    return accs\n",
    "    \n",
    "print(\"Cell 4: Updated to use Pairwise Forced-Choice for evaluation.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# version 0\n",
    "# # Cell 5: Data Preparation & Subsetting (Optimized: Center -> Filter)\n",
    "# # Task: 1. Split data by subject.\n",
    "# #       2. Center FULL subject data (to preserve true baseline).\n",
    "# #       3. Filter for CSS/CSR conditions.\n",
    "# #       4. Organize into Groups (SAD/HC).\n",
    "\n",
    "# print(\"--- Cell 5: Data Preparation & Subsetting (Center -> Filter) ---\")\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # =============================================================================\n",
    "# # 0. Helper: Group Assignment Logic\n",
    "# # =============================================================================\n",
    "# if 'meta' in locals():\n",
    "#     # Standardize IDs\n",
    "#     meta['subject_id'] = meta['subject_id'].astype(str).str.strip()\n",
    "#     sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n",
    "#     print(f\"Metadata loaded for {len(sub_to_meta)} subjects.\")\n",
    "# else:\n",
    "#     raise ValueError(\"Metadata 'meta' not found. Please run Cell 3.\")\n",
    "\n",
    "# def get_group_key(sub_id):\n",
    "#     \"\"\"Returns 'Group_Drug' key (e.g., 'SAD_Placebo') for a subject ID.\"\"\"\n",
    "#     s_str = str(sub_id).strip()\n",
    "    \n",
    "#     # Try different ID formats\n",
    "#     conds = None\n",
    "#     if s_str in sub_to_meta: conds = sub_to_meta[s_str]\n",
    "#     elif f\"sub-{s_str}\" in sub_to_meta: conds = sub_to_meta[f\"sub-{s_str}\"]\n",
    "#     elif s_str.replace(\"sub-\", \"\") in sub_to_meta: conds = sub_to_meta[s_str.replace(\"sub-\", \"\")]\n",
    "    \n",
    "#     if conds:\n",
    "#         return f\"{conds['Group']}_{conds['Drug']}\"\n",
    "#     return None\n",
    "\n",
    "# # =============================================================================\n",
    "# # 1. Processing Logic (Subject-Wise Operation)\n",
    "# # =============================================================================\n",
    "# group_keys = [\"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"]\n",
    "\n",
    "# def process_phase_data(X_all, y_all, sub_all, phase_name):\n",
    "#     print(f\"\\nProcessing {phase_name} Phase...\")\n",
    "#     if X_all is None: return {k: None for k in group_keys}\n",
    "    \n",
    "#     # Storage for results\n",
    "#     grouped_data = {k: {'X': [], 'y': [], 'sub': []} for k in group_keys}\n",
    "    \n",
    "#     # 1. Identify Unique Subjects\n",
    "#     unique_subs = np.unique(sub_all)\n",
    "#     print(f\"  > Found {len(unique_subs)} unique subjects.\")\n",
    "    \n",
    "#     count_missing_meta = 0\n",
    "    \n",
    "#     for sub in unique_subs:\n",
    "#         # 2. Get Group Key\n",
    "#         g_key = get_group_key(sub)\n",
    "#         if not g_key:\n",
    "#             count_missing_meta += 1\n",
    "#             continue\n",
    "            \n",
    "#         # 3. Extract Subject's FULL Data\n",
    "#         mask_sub = (sub_all == sub)\n",
    "#         X_sub_full = X_all[mask_sub]\n",
    "#         y_sub_full = y_all[mask_sub]\n",
    "        \n",
    "#         # 4. CENTER DATA (Full Subject Mean)\n",
    "#         #    We subtract the mean of ALL trials (CS+, CS-, etc.) to preserve true baseline\n",
    "#         sub_mean = np.mean(X_sub_full, axis=0)\n",
    "#         X_sub_centered = X_sub_full - sub_mean\n",
    "        \n",
    "#         # 5. FILTER CONDITIONS (Keep only CSS / CSR)\n",
    "#         mask_cond = np.isin(y_sub_full, [\"CSS\", \"CSR\"])\n",
    "        \n",
    "#         if np.sum(mask_cond) > 0:\n",
    "#             grouped_data[g_key]['X'].append(X_sub_centered[mask_cond])\n",
    "#             grouped_data[g_key]['y'].append(y_sub_full[mask_cond])\n",
    "#             # Create subject ID array matching the filtered length\n",
    "#             grouped_data[g_key]['sub'].append(np.full(np.sum(mask_cond), sub))\n",
    "            \n",
    "#     if count_missing_meta > 0:\n",
    "#         print(f\"  ! Warning: {count_missing_meta} subjects missing metadata skipped.\")\n",
    "\n",
    "#     # 6. Final Assembly\n",
    "#     final_output = {}\n",
    "#     for key in group_keys:\n",
    "#         if len(grouped_data[key]['X']) > 0:\n",
    "#             final_output[key] = {\n",
    "#                 \"X\": np.vstack(grouped_data[key]['X']),\n",
    "#                 \"y\": np.concatenate(grouped_data[key]['y']),\n",
    "#                 \"sub\": np.concatenate(grouped_data[key]['sub'])\n",
    "#             }\n",
    "#             n_sub = len(np.unique(final_output[key]['sub']))\n",
    "#             print(f\"  [{key}] {phase_name}: {n_sub} subjects | Matrix: {final_output[key]['X'].shape}\")\n",
    "#         else:\n",
    "#             final_output[key] = None\n",
    "#             print(f\"  [{key}] {phase_name}: No data.\")\n",
    "            \n",
    "#     return final_output\n",
    "\n",
    "# # =============================================================================\n",
    "# # 2. Variable Detection\n",
    "# # =============================================================================\n",
    "# if 'X_ext' not in locals(): raise ValueError(\"X_ext missing. Run Cell 2.\")\n",
    "    \n",
    "# # Handle Reinstatement variable naming\n",
    "# if 'X_rst' in locals():\n",
    "#     X_rein, y_rein, sub_rein = X_rst, y_rst, sub_rst\n",
    "# elif 'X_reinst' in locals():\n",
    "#     X_rein, y_rein, sub_rein = X_reinst, y_reinst, sub_reinst\n",
    "# else:\n",
    "#     print(\"  ! Reinstatement data missing.\")\n",
    "#     X_rein, y_rein, sub_rein = None, None, None\n",
    "\n",
    "# # =============================================================================\n",
    "# # 3. Execute\n",
    "# # =============================================================================\n",
    "# ext_subsets = process_phase_data(X_ext, y_ext, sub_ext, \"Extinction\")\n",
    "# rst_subsets = process_phase_data(X_rein, y_rein, sub_rein, \"Reinstatement\")\n",
    "\n",
    "# # Structure Results\n",
    "# data_subsets = {}\n",
    "# for key in group_keys:\n",
    "#     data_subsets[key] = {\n",
    "#         \"ext\": ext_subsets.get(key),\n",
    "#         \"rst\": rst_subsets.get(key)\n",
    "#     }\n",
    "\n",
    "# print(\"\\nCell 5 Complete. Data is Centered (Full-Session) and Filtered.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 5: Data Preparation & Subsetting (Optimized: Center -> Filter)\n",
    "# Task: 1. Split data by subject.\n",
    "#       2. Center FULL subject data (to preserve true baseline).\n",
    "#       3. Filter for CSS/CSR conditions.\n",
    "#       4. Organize into Groups (SAD/HC).\n",
    "\n",
    "print(\"--- Cell 5: Data Preparation & Subsetting (Center -> Filter) ---\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Helper: Group Assignment Logic\n",
    "# =============================================================================\n",
    "if 'meta' in locals():\n",
    "    # Standardize IDs\n",
    "    meta['subject_id'] = meta['subject_id'].astype(str).str.strip()\n",
    "    sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n",
    "    print(f\"Metadata loaded for {len(sub_to_meta)} subjects.\")\n",
    "else:\n",
    "    raise ValueError(\"Metadata 'meta' not found. Please run Cell 3.\")\n",
    "\n",
    "group_keys = [\"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"]\n",
    "\n",
    "if 'X_ext' not in locals(): raise ValueError(\"X_ext missing. Run Cell 2.\")\n",
    "    \n",
    "# Handle Reinstatement variable naming\n",
    "if 'X_rst' in locals():\n",
    "    X_rein, y_rein, sub_rein = X_rst, y_rst, sub_rst\n",
    "elif 'X_reinst' in locals():\n",
    "    X_rein, y_rein, sub_rein = X_reinst, y_reinst, sub_reinst\n",
    "else:\n",
    "    print(\"  ! Reinstatement data missing.\")\n",
    "    X_rein, y_rein, sub_rein = None, None, None\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Execute\n",
    "# =============================================================================\n",
    "ext_subsets = process_phase_data(X_ext, y_ext, sub_ext, \"Extinction\")\n",
    "rst_subsets = process_phase_data(X_rein, y_rein, sub_rein, \"Reinstatement\")\n",
    "\n",
    "# Structure Results\n",
    "data_subsets = {}\n",
    "for key in group_keys:\n",
    "    data_subsets[key] = {\n",
    "        \"ext\": ext_subsets.get(key),\n",
    "        \"rst\": rst_subsets.get(key)\n",
    "    }\n",
    "\n",
    "print(\"\\nCell 5 Complete. Data is Centered (Full-Session) and Filtered.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 6: Analysis 1.1 - Neural Dissociation Execution\n",
    "# Protocol: SAD -> HC\n",
    "# Updates:\n",
    "#   - Uses 'run_pairwise_decoding_analysis' (Forced-Choice Accuracy).\n",
    "#   - Functional Specificity Heatmap uses Mean CV Accuracy for diagonals (Evaluation).\n",
    "#   - Cross-Decoding uses the 'final_model' (Refitted on full data) on the other group.\n",
    "#   - Hyperparameter selected from 20 values (0.01-100) using training data only.\n",
    "#   - 5-fold CV, repeated 10 times with different splits; mean performance reported.\n",
    "#   - Forced-choice accuracy used to mitigate inter-site activation differences.\n",
    "\n",
    "print(\"--- Running Analysis 1.1: Neural Dissociation ---\")\n",
    "\n",
    "target_param = 'classification__C'  # Variable for the hyperparameter key\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Data Slicing\n",
    "# =============================================================================\n",
    "# Load Data\n",
    "try:\n",
    "    X_hc, y_hc, sub_hc = get_extinction_data(\"HC_Placebo\")\n",
    "    X_sad, y_sad, sub_sad = get_extinction_data(\"SAD_Placebo\")\n",
    "    print(f\"Data Loaded: SAD (n={len(np.unique(sub_sad))}), HC (n={len(np.unique(sub_hc))})\")\n",
    "except ValueError as e:\n",
    "    print(f\"CRITICAL ERROR: {e}\")\n",
    "    raise\n",
    "\n",
    "# =============================================================================\n",
    "# TEST 1: Baseline Neural Discriminability (Self-Decoding)\n",
    "# =============================================================================\n",
    "print(\"\\n--- TEST 1: Baseline Neural Discriminability ---\")\n",
    "\n",
    "print(\"Processing SAD...\")\n",
    "res_sad_dict = run_pairwise_decoding_analysis(X_sad, y_sad, sub_sad, n_repeats=N_REPEATS)\n",
    "best_c_sad = res_sad_dict[list(res_sad_dict.keys())[0]]['model'].get_params()[target_param]\n",
    "print(f\"  > Best {target_param} for SAD: {best_c_sad}\")\n",
    "\n",
    "print(\"Processing HC...\")\n",
    "res_hc_dict = run_pairwise_decoding_analysis(X_hc, y_hc, sub_hc, n_repeats=N_REPEATS)\n",
    "best_c_hc = res_hc_dict[list(res_hc_dict.keys())[0]]['model'].get_params()[target_param]\n",
    "print(f\"  > Best {target_param} for HC: {best_c_hc}\")\n",
    "\n",
    "# Select the target contrast (CSS vs CSR)\n",
    "pair_key = \"CSR vs CSS\" if \"CSR vs CSS\" in res_sad_dict else \"CSS vs CSR\"\n",
    "if pair_key not in res_sad_dict or pair_key not in res_hc_dict:\n",
    "    raise ValueError(f\"Contrast {pair_key} not found. Check if CSS/CSR labels exist.\")\n",
    "\n",
    "res_sad = res_sad_dict[pair_key]\n",
    "res_hc = res_hc_dict[pair_key]\n",
    "\n",
    "# Permutation Test (Comparing Observed CV Score against Null CV Scores)\n",
    "print(f\"Running Permutation Test (Self-Decoding, {N_PERMUTATION} iter)...\")\n",
    "iters_per_job = N_PERMUTATION // N_JOBS\n",
    "perm_acc_sad = np.concatenate(Parallel(n_jobs=N_JOBS)(delayed(run_perm_simple)(X_sad, y_sad, sub_sad, iters_per_job) for _ in range(N_JOBS)))\n",
    "perm_acc_hc = np.concatenate(Parallel(n_jobs=N_JOBS)(delayed(run_perm_simple)(X_hc, y_hc, sub_hc, iters_per_job) for _ in range(N_JOBS)))\n",
    "\n",
    "# =============================================================================\n",
    "# TEST 2: Functional Specificity (Cross-Decoding)\n",
    "# =============================================================================\n",
    "print(\"\\n--- TEST 2: Functional Specificity ---\")\n",
    "# Logic: Use Final Refit Model (Trained on All A) -> Predict All B -> Avg Subject Accuracy\n",
    "\n",
    "# A. SAD Model -> HC Data\n",
    "model_sad = res_sad['model'] # This is the Refit model\n",
    "# 'run_cross_decoding' calculates raw accuracy per subject\n",
    "accs_sad2hc = run_cross_decoding(model_sad, X_hc, y_hc, sub_hc, model_sad.classes_)\n",
    "mean_sad2hc = np.mean(accs_sad2hc)\n",
    "print(f\"  > SAD Model -> HC Data: {mean_sad2hc:.4f}\")\n",
    "\n",
    "# B. HC Model -> SAD Data\n",
    "model_hc = res_hc['model']\n",
    "accs_hc2sad = run_cross_decoding(model_hc, X_sad, y_sad, sub_sad, model_hc.classes_)\n",
    "mean_hc2sad = np.mean(accs_hc2sad)\n",
    "print(f\"  > HC Model -> SAD Data: {mean_hc2sad:.4f}\")\n",
    "\n",
    "# Permutation Test (Cross-Decoding)\n",
    "print(f\"Running Permutation Test (Cross-Decoding, {N_PERMUTATION} iter)...\")\n",
    "perm_sad2hc = np.concatenate(Parallel(n_jobs=N_JOBS)(\n",
    "    delayed(run_cross_perm)(model_sad, X_hc, y_hc, sub_hc, iters_per_job) for _ in range(N_JOBS)))\n",
    "p_sad2hc = np.mean(perm_sad2hc >= mean_sad2hc)\n",
    "\n",
    "perm_hc2sad = np.concatenate(Parallel(n_jobs=N_JOBS)(\n",
    "    delayed(run_cross_perm)(model_hc, X_sad, y_sad, sub_sad, iters_per_job) for _ in range(N_JOBS)))\n",
    "p_hc2sad = np.mean(perm_hc2sad >= mean_hc2sad)\n",
    "\n",
    "# =============================================================================\n",
    "# TEST 3: Spatial Specificity\n",
    "# =============================================================================\n",
    "print(\"\\n--- TEST 3: Spatial Specificity ---\")\n",
    "map_sad, map_hc = res_sad['haufe_pattern'], res_hc['haufe_pattern']\n",
    "obs_sim = cosine_similarity(map_sad.reshape(1, -1), map_hc.reshape(1, -1))[0][0]\n",
    "\n",
    "# Prepare Data for Permutation (Combine groups)\n",
    "X_comb = np.concatenate([X_sad, X_hc])\n",
    "y_comb = np.concatenate([y_sad, y_hc])\n",
    "sub_comb = np.concatenate([sub_sad, sub_hc])\n",
    "\n",
    "all_sub_maps, all_sub_groups = [], []\n",
    "perm_pipe = build_binary_pipeline(); perm_pipe.set_params(classification__C=1.0)\n",
    "\n",
    "# Pre-compute subject maps\n",
    "print(f\"Pre-computing {len(np.unique(sub_comb))} individual subject maps...\")\n",
    "for sub in np.unique(sub_comb):\n",
    "    mask = sub_comb == sub\n",
    "    perm_pipe.fit(X_comb[mask], y_comb[mask])\n",
    "    W = perm_pipe.named_steps['classification'].coef_\n",
    "    # Calculate Covariance (Scaler handles centered input)\n",
    "    cov = np.cov(X_comb[mask], rowvar=False)\n",
    "    A = cov @ W.T\n",
    "    \n",
    "    if perm_pipe.classes_[1] == 'CSS': A = -A \n",
    "    all_sub_maps.append(A.flatten())\n",
    "    all_sub_groups.append(\"SAD\" if sub in sub_sad else \"HC\")\n",
    "\n",
    "# Run Spatial Permutation\n",
    "print(f\"Running Spatial Permutation ({N_PERMUTATION} iter)...\")\n",
    "perm_sims = np.array(Parallel(n_jobs=N_JOBS)(delayed(run_spatial_perm)(i, np.array(all_sub_maps), np.array(all_sub_groups)) for i in range(N_PERMUTATION)))\n",
    "\n",
    "p_sim_spatial = 2 * min(np.mean(perm_sims <= obs_sim), np.mean(perm_sims >= obs_sim))\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION\n",
    "# =============================================================================\n",
    "print(\"\\n--- Generating Plots ---\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(2, 2, height_ratios=[1, 1.2])\n",
    "\n",
    "# Row 1: Self-Decoding (Permutation Distribution)\n",
    "p_sad = plot_dist_with_thresh(perm_acc_sad, res_sad['accuracy'], fig.add_subplot(gs[0, 0]), \n",
    "                              f\"SAD Self-Decoding (CV Acc: {res_sad['accuracy']:.2f})\")\n",
    "p_hc = plot_dist_with_thresh(perm_acc_hc, res_hc['accuracy'], fig.add_subplot(gs[0, 1]), \n",
    "                             f\"HC Self-Decoding (CV Acc: {res_hc['accuracy']:.2f})\")\n",
    "\n",
    "# Row 2: Matrices\n",
    "# Functional Specificity\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "# Matrix: [CV Accuracy] vs [Mean Cross Accuracy]\n",
    "# Diagonals: Generalization within group (CV)\n",
    "# Off-Diagonals: Generalization across groups (Cross-Decoding)\n",
    "func_matrix = np.array([\n",
    "    [res_sad['accuracy'], mean_sad2hc], \n",
    "    [mean_hc2sad, res_hc['accuracy']]\n",
    "])\n",
    "func_pvals = np.array([[p_sad, p_sad2hc], [p_hc2sad, p_hc]])\n",
    "\n",
    "annot_func = np.empty_like(func_matrix, dtype=object)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        val_str = f\"{func_matrix[i, j]:.3f}\"\n",
    "        sig_str = \"*\" if func_pvals[i, j] < 0.05 else \"\"\n",
    "        annot_func[i, j] = f\"{val_str}\\n({sig_str})\"\n",
    "\n",
    "sns.heatmap(func_matrix, annot=annot_func, fmt=\"\", cmap=\"RdBu_r\", center=0.5, vmin=0.3, vmax=0.9, cbar=True,\n",
    "            xticklabels=['Test SAD', 'Test HC'], yticklabels=['Train SAD', 'Train HC'], ax=ax3)\n",
    "ax3.set_title(\"Functional Specificity\\n(Forced-Choice Accuracy)\")\n",
    "\n",
    "# Spatial Specificity\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "spatial_matrix = np.array([[1.0, obs_sim], [obs_sim, 1.0]])\n",
    "spatial_pvals = np.array([[0.0, p_sim_spatial], [p_sim_spatial, 0.0]])\n",
    "annot_spatial = np.empty_like(spatial_matrix, dtype=object)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        star = \"*\" if (spatial_pvals[i, j] < 0.05 and i != j) else \"\"\n",
    "        annot_spatial[i, j] = f\"{spatial_matrix[i, j]:.3f}\\n{star}\"\n",
    "\n",
    "sns.heatmap(spatial_matrix, annot=annot_spatial, fmt=\"\", cmap=\"RdBu_r\", center=0, vmin=-1, vmax=1, cbar=True,\n",
    "            xticklabels=['SAD Map', 'HC Map'], yticklabels=['SAD Map', 'HC Map'], ax=ax4)\n",
    "ax4.set_title(\"Spatial Specificity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save Results\n",
    "results_11 = {\n",
    "    \"acc_sad_cv\": res_sad['accuracy'], \n",
    "    \"p_sad\": p_sad, \n",
    "    \"acc_hc_cv\": res_hc['accuracy'], \n",
    "    \"p_hc\": p_hc, \n",
    "    \"func_matrix\": func_matrix, \n",
    "    \"sim_spatial\": obs_sim, \n",
    "    \"p_sim\": p_sim_spatial,\n",
    "    \"map_sad\": map_sad, \n",
    "    \"map_hc\": map_hc\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # Whole-brain version\n",
    "# # Cell 7: Voxel-wise Spatial Topology & Visualization\n",
    "# # Context: Voxel-wise analysis using Haufe Transforms & Permutation Testing.\n",
    "# # Fix: Loads specific ROI mask if available, or handles unmasking errors gracefully.\n",
    "\n",
    "# print(\"--- Cell 7: Running Voxel-wise Spatial Analysis ---\")\n",
    "\n",
    "# import os\n",
    "# import nibabel as nib\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from nilearn import plotting, image, masking\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# from sklearn.base import clone\n",
    "# from sklearn.utils import resample, shuffle\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# # =============================================================================\n",
    "# # 0. Setup & Dependency Check\n",
    "# # =============================================================================\n",
    "# # 1. Check for Results\n",
    "# if 'res_sad' not in locals() or 'res_hc' not in locals():\n",
    "#     raise ValueError(\"Analysis results ('res_sad', 'res_hc') not found. Please run Cell 6 first.\")\n",
    "\n",
    "# # 2. Check for Data\n",
    "# if 'X_sad' not in locals():\n",
    "#     print(\"Loading data from 'data_subsets'...\")\n",
    "#     try:\n",
    "#         d_s = data_subsets[\"SAD_Placebo\"][\"ext\"]\n",
    "#         d_h = data_subsets[\"HC_Placebo\"][\"ext\"]\n",
    "#         X_sad, y_sad, sub_sad = d_s[\"X\"], d_s[\"y\"], d_s[\"sub\"]\n",
    "#         X_hc, y_hc, sub_hc = d_h[\"X\"], d_h[\"y\"], d_h[\"sub\"]\n",
    "#     except Exception:\n",
    "#         raise ValueError(\"Data missing. Please run Cell 5.\")\n",
    "\n",
    "# # 3. MASK HANDLING (CRITICAL FIX)\n",
    "# # We need the mask that matches X_sad.shape[1]\n",
    "# # Option A: Try to find a specific ROI mask in data root\n",
    "# roi_mask_path = os.path.join(data_root, \"mask.nii.gz\") # Adjust this name if your mask is named differently!\n",
    "# std_mask_path = '/Users/xiaoqianxiao/fsl/data/standard/MNI152_T1_2mm_brain_mask.nii.gz'\n",
    "\n",
    "# mask_img = None\n",
    "# if os.path.exists(roi_mask_path):\n",
    "#     print(f\"  > Loading Data Specific Mask: {roi_mask_path}\")\n",
    "#     mask_img = nib.load(roi_mask_path)\n",
    "#     # Check size match\n",
    "#     if np.sum(mask_img.get_fdata() > 0) != X_sad.shape[1]:\n",
    "#         print(f\"  ! WARNING: Mask size ({np.sum(mask_img.get_fdata()>0)}) != Feature size ({X_sad.shape[1]}). Visualization will be skipped.\")\n",
    "#         mask_img = None\n",
    "# elif os.path.exists(std_mask_path):\n",
    "#     print(f\"  > Loading Standard Mask: {std_mask_path}\")\n",
    "#     temp_mask = nib.load(std_mask_path)\n",
    "#     # Only use if sizes match (unlikely for ROI analysis, but good check)\n",
    "#     if np.sum(temp_mask.get_fdata() > 0) == X_sad.shape[1]:\n",
    "#         mask_img = temp_mask\n",
    "#     else:\n",
    "#         print(f\"  ! Standard mask size mismatch ({np.sum(temp_mask.get_fdata()>0)} vs {X_sad.shape[1]}).\")\n",
    "#         print(\"  ! Skipping 'unmask' visualization to prevent crash.\")\n",
    "\n",
    "# # 4. Config\n",
    "# alpha_val = thresh_hold_p if 'thresh_hold_p' in locals() else 0.05\n",
    "# fdr_alpha = 1 - alpha_val if alpha_val > 0.5 else alpha_val\n",
    "# print(f\"FDR Alpha Level: {fdr_alpha}\")\n",
    "\n",
    "# # =============================================================================\n",
    "# # 1. Analysis Helper Functions\n",
    "# # =============================================================================\n",
    "# def compute_haufe_binary_robust(model, X):\n",
    "#     scores = model.decision_function(X)\n",
    "#     return np.dot((X - np.mean(X, axis=0)).T, scores - np.mean(scores)) / (X.shape[0] - 1)\n",
    "\n",
    "# def get_robust_weights(X, y, subjects, pipeline, n_boot=10):\n",
    "#     unique_subs = np.unique(subjects)\n",
    "#     accumulated_weights = np.zeros(X.shape[1])\n",
    "#     for i in range(n_boot):\n",
    "#         boot_subs = resample(unique_subs, replace=True, random_state=i)\n",
    "#         X_boot_list, y_boot_list = [], []\n",
    "#         for sub in boot_subs:\n",
    "#             mask = (subjects == sub)\n",
    "#             X_sub = X[mask]\n",
    "#             X_boot_list.append(X_sub - np.mean(X_sub, axis=0))\n",
    "#             y_boot_list.append(y[mask])\n",
    "#         X_boot = np.vstack(X_boot_list)\n",
    "#         y_boot = np.hstack(y_boot_list)\n",
    "        \n",
    "#         clf = clone(pipeline)\n",
    "#         clf.fit(X_boot, y_boot)\n",
    "#         accumulated_weights += compute_haufe_binary_robust(clf, X_boot)\n",
    "#     return accumulated_weights / n_boot\n",
    "\n",
    "# def run_wen_paper_analysis_voxelwise(X, y, subjects, pipeline_template, best_C, n_permutations):\n",
    "#     print(f\"  Estimating Weights ({n_permutations} perms)...\")\n",
    "#     pipe = clone(pipeline_template); pipe.set_params(classification__C=best_C)\n",
    "#     obs_weights = get_robust_weights(X, y, subjects, pipe, n_boot=10)\n",
    "    \n",
    "#     def run_null(i):\n",
    "#         y_shuff = shuffle(y, random_state=i)\n",
    "#         return get_robust_weights(X, y_shuff, subjects, pipe, n_boot=1)\n",
    "\n",
    "#     null_weights_list = Parallel(n_jobs=N_JOBS, verbose=1)(delayed(run_null)(i) for i in range(n_permutations))\n",
    "#     null_weights = np.array(null_weights_list)\n",
    "    \n",
    "#     null_mean = np.mean(null_weights, axis=0)\n",
    "#     null_std = np.std(null_weights, axis=0)\n",
    "#     z_scores = (obs_weights - null_mean) / (null_std + 1e-12)\n",
    "    \n",
    "#     n_extreme = np.sum(np.abs(null_weights) >= np.abs(obs_weights), axis=0)\n",
    "#     p_values = (n_extreme + 1) / (n_permutations + 1)\n",
    "#     reject, _, _, _ = multipletests(p_values, alpha=fdr_alpha, method='fdr_bh')\n",
    "    \n",
    "#     return z_scores, reject\n",
    "\n",
    "# # =============================================================================\n",
    "# # 2. Execution\n",
    "# # =============================================================================\n",
    "# groups = {\n",
    "#     'SAD': {'X': X_sad, 'y': y_sad, 'sub': sub_sad, 'res': res_sad}, \n",
    "#     'HC':  {'X': X_hc,  'y': y_hc,  'sub': sub_hc,  'res': res_hc}\n",
    "# }\n",
    "# target_pair = ['CSR', 'CSS']\n",
    "# sns.set_context(\"poster\")\n",
    "\n",
    "# spatial_results = {}\n",
    "\n",
    "# for name, data in groups.items():\n",
    "#     print(f\"\\nAnalyzing {name}...\")\n",
    "#     mask_cls = np.isin(data['y'], target_pair)\n",
    "#     X_curr = data['X'][mask_cls]\n",
    "#     y_curr = data['y'][mask_cls]\n",
    "#     sub_curr = data['sub'][mask_cls]\n",
    "    \n",
    "#     z_scores, sig_mask = run_wen_paper_analysis_voxelwise(\n",
    "#         X_p, y_curr, sub_curr, build_binary_pipeline(), data['res']['best_C'], N_PERMUTATION\n",
    "#     )\n",
    "    \n",
    "#     dummy_pipe = build_binary_pipeline(); dummy_pipe.fit(X_p, y_curr)\n",
    "#     if dummy_pipe.classes_[0] == 'CSR': z_scores = -z_scores\n",
    "    \n",
    "#     spatial_results[f\"{name} Placebo\"] = {'z_scores': z_scores, 'sig_mask': sig_mask}\n",
    "    \n",
    "#     n_sig = np.sum(sig_mask)\n",
    "#     print(f\"Significant Voxels: {n_sig} ({(n_sig/len(z_scores))*100:.2f}%)\")\n",
    "    \n",
    "#     # VISUALIZATION BLOCK (Protected)\n",
    "#     if n_sig > 0:\n",
    "#         if mask_img is not None:\n",
    "#             try:\n",
    "#                 z_map_masked = z_scores * sig_mask\n",
    "#                 z_img = masking.unmask(z_map_masked, mask_img)\n",
    "#                 fig = plt.figure(figsize=(16, 6))\n",
    "#                 plotting.plot_glass_brain(\n",
    "#                     z_img, threshold=1.96, plot_abs=False, display_mode='lyrz', \n",
    "#                     colorbar=True, vmin=-5, vmax=5, cmap='RdBu_r', \n",
    "#                     title=f\"{name}: FDR < {fdr_alpha}\", figure=fig\n",
    "#                 )\n",
    "#                 plt.show()\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"  ! Visualization failed: {e}\")\n",
    "#         else:\n",
    "#             print(\"  ! Mask not available. Skipping glass brain plot.\")\n",
    "\n",
    "# print(\"--- Cell 7 Complete (Spatial Results Stored) ---\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7: Voxel-wise Spatial Topology & Visualization (ROI Reconstruction)\n",
    "# Context: Voxel-wise analysis using Haufe Transforms.\n",
    "# Fix: Reconstructs whole-brain maps by \"painting\" Z-scores back into individual ROI masks.\n",
    "\n",
    "print(\"--- Cell 7: Running Voxel-wise Spatial Analysis (ROI Reconstruction) ---\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup & Configuration\n",
    "# =============================================================================\n",
    "# 1. ROI Configuration\n",
    "ROI_DIR = \"/Users/xiaoqianxiao/tool/parcellation/Gillian_anatomically_constrained\"\n",
    "ROI_ORDER = [\n",
    "    'left_acc', 'left_amygdala', 'left_hippocampus', 'left_insula', 'left_vmpfc',\n",
    "    'right_acc', 'right_amygdala', 'right_hippocampus', 'right_insula', 'right_vmpfc'\n",
    "]\n",
    "\n",
    "# 2. Check for Results\n",
    "if 'res_sad' not in locals() or 'res_hc' not in locals():\n",
    "    raise ValueError(\"Analysis results ('res_sad', 'res_hc') not found. Please run Cell 6 first.\")\n",
    "\n",
    "# 3. Check for Data\n",
    "if 'X_sad' not in locals():\n",
    "    print(\"Loading data from 'data_subsets'...\")\n",
    "    try:\n",
    "        d_s = data_subsets[\"SAD_Placebo\"][\"ext\"]\n",
    "        d_h = data_subsets[\"HC_Placebo\"][\"ext\"]\n",
    "        X_sad, y_sad, sub_sad = d_s[\"X\"], d_s[\"y\"], d_s[\"sub\"]\n",
    "        X_hc, y_hc, sub_hc = d_h[\"X\"], d_h[\"y\"], d_h[\"sub\"]\n",
    "    except Exception:\n",
    "        raise ValueError(\"Data missing. Please run Cell 5.\")\n",
    "\n",
    "# 4. Config\n",
    "alpha_val = thresh_hold_p if 'thresh_hold_p' in locals() else 0.05\n",
    "fdr_alpha = 1 - alpha_val if alpha_val > 0.5 else alpha_val\n",
    "print(f\"FDR Alpha Level: {fdr_alpha}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Helper: ROI Map Reconstruction\n",
    "# =============================================================================\n",
    "def reconstruct_roi_map(flat_data, roi_names, roi_dir):\n",
    "    \"\"\"\n",
    "    Paints a 1D array of values back into a 3D brain volume by iterating \n",
    "    through the specific list of ROI masks.\n",
    "    \"\"\"\n",
    "    # 1. Determine Reference Space (Load first mask)\n",
    "    first_mask_path = glob.glob(os.path.join(roi_dir, f\"*{roi_names[0]}*.nii*\"))[0]\n",
    "    ref_img = nib.load(first_mask_path)\n",
    "    affine = ref_img.affine\n",
    "    final_vol = np.zeros(ref_img.shape)\n",
    "    \n",
    "    current_idx = 0\n",
    "    \n",
    "    # 2. Iterate and Paint\n",
    "    for name in roi_names:\n",
    "        # Find file (handle potential suffixes like .nii or .nii.gz)\n",
    "        fpaths = glob.glob(os.path.join(roi_dir, f\"*{name}*.nii*\"))\n",
    "        if not fpaths:\n",
    "            print(f\"  ! Error: Mask for '{name}' not found in {roi_dir}\")\n",
    "            return None\n",
    "        \n",
    "        mask_img = nib.load(fpaths[0])\n",
    "        mask_data = mask_img.get_fdata() > 0 # Boolean mask\n",
    "        n_voxels = np.sum(mask_data)\n",
    "        \n",
    "        # Check if we have enough data left\n",
    "        if current_idx + n_voxels > len(flat_data):\n",
    "            print(f\"  ! Error: Data mismatch. Feature vector too short for ROI {name}.\")\n",
    "            return None\n",
    "            \n",
    "        # Extract chunk and paint\n",
    "        roi_values = flat_data[current_idx : current_idx + n_voxels]\n",
    "        final_vol[mask_data] = roi_values # Place values in 3D space\n",
    "        \n",
    "        current_idx += n_voxels\n",
    "        \n",
    "    # Check if data was fully consumed\n",
    "    if current_idx != len(flat_data):\n",
    "         print(f\"  ! Warning: {len(flat_data) - current_idx} features were unused (Feature vector longer than ROIs).\")\n",
    "\n",
    "    return nib.Nifti1Image(final_vol, affine)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Analysis Helper Functions (Haufe)\n",
    "# =============================================================================\n",
    "def compute_haufe_binary_robust(model, X):\n",
    "    scores = model.decision_function(X)\n",
    "    return np.dot((X - np.mean(X, axis=0)).T, scores - np.mean(scores)) / (X.shape[0] - 1)\n",
    "\n",
    "def get_robust_weights(X, y, subjects, pipeline, n_boot=10):\n",
    "    unique_subs = np.unique(subjects)\n",
    "    accumulated_weights = np.zeros(X.shape[1])\n",
    "    for i in range(n_boot):\n",
    "        boot_subs = resample(unique_subs, replace=True, random_state=i)\n",
    "        X_boot_list, y_boot_list = [], []\n",
    "        for sub in boot_subs:\n",
    "            mask = (subjects == sub)\n",
    "            X_sub = X[mask]\n",
    "            X_boot_list.append(X_sub - np.mean(X_sub, axis=0))\n",
    "            y_boot_list.append(y[mask])\n",
    "        X_boot = np.vstack(X_boot_list)\n",
    "        y_boot = np.hstack(y_boot_list)\n",
    "        \n",
    "        clf = clone(pipeline)\n",
    "        clf.fit(X_boot, y_boot)\n",
    "        accumulated_weights += compute_haufe_binary_robust(clf, X_boot)\n",
    "    return accumulated_weights / n_boot\n",
    "\n",
    "def run_wen_paper_analysis_voxelwise(X, y, subjects, pipeline_template, best_C, n_permutations):\n",
    "    print(f\"  Estimating Weights ({n_permutations} perms)...\")\n",
    "    pipe = clone(pipeline_template); pipe.set_params(classification__C=best_C)\n",
    "    obs_weights = get_robust_weights(X, y, subjects, pipe, n_boot=10)\n",
    "    \n",
    "    def run_null(i):\n",
    "        y_shuff = shuffle(y, random_state=i)\n",
    "        return get_robust_weights(X, y_shuff, subjects, pipe, n_boot=1)\n",
    "\n",
    "    null_weights_list = Parallel(n_jobs=N_JOBS, verbose=1)(delayed(run_null)(i) for i in range(n_permutations))\n",
    "    null_weights = np.array(null_weights_list)\n",
    "    \n",
    "    null_mean = np.mean(null_weights, axis=0)\n",
    "    null_std = np.std(null_weights, axis=0)\n",
    "    z_scores = (obs_weights - null_mean) / (null_std + 1e-12)\n",
    "    \n",
    "    n_extreme = np.sum(np.abs(null_weights) >= np.abs(obs_weights), axis=0)\n",
    "    p_values = (n_extreme + 1) / (n_permutations + 1)\n",
    "    reject, _, _, _ = multipletests(p_values, alpha=fdr_alpha, method='fdr_bh')\n",
    "    \n",
    "    return z_scores, reject\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Execution\n",
    "# =============================================================================\n",
    "groups = {\n",
    "    'SAD': {'X': X_sad, 'y': y_sad, 'sub': sub_sad, 'res': res_sad}, \n",
    "    'HC':  {'X': X_hc,  'y': y_hc,  'sub': sub_hc,  'res': res_hc}\n",
    "}\n",
    "target_pair = ['CSR', 'CSS']\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "spatial_results = {}\n",
    "\n",
    "for name, data in groups.items():\n",
    "    print(f\"\\nAnalyzing {name}...\")\n",
    "    mask_cls = np.isin(data['y'], target_pair)\n",
    "    X_curr = data['X'][mask_cls]\n",
    "    y_curr = data['y'][mask_cls]\n",
    "    sub_curr = data['sub'][mask_cls]\n",
    "    \n",
    "    # Run Analysis\n",
    "    z_scores, sig_mask = run_wen_paper_analysis_voxelwise(\n",
    "        X_curr, y_curr, sub_curr, build_binary_pipeline(), data['res']['best_C'], N_PERMUTATION\n",
    "    )\n",
    "    \n",
    "    # Direction correction (Ensure CSR is positive)\n",
    "    dummy_pipe = build_binary_pipeline(); dummy_pipe.fit(X_curr, y_curr)\n",
    "    if dummy_pipe.classes_[0] == 'CSR': z_scores = -z_scores\n",
    "    \n",
    "    spatial_results[f\"{name} Placebo\"] = {'z_scores': z_scores, 'sig_mask': sig_mask}\n",
    "    \n",
    "    n_sig = np.sum(sig_mask)\n",
    "    print(f\"Significant Voxels: {n_sig} ({(n_sig/len(z_scores))*100:.2f}%)\")\n",
    "    \n",
    "    # VISUALIZATION (Reconstruct Map)\n",
    "    if n_sig > 0:\n",
    "        try:\n",
    "            # Mask Z-scores\n",
    "            z_masked = z_scores * sig_mask\n",
    "            \n",
    "            # Reconstruct 3D Nifti from 1D array using ROI list\n",
    "            print(\"  > Reconstructing 3D map from ROI masks...\")\n",
    "            z_img = reconstruct_roi_map(z_masked, ROI_ORDER, ROI_DIR)\n",
    "            \n",
    "            if z_img is not None:\n",
    "                fig = plt.figure(figsize=(16, 6))\n",
    "                plotting.plot_glass_brain(\n",
    "                    z_img, \n",
    "                    threshold=1.96, \n",
    "                    plot_abs=False, \n",
    "                    display_mode='lyrz', \n",
    "                    colorbar=True, \n",
    "                    vmin=-5, vmax=5, \n",
    "                    cmap='RdBu_r', \n",
    "                    title=f\"{name}: FDR < {fdr_alpha}\", \n",
    "                    figure=fig\n",
    "                )\n",
    "                plt.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ! Visualization failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "print(\"--- Cell 7 Complete (Spatial Results Stored) ---\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 8: Feature Importance (Permutation) & Mask Generation\n",
    "# Objective: Identify task-relevant voxels/regions using Permutation Importance.\n",
    "# Context: Used as the primary feature selector for downstream analysis (Cell 9 & 10).\n",
    "\n",
    "print(\"--- Cell 8: Generating Permutation Importance Masks ---\")\n",
    "# =============================================================================\n",
    "# 0. Setup & Dependency Checks\n",
    "# =============================================================================\n",
    "# 1. Check for Results (Models) from Cell 6\n",
    "if 'res_sad' not in locals() or 'res_hc' not in locals():\n",
    "    raise ValueError(\"Models ('res_sad', 'res_hc') not found. Please run Cell 6 first.\")\n",
    "\n",
    "# 2. Check for Data (Global or Nested)\n",
    "# We ensure X_sad/X_hc are available, reloading from data_subsets if necessary.\n",
    "if 'X_sad' not in locals():\n",
    "    print(\"  > Reloading extinction data from 'data_subsets'...\")\n",
    "    try:\n",
    "        X_sad = data_subsets[\"SAD_Placebo\"][\"ext\"][\"X\"]\n",
    "        y_sad = data_subsets[\"SAD_Placebo\"][\"ext\"][\"y\"]\n",
    "        sub_sad = data_subsets[\"SAD_Placebo\"][\"ext\"][\"sub\"]\n",
    "        \n",
    "        X_hc = data_subsets[\"HC_Placebo\"][\"ext\"][\"X\"]\n",
    "        y_hc = data_subsets[\"HC_Placebo\"][\"ext\"][\"y\"]\n",
    "        sub_hc = data_subsets[\"HC_Placebo\"][\"ext\"][\"sub\"]\n",
    "    except (KeyError, TypeError):\n",
    "        raise ValueError(\"Data missing. Please run Cell 5 (Data Prep).\")\n",
    "\n",
    "# 3. Check for ROI Labels\n",
    "if 'parcel_names_ext' not in locals():\n",
    "    print(\"  ! WARNING: 'parcel_names_ext' not found. Using generic feature indices for plotting.\")\n",
    "    parcel_names_ext = [f\"Feat_{i}\" for i in range(X_sad.shape[1])]\n",
    "\n",
    "# Settings\n",
    "target_pair = ['CSR', 'CSS']\n",
    "n_repeats = 100 # Number of permutation iterations for importance\n",
    "importance_masks = {}\n",
    "importance_scores = {}\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Compute Importance for SAD\n",
    "# =============================================================================\n",
    "print(\"1. Computing Importance for SAD Placebo...\")\n",
    "\n",
    "# Slice Data (CSR vs CSS only)\n",
    "mask_sad = np.isin(y_sad, target_pair)\n",
    "X_sad_p = X_sad[mask_sad]\n",
    "y_sad_p = y_sad[mask_sad]\n",
    "sub_sad_p = sub_sad[mask_sad]\n",
    "\n",
    "# Compute Importance (CV-based)\n",
    "imp_sad_mean = compute_perm_importance_cv(\n",
    "    res_sad['model'], X_sad_p, y_sad_p, sub_sad_p,\n",
    "    n_repeats=n_repeats, n_splits=SUBJECT_CV_SPLITS\n",
    ")\n",
    "\n",
    "# Define Mask: Top 5% most important voxels\n",
    "PERCENTILE_THRESH = 95\n",
    "thr_sad = np.percentile(imp_sad_mean, PERCENTILE_THRESH)\n",
    "mask_sad_sig = imp_sad_mean >= thr_sad\n",
    "importance_masks['SAD'] = mask_sad_sig\n",
    "importance_scores['SAD'] = imp_sad_mean\n",
    "\n",
    "print(f\"   > SAD: Found {np.sum(mask_sad_sig)} predictive voxels (Top 5%, thr={thr_sad:.6f}).\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Compute Importance for HC\n",
    "# =============================================================================\n",
    "print(\"2. Computing Importance for HC Placebo...\")\n",
    "\n",
    "# Slice Data\n",
    "mask_hc = np.isin(y_hc, target_pair)\n",
    "X_hc_p = X_hc[mask_hc]\n",
    "y_hc_p = y_hc[mask_hc]\n",
    "sub_hc_p = sub_hc[mask_hc]\n",
    "\n",
    "# Compute Importance (CV-based)\n",
    "imp_hc_mean = compute_perm_importance_cv(\n",
    "    res_hc['model'], X_hc_p, y_hc_p, sub_hc_p,\n",
    "    n_repeats=n_repeats, n_splits=SUBJECT_CV_SPLITS\n",
    ")\n",
    "\n",
    "# Define Mask: Top 5% most important voxels\n",
    "thr_hc = np.percentile(imp_hc_mean, PERCENTILE_THRESH)\n",
    "mask_hc_sig = imp_hc_mean >= thr_hc\n",
    "importance_masks['HC'] = mask_hc_sig\n",
    "importance_scores['HC'] = imp_hc_mean\n",
    "\n",
    "print(f\"   > HC:  Found {np.sum(mask_hc_sig)} predictive voxels (Top 5%, thr={thr_hc:.6f}).\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Visualization (River Plot)\n",
    "# =============================================================================\n",
    "print(\"3. Generating River Plot...\")\n",
    "\n",
    "# Prepare dictionary for plotting function\n",
    "plot_data = {\n",
    "    'SAD Placebo': imp_sad_mean,\n",
    "    'HC Placebo': imp_hc_mean\n",
    "}\n",
    "\n",
    "# Use the helper function from Cell 4\n",
    "# Assumes make_river_plot_importance handles the figure creation\n",
    "try:\n",
    "    make_river_plot_importance(\n",
    "        plot_data,\n",
    "        parcel_names_ext,\n",
    "        top_k=20,  # Show top 20 most important features per group\n",
    "        title=\"Neural Signatures (Permutation Importance)\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"  ! Visualization skipped due to error: {e}\")\n",
    "\n",
    "print(\"Cell 8: Importance masks generated and stored in 'importance_masks'.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 9: Analysis 1.2 - Static Representational Topology (All Features | Centroid)\n",
    "# Objective: Characterize the stable organization of the social learning space.\n",
    "# Constraint: All features (no feature selection).\n",
    "# Method: Cross-validated Mahalanobis (crossnobis) distance with shrinkage covariance, averaged over split-half repeats.\n",
    "# Tests: Group Comparison (SAD vs HC) AND One-Sample Test (Dist > 0).\n",
    "# Reporting: Raw, z-scored, and per-voxel normalized crossnobis distances.\n",
    "\n",
    "print(\"--- Running Analysis 1.2: Static Representational Topology (All Features | Centroid) ---\")\n",
    "\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Global Constants\n",
    "RDM_CONDITIONS = [\"CS-\", \"CSS\", \"CSR\"] \n",
    "\n",
    "# =============================================================================\n",
    "# 0. Feature Selection (All Features)\n",
    "print(\"\\n[Step 0] Using all features (no feature selection).\")\n",
    "\n",
    "mask_sad_top5 = np.ones(X_ext.shape[1], dtype=bool)\n",
    "mask_hc_top5 = np.ones(X_ext.shape[1], dtype=bool)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Data Preparation (Recovering CS-)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 1] Preparing Centroid Data...\")\n",
    "\n",
    "# Validate Source Data\n",
    "if 'X_ext' not in locals() or 'y_ext' not in locals():\n",
    "    raise ValueError(\"Global 'X_ext' variables missing. Cannot retrieve CS- trials (Cell 5 filtered them out).\")\n",
    "\n",
    "# Retrieve Subject Lists from the Nested Dictionary (created in Cell 5)\n",
    "# structure: data_subsets['Group']['ext']['sub']\n",
    "try:\n",
    "    known_hc = np.unique(data_subsets[\"HC_Placebo\"][\"ext\"][\"sub\"])\n",
    "    known_sad = np.unique(data_subsets[\"SAD_Placebo\"][\"ext\"][\"sub\"])\n",
    "except (KeyError, TypeError):\n",
    "    raise ValueError(\"Data structure mismatch. Ensure Cell 5 generated 'data_subsets' with ['ext'] keys.\")\n",
    "\n",
    "# Create a temporary group mapping array matching the global X_ext\n",
    "group_ext = np.array([\"Unknown\"] * len(sub_ext), dtype=object)\n",
    "group_ext[np.isin(sub_ext, known_hc)] = \"HC\"\n",
    "group_ext[np.isin(sub_ext, known_sad)] = \"SAD\"\n",
    "\n",
    "# Filter Global Data for RDM Conditions\n",
    "mask_conds = np.isin(y_ext, RDM_CONDITIONS)\n",
    "X_raw = X_ext[mask_conds]\n",
    "y_raw = y_ext[mask_conds]\n",
    "sub_raw = sub_ext[mask_conds]\n",
    "grp_raw = group_ext[mask_conds]\n",
    "\n",
    "# Split by Group\n",
    "mask_sad_grp = (grp_raw == \"SAD\")\n",
    "mask_hc_grp = (grp_raw == \"HC\")\n",
    "\n",
    "# Slice Features (Apply the All Features Masks)\n",
    "X_sad_12 = X_raw[mask_sad_grp][:, mask_sad_top5]\n",
    "y_sad_12 = y_raw[mask_sad_grp]\n",
    "sub_sad_12 = sub_raw[mask_sad_grp]\n",
    "\n",
    "X_hc_12 = X_raw[mask_hc_grp][:, mask_hc_top5]\n",
    "y_hc_12 = y_raw[mask_hc_grp]\n",
    "sub_hc_12 = sub_raw[mask_hc_grp]\n",
    "\n",
    "print(f\"  > SAD Matrix (All Features): {X_sad_12.shape} | HC Matrix (All Features): {X_hc_12.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Centroid RDM Calculation\n",
    "# =============================================================================\n",
    "def calculate_crossnobis_rdm(\n",
    "    X,\n",
    "    y,\n",
    "    subjects,\n",
    "    conditions,\n",
    "    n_repeats=CROSSNOBIS_REPEATS,\n",
    "    random_state=RANDOM_STATE,\n",
    "    standardize=False,\n",
    "):\n",
    "    # Crossnobis RDM per subject with Ledoit-Wolf shrinkage, averaged over repeats.\n",
    "    unique_subs = np.unique(subjects)\n",
    "    rdms = []\n",
    "    sub_ids = []\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    for sub in unique_subs:\n",
    "        mask_sub = (subjects == sub)\n",
    "        X_sub = X[mask_sub]\n",
    "        y_sub = y[mask_sub]\n",
    "\n",
    "        if standardize:\n",
    "            mean = np.mean(X_sub, axis=0)\n",
    "            std = np.std(X_sub, axis=0)\n",
    "            std = np.where(std == 0, 1.0, std)\n",
    "            X_sub = (X_sub - mean) / std\n",
    "\n",
    "        rdm_accum = None\n",
    "        valid_reps = 0\n",
    "\n",
    "        for rep in range(n_repeats):\n",
    "            # Build split-half means per condition\n",
    "            means_a = {}\n",
    "            means_b = {}\n",
    "            ok = True\n",
    "            for cond in conditions:\n",
    "                idx = np.where(y_sub == cond)[0]\n",
    "                if len(idx) < 2:\n",
    "                    ok = False\n",
    "                    break\n",
    "                idx = idx.copy()\n",
    "                rng.shuffle(idx)\n",
    "                half = len(idx) // 2\n",
    "                idx_a = idx[:half]\n",
    "                idx_b = idx[half:]\n",
    "                if len(idx_a) == 0 or len(idx_b) == 0:\n",
    "                    ok = False\n",
    "                    break\n",
    "                means_a[cond] = np.mean(X_sub[idx_a], axis=0)\n",
    "                means_b[cond] = np.mean(X_sub[idx_b], axis=0)\n",
    "            if not ok:\n",
    "                continue\n",
    "\n",
    "            # Estimate noise covariance from residuals (all trials, condition-demeaned)\n",
    "            resid = []\n",
    "            for cond in conditions:\n",
    "                idx = np.where(y_sub == cond)[0]\n",
    "                cond_mean = np.mean(X_sub[idx], axis=0)\n",
    "                resid.append(X_sub[idx] - cond_mean)\n",
    "            resid = np.vstack(resid)\n",
    "            cov = LedoitWolf().fit(resid).covariance_\n",
    "            prec = np.linalg.pinv(cov)\n",
    "\n",
    "            # Crossnobis distance matrix\n",
    "            n = len(conditions)\n",
    "            rdm = np.zeros((n, n))\n",
    "            for i in range(n):\n",
    "                for j in range(i + 1, n):\n",
    "                    c_i = conditions[i]\n",
    "                    c_j = conditions[j]\n",
    "                    d_a = means_a[c_i] - means_a[c_j]\n",
    "                    d_b = means_b[c_i] - means_b[c_j]\n",
    "                    dist = float(d_a.T @ prec @ d_b)\n",
    "                    rdm[i, j] = dist\n",
    "                    rdm[j, i] = dist\n",
    "\n",
    "            if rdm_accum is None:\n",
    "                rdm_accum = rdm\n",
    "            else:\n",
    "                rdm_accum += rdm\n",
    "            valid_reps += 1\n",
    "\n",
    "        if valid_reps == 0:\n",
    "            continue\n",
    "        rdm_mean = rdm_accum / valid_reps\n",
    "        rdms.append(rdm_mean)\n",
    "        sub_ids.append(sub)\n",
    "\n",
    "    return np.array(rdms), np.array(sub_ids)\n",
    "\n",
    "# Compute RDMs (raw + z-scored)\n",
    "print(f\"  Calculating Centroid RDMs (Conditions: {RDM_CONDITIONS}) with {CROSSNOBIS_REPEATS} split-half repeats...\")\n",
    "rdms_sad_raw, subs_sad_rdm = calculate_crossnobis_rdm(X_sad_12, y_sad_12, sub_sad_12, RDM_CONDITIONS, standardize=False)\n",
    "rdms_hc_raw, subs_hc_rdm = calculate_crossnobis_rdm(X_hc_12, y_hc_12, sub_hc_12, RDM_CONDITIONS, standardize=False)\n",
    "\n",
    "rdms_sad_z, subs_sad_rdm_z = calculate_crossnobis_rdm(X_sad_12, y_sad_12, sub_sad_12, RDM_CONDITIONS, standardize=True)\n",
    "rdms_hc_z, subs_hc_rdm_z = calculate_crossnobis_rdm(X_hc_12, y_hc_12, sub_hc_12, RDM_CONDITIONS, standardize=True)\n",
    "\n",
    "print(f\"  > Computed RDMs (raw): SAD (n={len(subs_sad_rdm)}), HC (n={len(subs_hc_rdm)})\")\n",
    "print(f\"  > Computed RDMs (z-scored): SAD (n={len(subs_sad_rdm_z)}), HC (n={len(subs_hc_rdm_z)})\")\n",
    "\n",
    "# Per-voxel normalization (scale by number of features)\n",
    "n_feat_sad = X_sad_12.shape[1]\n",
    "n_feat_hc = X_hc_12.shape[1]\n",
    "rdms_sad_raw_pv = rdms_sad_raw / n_feat_sad\n",
    "rdms_hc_raw_pv = rdms_hc_raw / n_feat_hc\n",
    "rdms_sad_z_pv = rdms_sad_z / n_feat_sad\n",
    "rdms_hc_z_pv = rdms_hc_z / n_feat_hc\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Metrics & Statistical Tests\n",
    "# =============================================================================\n",
    "# Conditions: 0=CS-, 1=CSS, 2=CSR\n",
    "idx_cs_minus, idx_css, idx_csr = 0, 1, 2\n",
    "\n",
    "def extract_metrics(rdms):\n",
    "    # Metric A: Threat (CSR) vs Safety (CSS)\n",
    "    m_a = rdms[:, idx_csr, idx_css]\n",
    "    # Metric B: Safety (CSS) vs Baseline (CS-)\n",
    "    m_b = rdms[:, idx_css, idx_cs_minus]\n",
    "    return m_a, m_b\n",
    "\n",
    "print(\"\\n[Step 3] Statistical Testing...\")\n",
    "\n",
    "# --- Helper for One-Sample Test (Significantly > 0?) ---\n",
    "def one_sample_test(data, name):\n",
    "    # Test if distance is greater than 0\n",
    "    t_val, p_val = ttest_1samp(data, 0, alternative='greater')\n",
    "    sig = \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"  > {name}: Mean={np.mean(data):.3f}, t={t_val:.3f}, p={p_val:.4f} ({sig})\")\n",
    "    return p_val\n",
    "\n",
    "# ---- RAW ----\n",
    "print(\"\\n[RAW] Metric A: Threat (CSR) vs Safety (CSS) Distance\")\n",
    "vec_a_sad_raw, vec_b_sad_raw = extract_metrics(rdms_sad_raw)\n",
    "vec_a_hc_raw, vec_b_hc_raw = extract_metrics(rdms_hc_raw)\n",
    "\n",
    "p_a_sad_0_raw = one_sample_test(vec_a_sad_raw, \"SAD (Dist > 0)\")\n",
    "p_a_hc_0_raw = one_sample_test(vec_a_hc_raw, \"HC  (Dist > 0)\")\n",
    "\n",
    "print(\"  > Group Comparison (SAD vs HC):\")\n",
    "t_a_raw, p_a_raw, m_a_sad_raw, m_a_hc_raw = perm_ttest_ind(vec_a_sad_raw, vec_a_hc_raw, n_perm=N_PERMUTATION)\n",
    "print(f\"    Diff: SAD={m_a_sad_raw:.3f}, HC={m_a_hc_raw:.3f} | t={t_a_raw:.3f}, p={p_a_raw:.4f}\")\n",
    "\n",
    "print(\"\\n[RAW] Metric B: Safety (CSS) vs Background (CS-) Distance\")\n",
    "p_b_sad_0_raw = one_sample_test(vec_b_sad_raw, \"SAD (Dist > 0)\")\n",
    "p_b_hc_0_raw = one_sample_test(vec_b_hc_raw, \"HC  (Dist > 0)\")\n",
    "\n",
    "print(\"  > Group Comparison (SAD vs HC):\")\n",
    "t_b_raw, p_b_raw, m_b_sad_raw, m_b_hc_raw = perm_ttest_ind(vec_b_sad_raw, vec_b_hc_raw, n_perm=N_PERMUTATION)\n",
    "print(f\"    Diff: SAD={m_b_sad_raw:.3f}, HC={m_b_hc_raw:.3f} | t={t_b_raw:.3f}, p={p_b_raw:.4f}\")\n",
    "\n",
    "# ---- Z-SCORED ----\n",
    "print(\"\\n[Z-SCORED] Metric A: Threat (CSR) vs Safety (CSS) Distance\")\n",
    "vec_a_sad_z, vec_b_sad_z = extract_metrics(rdms_sad_z)\n",
    "vec_a_hc_z, vec_b_hc_z = extract_metrics(rdms_hc_z)\n",
    "\n",
    "p_a_sad_0_z = one_sample_test(vec_a_sad_z, \"SAD (Dist > 0)\")\n",
    "p_a_hc_0_z = one_sample_test(vec_a_hc_z, \"HC  (Dist > 0)\")\n",
    "\n",
    "print(\"  > Group Comparison (SAD vs HC):\")\n",
    "t_a_z, p_a_z, m_a_sad_z, m_a_hc_z = perm_ttest_ind(vec_a_sad_z, vec_a_hc_z, n_perm=N_PERMUTATION)\n",
    "print(f\"    Diff: SAD={m_a_sad_z:.3f}, HC={m_a_hc_z:.3f} | t={t_a_z:.3f}, p={p_a_z:.4f}\")\n",
    "\n",
    "print(\"\\n[Z-SCORED] Metric B: Safety (CSS) vs Background (CS-) Distance\")\n",
    "p_b_sad_0_z = one_sample_test(vec_b_sad_z, \"SAD (Dist > 0)\")\n",
    "p_b_hc_0_z = one_sample_test(vec_b_hc_z, \"HC  (Dist > 0)\")\n",
    "\n",
    "print(\"  > Group Comparison (SAD vs HC):\")\n",
    "t_b_z, p_b_z, m_b_sad_z, m_b_hc_z = perm_ttest_ind(vec_b_sad_z, vec_b_hc_z, n_perm=N_PERMUTATION)\n",
    "print(f\"    Diff: SAD={m_b_sad_z:.3f}, HC={m_b_hc_z:.3f} | t={t_b_z:.3f}, p={p_b_z:.4f}\")\n",
    "\n",
    "# ---- PER-VOXEL (RAW) ----\n",
    "print(\"\\n[PER-VOXEL RAW] Metric A: Threat (CSR) vs Safety (CSS) Distance\")\n",
    "vec_a_sad_raw_pv, vec_b_sad_raw_pv = extract_metrics(rdms_sad_raw_pv)\n",
    "vec_a_hc_raw_pv, vec_b_hc_raw_pv = extract_metrics(rdms_hc_raw_pv)\n",
    "\n",
    "p_a_sad_0_raw_pv = one_sample_test(vec_a_sad_raw_pv, \"SAD (Dist > 0)\")\n",
    "p_a_hc_0_raw_pv = one_sample_test(vec_a_hc_raw_pv, \"HC  (Dist > 0)\")\n",
    "\n",
    "print(\"  > Group Comparison (SAD vs HC):\")\n",
    "t_a_raw_pv, p_a_raw_pv, m_a_sad_raw_pv, m_a_hc_raw_pv = perm_ttest_ind(vec_a_sad_raw_pv, vec_a_hc_raw_pv, n_perm=N_PERMUTATION)\n",
    "print(f\"    Diff: SAD={m_a_sad_raw_pv:.6f}, HC={m_a_hc_raw_pv:.6f} | t={t_a_raw_pv:.3f}, p={p_a_raw_pv:.4f}\")\n",
    "\n",
    "print(\"\\n[PER-VOXEL RAW] Metric B: Safety (CSS) vs Background (CS-) Distance\")\n",
    "p_b_sad_0_raw_pv = one_sample_test(vec_b_sad_raw_pv, \"SAD (Dist > 0)\")\n",
    "p_b_hc_0_raw_pv = one_sample_test(vec_b_hc_raw_pv, \"HC  (Dist > 0)\")\n",
    "\n",
    "print(\"  > Group Comparison (SAD vs HC):\")\n",
    "t_b_raw_pv, p_b_raw_pv, m_b_sad_raw_pv, m_b_hc_raw_pv = perm_ttest_ind(vec_b_sad_raw_pv, vec_b_hc_raw_pv, n_perm=N_PERMUTATION)\n",
    "print(f\"    Diff: SAD={m_b_sad_raw_pv:.6f}, HC={m_b_hc_raw_pv:.6f} | t={t_b_raw_pv:.3f}, p={p_b_raw_pv:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Visualization\n",
    "# =============================================================================\n",
    "\n",
    "def plot_topology(rdms_sad, rdms_hc, vec_a_sad, vec_a_hc, vec_b_sad, vec_b_hc,\n",
    "                  p_a, p_b, p_a_sad_0, p_a_hc_0, p_b_sad_0, p_b_hc_0,\n",
    "                  title_suffix):\n",
    "    sns.set_context(\"poster\")\n",
    "    fig = plt.figure(figsize=(24, 8))\n",
    "    gs = fig.add_gridspec(1, 3)\n",
    "\n",
    "    # Heatmaps\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    sns.heatmap(\n",
    "        np.mean(rdms_sad, axis=0),\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"viridis\",\n",
    "        vmin=0,\n",
    "        vmax=1.2,\n",
    "        xticklabels=RDM_CONDITIONS,\n",
    "        yticklabels=RDM_CONDITIONS,\n",
    "        ax=ax1,\n",
    "        cbar=False,\n",
    "    )\n",
    "    ax1.set_title(f\"SAD Topology ({title_suffix})\\n(n={len(rdms_sad)})\")\n",
    "\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    sns.heatmap(\n",
    "        np.mean(rdms_hc, axis=0),\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"viridis\",\n",
    "        vmin=0,\n",
    "        vmax=1.2,\n",
    "        xticklabels=RDM_CONDITIONS,\n",
    "        yticklabels=RDM_CONDITIONS,\n",
    "        ax=ax2,\n",
    "    )\n",
    "    ax2.set_title(f\"HC Topology ({title_suffix})\\n(n={len(rdms_hc)})\")\n",
    "\n",
    "    # Violins\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    df_res = pd.DataFrame({\n",
    "        'Group': ['SAD'] * len(vec_a_sad) + ['HC'] * len(vec_a_hc) + ['SAD'] * len(vec_b_sad) + ['HC'] * len(vec_b_hc),\n",
    "        'Distance': np.concatenate([vec_a_sad, vec_a_hc, vec_b_sad, vec_b_hc]),\n",
    "        'Metric': ['A: Threat Dist'] * len(vec_a_sad) + ['A: Threat Dist'] * len(vec_a_hc) +\n",
    "                  ['B: Safety Dist'] * len(vec_b_sad) + ['B: Safety Dist'] * len(vec_b_hc),\n",
    "    })\n",
    "    sns.violinplot(\n",
    "        data=df_res,\n",
    "        x='Metric',\n",
    "        y='Distance',\n",
    "        hue='Group',\n",
    "        split=True,\n",
    "        inner='quartile',\n",
    "        palette={'SAD': '#c44e52', 'HC': '#4c72b0'},\n",
    "        ax=ax3,\n",
    "    )\n",
    "    ax3.set_title(f\"Topological Metrics (Centroid | {title_suffix})\")\n",
    "    ax3.set_ylabel(\"Crossnobis Distance\")\n",
    "\n",
    "    # Annotate Group Differences\n",
    "    y_max = df_res['Distance'].max()\n",
    "    if p_a < 0.05:\n",
    "        ax3.text(0, y_max + 0.05, f'* (p={p_a:.3f})', ha='center', fontsize=18)\n",
    "    if p_b < 0.05:\n",
    "        ax3.text(1, y_max + 0.05, f'* (p={p_b:.3f})', ha='center', fontsize=18)\n",
    "\n",
    "    def get_sig_star(p):\n",
    "        return \"*\" if p < 0.05 else \"ns\"\n",
    "\n",
    "    # For Metric A\n",
    "    ax3.text(-0.2, -0.15, f\"SAD: {get_sig_star(p_a_sad_0)}\", transform=ax3.get_xaxis_transform(),\n",
    "             ha='center', fontsize=14, color='#c44e52')\n",
    "    ax3.text(0.2, -0.15, f\"HC: {get_sig_star(p_a_hc_0)}\", transform=ax3.get_xaxis_transform(),\n",
    "             ha='center', fontsize=14, color='#4c72b0')\n",
    "\n",
    "    # For Metric B\n",
    "    ax3.text(0.8, -0.15, f\"SAD: {get_sig_star(p_b_sad_0)}\", transform=ax3.get_xaxis_transform(),\n",
    "             ha='center', fontsize=14, color='#c44e52')\n",
    "    ax3.text(1.2, -0.15, f\"HC: {get_sig_star(p_b_hc_0)}\", transform=ax3.get_xaxis_transform(),\n",
    "             ha='center', fontsize=14, color='#4c72b0')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot RAW\n",
    "plot_topology(\n",
    "    rdms_sad_raw,\n",
    "    rdms_hc_raw,\n",
    "    vec_a_sad_raw,\n",
    "    vec_a_hc_raw,\n",
    "    vec_b_sad_raw,\n",
    "    vec_b_hc_raw,\n",
    "    p_a_raw,\n",
    "    p_b_raw,\n",
    "    p_a_sad_0_raw,\n",
    "    p_a_hc_0_raw,\n",
    "    p_b_sad_0_raw,\n",
    "    p_b_hc_0_raw,\n",
    "    title_suffix=\"All Features (Raw)\",\n",
    ")\n",
    "\n",
    "# Plot Z-SCORED\n",
    "plot_topology(\n",
    "    rdms_sad_z,\n",
    "    rdms_hc_z,\n",
    "    vec_a_sad_z,\n",
    "    vec_a_hc_z,\n",
    "    vec_b_sad_z,\n",
    "    vec_b_hc_z,\n",
    "    p_a_z,\n",
    "    p_b_z,\n",
    "    p_a_sad_0_z,\n",
    "    p_a_hc_0_z,\n",
    "    p_b_sad_0_z,\n",
    "    p_b_hc_0_z,\n",
    "    title_suffix=\"All Features (Z-Scored)\",\n",
    ")\n",
    "\n",
    "# Plot PER-VOXEL RAW\n",
    "plot_topology(\n",
    "    rdms_sad_raw_pv,\n",
    "    rdms_hc_raw_pv,\n",
    "    vec_a_sad_raw_pv,\n",
    "    vec_a_hc_raw_pv,\n",
    "    vec_b_sad_raw_pv,\n",
    "    vec_b_hc_raw_pv,\n",
    "    p_a_raw_pv,\n",
    "    p_b_raw_pv,\n",
    "    p_a_sad_0_raw_pv,\n",
    "    p_a_hc_0_raw_pv,\n",
    "    p_b_sad_0_raw_pv,\n",
    "    p_b_hc_0_raw_pv,\n",
    "    title_suffix=\"All Features (Raw / Per-Voxel)\",\n",
    ")\n",
    "\n",
    "# Store Results\n",
    "results_12 = {\n",
    "    \"rdms_sad_raw\": rdms_sad_raw,\n",
    "    \"rdms_hc_raw\": rdms_hc_raw,\n",
    "    \"rdms_sad_z\": rdms_sad_z,\n",
    "    \"rdms_hc_z\": rdms_hc_z,\n",
    "    \"rdms_sad_raw_pv\": rdms_sad_raw_pv,\n",
    "    \"rdms_hc_raw_pv\": rdms_hc_raw_pv,\n",
    "    \"rdms_sad_z_pv\": rdms_sad_z_pv,\n",
    "    \"rdms_hc_z_pv\": rdms_hc_z_pv,\n",
    "    \"metric_a_stats_raw\": (t_a_raw, p_a_raw),\n",
    "    \"metric_b_stats_raw\": (t_b_raw, p_b_raw),\n",
    "    \"metric_a_stats_z\": (t_a_z, p_a_z),\n",
    "    \"metric_b_stats_z\": (t_b_z, p_b_z),\n",
    "    \"metric_a_stats_raw_pv\": (t_a_raw_pv, p_a_raw_pv),\n",
    "    \"metric_b_stats_raw_pv\": (t_b_raw_pv, p_b_raw_pv),\n",
    "    \"one_sample_stats_raw\": {\n",
    "        \"p_a_sad\": p_a_sad_0_raw,\n",
    "        \"p_a_hc\": p_a_hc_0_raw,\n",
    "        \"p_b_sad\": p_b_sad_0_raw,\n",
    "        \"p_b_hc\": p_b_hc_0_raw,\n",
    "    },\n",
    "    \"one_sample_stats_z\": {\n",
    "        \"p_a_sad\": p_a_sad_0_z,\n",
    "        \"p_a_hc\": p_a_hc_0_z,\n",
    "        \"p_b_sad\": p_b_sad_0_z,\n",
    "        \"p_b_hc\": p_b_hc_0_z,\n",
    "    },\n",
    "    \"one_sample_stats_raw_pv\": {\n",
    "        \"p_a_sad\": p_a_sad_0_raw_pv,\n",
    "        \"p_a_hc\": p_a_hc_0_raw_pv,\n",
    "        \"p_b_sad\": p_b_sad_0_raw_pv,\n",
    "        \"p_b_hc\": p_b_hc_0_raw_pv,\n",
    "    },\n",
    "}\n",
    "_save_result(\"results_12\", results_12)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 10: Analysis 1.3 - Dynamic Representational Drift (Top 5% Features)\n",
    "# Objective: Quantify plasticity magnitude (Projection) and fidelity (Cosine).\n",
    "# Target Definitions:\n",
    "#   - Safety:  Extinction CSS -> Extinction CS-\n",
    "#   - Threat:  Extinction CSR -> Reinstatement CSR\n",
    "# Feature Selection: Top 5% Importance (Permutation Scores)\n",
    "\n",
    "print(\"--- Running Analysis 1.3: Dynamic Representational Drift (Top 5% Features) ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import ttest_1samp, ttest_ind, levene, shapiro, mannwhitneyu\n",
    "\n",
    "# Constants\n",
    "COND_SAFETY_TARGET = \"CS-\"\n",
    "COND_SAFETY_LEARN = \"CSS\"\n",
    "COND_THREAT_LEARN = \"CSR\"\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Feature Selection & Data Loading\n",
    "# =============================================================================\n",
    "print(f\"\\n[Step 0] Setup & Data Loading...\")\n",
    "\n",
    "# Use Top 5% voxel masks from Analysis 1.1 (Cell 9)\n",
    "if 'importance_masks' not in locals():\n",
    "    raise ValueError(\"Top 5% masks not found. Run Analysis 1.1 / Cell 9 first.\")\n",
    "mask_sad = importance_masks['SAD']\n",
    "mask_hc = importance_masks['HC']\n",
    "print(f\"  > Using Top 5% voxels: SAD={int(np.sum(mask_sad))}, HC={int(np.sum(mask_hc))}\")\n",
    "\n",
    "\n",
    "# 1. Select Top 5% Features\n",
    "def get_phase_data(group, phase):\n",
    "    try:\n",
    "        d = data_subsets[group][phase]\n",
    "        if d is None: return None, None, None\n",
    "        return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "    except KeyError:\n",
    "        return None, None, None\n",
    "\n",
    "# Load Extinction (Start/Learning Phase)\n",
    "X_ext_sad, y_ext_sad, sub_ext_sad = get_phase_data(\"SAD_Placebo\", \"ext\")\n",
    "X_ext_hc, y_ext_hc, sub_ext_hc = get_phase_data(\"HC_Placebo\", \"ext\")\n",
    "\n",
    "# Load Reinstatement (Target Phase for Threat)\n",
    "X_rst_sad, y_rst_sad, sub_rst_sad = get_phase_data(\"SAD_Placebo\", \"rst\")\n",
    "X_rst_hc, y_rst_hc, sub_rst_hc = get_phase_data(\"HC_Placebo\", \"rst\")\n",
    "\n",
    "# Validate Reinstatement Data\n",
    "if X_rst_sad is None or X_rst_hc is None:\n",
    "    raise ValueError(\"Reinstatement data missing in data_subsets. Run Cell 5 and ensure phase3 is loaded.\")\n",
    "# Handle CS- (Safety Target) - likely missing from subsets, need global X_ext\n",
    "if 'X_ext' in locals():\n",
    "    X_global, y_global, sub_global = X_ext, y_ext, sub_ext\n",
    "else:\n",
    "    print(\"  ! WARNING: Global X_ext missing. Safety Target (CS-) might be unavailable.\")\n",
    "    X_global, y_global, sub_global = X_ext_sad, y_ext_sad, sub_ext_sad\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Vector Calculation Helper (Cross-Phase Support)\n",
    "# =============================================================================\n",
    "def calculate_plasticity_vectors(\n",
    "    X_learn, y_learn, sub_learn,   # Data for Learning Trajectory (Start -> End)\n",
    "    X_targ, y_targ, sub_targ,      # Data for Target Definition\n",
    "    feature_mask, \n",
    "    cond_learn,                    # Condition changing (e.g., CSS or CSR)\n",
    "    cond_target_label              # Label of the target (e.g., CS- or CSR)\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates projection of learning (in X_learn) onto axis towards Target (in X_targ).\n",
    "    \"\"\"\n",
    "    # 1. Apply Feature Mask & Centering\n",
    "    X_learn = X_learn[:, feature_mask]\n",
    "    X_targ = X_targ[:, feature_mask]\n",
    "    # Note: Center phases separately to remove global session shifts (drift correction)\n",
    "    \n",
    "    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n",
    "    res = {'sub': [], 'projection': [], 'cosine': [], 'init_dist': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # Slice Learning Data (The Drift)\n",
    "        m_l = (sub_learn == sub); xl = X_learn[m_l]; yl = y_learn[m_l]\n",
    "        \n",
    "        # Slice Target Data (The Goal)\n",
    "        m_t = (sub_targ == sub); xt = X_targ[m_t]; yt = y_targ[m_t]\n",
    "        \n",
    "        # A. Define Target Centroid (P_target)\n",
    "        mask_tgt_cond = (yt == cond_target_label)\n",
    "        if np.sum(mask_tgt_cond) == 0: continue\n",
    "        P_target = np.mean(xt[mask_tgt_cond], axis=0)\n",
    "        \n",
    "        # B. Define Start & End (Learning Phase)\n",
    "        mask_lrn_cond = (yl == cond_learn)\n",
    "        idx_lrn = np.where(mask_lrn_cond)[0]\n",
    "        if len(idx_lrn) < 2: continue\n",
    "        \n",
    "        cutoff = len(idx_lrn) // 2\n",
    "        # Early Learning\n",
    "        P_start = np.mean(xl[idx_lrn[:cutoff]], axis=0)\n",
    "        # Late Learning\n",
    "        P_end = np.mean(xl[idx_lrn[cutoff:]], axis=0)\n",
    "        \n",
    "        # C. Define Vectors\n",
    "        # Axis: From Start (Ext) -> Target (Reinstatement or CS-)\n",
    "        V_axis = P_target - P_start\n",
    "        # Drift: Actual change during learning\n",
    "        V_drift = P_end - P_start\n",
    "        \n",
    "        norm_axis = norm(V_axis)\n",
    "        norm_drift = norm(V_drift)\n",
    "        \n",
    "        if norm_axis == 0 or norm_drift == 0: continue\n",
    "        \n",
    "        dot_prod = np.dot(V_drift, V_axis)\n",
    "        \n",
    "        # Scalar Projection (Magnitude)\n",
    "        projection = dot_prod / norm_axis\n",
    "        \n",
    "        # Cosine Similarity (Fidelity)\n",
    "        cosine = dot_prod / (norm_drift * norm_axis)\n",
    "        \n",
    "        res['sub'].append(sub)\n",
    "        res['projection'].append(projection)\n",
    "        res['cosine'].append(cosine)\n",
    "        res['init_dist'].append(norm_axis)\n",
    "        \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Execution\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Calculating Vectors...\")\n",
    "\n",
    "# A. Safety Learning (CSS -> CS-)\n",
    "# Both Start and Target are in Extinction (or Global)\n",
    "print(\"  > Safety Analysis: Start=CSS(Ext) -> Target=CS-(Ext)\")\n",
    "df_safe_sad = calculate_plasticity_vectors(\n",
    "    X_ext_sad, y_ext_sad, sub_ext_sad,     # Learn: Extinction\n",
    "    X_global, y_global, sub_global,        # Target: Global (contains CS-)\n",
    "    mask_sad, COND_SAFETY_LEARN, COND_SAFETY_TARGET\n",
    ")\n",
    "df_safe_hc = calculate_plasticity_vectors(\n",
    "    X_ext_hc, y_ext_hc, sub_ext_hc, \n",
    "    X_global, y_global, sub_global, \n",
    "    mask_hc, COND_SAFETY_LEARN, COND_SAFETY_TARGET\n",
    ")\n",
    "\n",
    "# B. Threat Maintenance (CSR -> Reinstatement CSR)\n",
    "# Start is Extinction, Target is REINSTATEMENT\n",
    "print(\"  > Threat Analysis: Start=CSR(Ext) -> Target=CSR(Reinstatement)\")\n",
    "df_threat_sad = calculate_plasticity_vectors(\n",
    "    X_ext_sad, y_ext_sad, sub_ext_sad,     # Learn: Extinction\n",
    "    X_rst_sad, y_rst_sad, sub_rst_sad,     # Target: Reinstatement\n",
    "    mask_sad, COND_THREAT_LEARN, COND_THREAT_LEARN \n",
    ")\n",
    "df_threat_hc = calculate_plasticity_vectors(\n",
    "    X_ext_hc, y_ext_hc, sub_ext_hc, \n",
    "    X_rst_hc, y_rst_hc, sub_rst_hc, \n",
    "    mask_hc, COND_THREAT_LEARN, COND_THREAT_LEARN\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Statistics & Visualization\n",
    "# =============================================================================\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine for plotting\n",
    "def tag_df(df, grp, cond):\n",
    "    if df.empty: return df\n",
    "    d = df.copy(); d['Group'] = grp; d['Condition'] = cond\n",
    "    return d\n",
    "\n",
    "df_plot = pd.concat([\n",
    "    tag_df(df_safe_sad, 'SAD', 'Safety'), tag_df(df_safe_hc, 'HC', 'Safety'),\n",
    "    tag_df(df_threat_sad, 'SAD', 'Threat'), tag_df(df_threat_hc, 'HC', 'Threat')\n",
    "])\n",
    "\n",
    "if df_plot.empty:\n",
    "    print(\"! No data generated. Check inputs.\")\n",
    "else:\n",
    "    print(f\"\\n[Step 3] Generated {len(df_plot)} subject vectors.\")\n",
    "    \n",
    "    sns.set_context(\"poster\")\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Projection (Magnitude)\n",
    "    sns.barplot(data=df_plot, x='Condition', y='projection', hue='Group', \n",
    "                palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=axes[0,0], \n",
    "                capsize=.1, errorbar='se')\n",
    "    axes[0,0].axhline(0, color='k', ls='--')\n",
    "    axes[0,0].set_title(\"Magnitude (Scalar Projection)\")\n",
    "    \n",
    "    # 2. Cosine (Fidelity)\n",
    "    sns.barplot(data=df_plot, x='Condition', y='cosine', hue='Group', \n",
    "                palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=axes[0,1], \n",
    "                capsize=.1, errorbar='se')\n",
    "    axes[0,1].axhline(0, color='k', ls='--')\n",
    "    axes[0,1].set_title(\"Directional Fidelity (Cosine)\")\n",
    "    \n",
    "    # 3. Stats (Printout)\n",
    "    print(\"\\n--- Statistical Summary (SAD vs HC) ---\")\n",
    "    for cond in ['Safety', 'Threat']:\n",
    "        print(f\"\\nCondition: {cond}\")\n",
    "        for met in ['projection', 'cosine']:\n",
    "            d_s = df_plot[(df_plot['Condition']==cond) & (df_plot['Group']=='SAD')][met]\n",
    "            d_h = df_plot[(df_plot['Condition']==cond) & (df_plot['Group']=='HC')][met]\n",
    "            \n",
    "            # One-sample t-test (vs 0)\n",
    "            if len(d_s)>1: \n",
    "                t0_s, p0_s = ttest_1samp(d_s, 0, alternative='greater')\n",
    "                print(f\"  > SAD > 0 ({met}): t={t0_s:.3f}, p={p0_s:.4f}\")\n",
    "            if len(d_h)>1:\n",
    "                t0_h, p0_h = ttest_1samp(d_h, 0, alternative='greater')\n",
    "                print(f\"  > HC  > 0 ({met}): t={t0_h:.3f}, p={p0_h:.4f}\")\n",
    "\n",
    "            # Group Diff\n",
    "            if len(d_s)>1 and len(d_h)>1:\n",
    "                t, p = ttest_ind(d_s, d_h)\n",
    "                sig = \"*\" if p < 0.05 else \"ns\"\n",
    "                print(f\"  > Group Diff ({met}): t={t:.3f}, p={p:.4f} {sig}\")\n",
    "\n",
    "    # 4. Scatter (Init Dist vs Projection)\n",
    "    sns.scatterplot(data=df_plot, x='init_dist', y='projection', hue='Group', style='Condition', \n",
    "                    palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, alpha=0.7, ax=axes[1,0], s=100)\n",
    "    axes[1,0].axhline(0, color='k', ls='--')\n",
    "    axes[1,0].set_title(\"Learning vs Initial Distance\")\n",
    "    \n",
    "    axes[1,1].axis('off') # Empty slot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "results_13 = {\n",
    "    'safe_sad': df_safe_sad,\n",
    "    'safe_hc': df_safe_hc,\n",
    "    'threat_sad': df_threat_sad,\n",
    "    'threat_hc': df_threat_hc,\n",
    "}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 10: Analysis 1.3 - Dynamic Representational Drift (Single-Trial Trajectories)\n",
    "# Objective: Visualize plasticity trial-by-trial using Top 5% Features.\n",
    "# Method: Project every trial onto the Ideal Axis (Start -> Target).\n",
    "#   - Score 0 = Resembles Early Extinction (Start)\n",
    "#   - Score 1 = Resembles Target (CS- or Reinstated CSR)\n",
    "\n",
    "print(\"--- Running Analysis 1.3: Single-Trial Trajectories (Top 5%) ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Constants\n",
    "COND_SAFETY_TARGET = \"CS-\"\n",
    "COND_SAFETY_LEARN = \"CSS\"\n",
    "COND_THREAT_LEARN = \"CSR\"\n",
    "BLOCK_SIZE = 1  # Group trials for smoother plotting (1 = Raw Single Trial)\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Feature Selection (Top 5% Positive)\n",
    "# =============================================================================\n",
    "print(f\"\\n[Step 0] Selecting Top {100-PERCENTILE_THRESH}% Features...\")\n",
    "\n",
    "# Use Top 5% voxel masks from Analysis 1.1 (Cell 9)\n",
    "if 'importance_masks' not in locals():\n",
    "    raise ValueError(\"Top 5% masks not found. Run Analysis 1.1 / Cell 9 first.\")\n",
    "mask_sad = importance_masks['SAD']\n",
    "mask_hc = importance_masks['HC']\n",
    "print(f\"  > Using Top 5% voxels: SAD={int(np.sum(mask_sad))}, HC={int(np.sum(mask_hc))}\")\n",
    "\n",
    "\n",
    "# --- FIXED FUNCTION ---\n",
    "def get_phase_data(group, phase):\n",
    "    try:\n",
    "        d = data_subsets[group][phase]\n",
    "        if d is None: return None, None, None\n",
    "        return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "    except KeyError:\n",
    "        return None, None, None\n",
    "\n",
    "# Load Start Data (Extinction)\n",
    "X_ext_sad, y_ext_sad, sub_ext_sad = get_phase_data(\"SAD_Placebo\", \"ext\")\n",
    "X_ext_hc, y_ext_hc, sub_ext_hc = get_phase_data(\"HC_Placebo\", \"ext\")\n",
    "\n",
    "# Load Target Data (Reinstatement)\n",
    "X_rst_sad, y_rst_sad, sub_rst_sad = get_phase_data(\"SAD_Placebo\", \"rst\")\n",
    "X_rst_hc, y_rst_hc, sub_rst_hc = get_phase_data(\"HC_Placebo\", \"rst\")\n",
    "\n",
    "# Check Reinstatement Availability\n",
    "if X_rst_sad is None or X_rst_hc is None:\n",
    "    raise ValueError(\"Reinstatement data missing in data_subsets. Run Cell 5 and ensure phase3 is loaded.\")\n",
    "# Check Global Availability (for CS-)\n",
    "if 'X_ext' in locals():\n",
    "    X_glob, y_glob, sub_glob = X_ext, y_ext, sub_ext\n",
    "else:\n",
    "    # Fallback to group data if global is missing\n",
    "    X_glob, y_glob, sub_glob = X_ext_sad, y_ext_sad, sub_ext_sad\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Trajectory Calculation Helper\n",
    "# =============================================================================\n",
    "def calc_trajectory(\n",
    "    X_learn, y_learn, sub_learn,    # The trials we want to project (the \"Movie\")\n",
    "    X_targ, y_targ, sub_targ,       # The dataset containing the Goal State\n",
    "    mask, \n",
    "    cond_learn,                     # Condition to track (e.g., CSS)\n",
    "    cond_target_label               # Label of Goal State (e.g., CS- or CSR)\n",
    "):\n",
    "    # Center Data separately to remove session effects\n",
    "    X_learn = X_learn[:, mask]\n",
    "    X_targ = X_targ[:, mask]\n",
    "    \n",
    "    unique_subs = np.intersect1d(np.unique(sub_learn), np.unique(sub_targ))\n",
    "    res = {'sub': [], 'trial': [], 'score': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        # 1. Get Subject Data\n",
    "        xl = X_learn[sub_learn == sub]; yl = y_learn[sub_learn == sub]\n",
    "        xt = X_targ[sub_targ == sub]; yt = y_targ[sub_targ == sub]\n",
    "        \n",
    "        # 2. Define Start Point (Early Learning)\n",
    "        # We define \"Start\" as the centroid of the FIRST HALF of the learning trials\n",
    "        mask_l = (yl == cond_learn)\n",
    "        trials_l = xl[mask_l]\n",
    "        if len(trials_l) < 2: continue\n",
    "        \n",
    "        cutoff = max(1, len(trials_l) // 2)\n",
    "        P_start = np.mean(trials_l[:cutoff], axis=0)\n",
    "        \n",
    "        # 3. Define Target Point\n",
    "        mask_t = (yt == cond_target_label)\n",
    "        if np.sum(mask_t) == 0: continue\n",
    "        P_target = np.mean(xt[mask_t], axis=0)\n",
    "        \n",
    "        # 4. Define Axis\n",
    "        V_axis = P_target - P_start\n",
    "        sq_norm = np.dot(V_axis, V_axis)\n",
    "        if sq_norm == 0: continue\n",
    "        \n",
    "        # 5. Project Each Trial\n",
    "        # Logic: Score = ((Trial - Start) . Axis) / ||Axis||^2\n",
    "        # This normalizes the progress: 0.0 = Start, 1.0 = Target\n",
    "        \n",
    "        # We center the trials relative to the Start Point of this specific axis\n",
    "        trials_centered = trials_l - P_start\n",
    "        \n",
    "        scores = np.dot(trials_centered, V_axis) / sq_norm\n",
    "        \n",
    "        for i, s in enumerate(scores):\n",
    "            res['sub'].append(sub)\n",
    "            res['trial'].append(i + 1)\n",
    "            res['score'].append(s)\n",
    "            \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Execute Analysis\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Calculating Single-Trial Trajectories...\")\n",
    "\n",
    "# A. Safety Learning\n",
    "# Axis: Early CSS (Ext) --> CS- Centroid (Ext/Global)\n",
    "print(\"  > Safety: CSS Trials projecting onto [Early CSS -> CS-]\")\n",
    "df_safe_sad = calc_trajectory(X_ext_sad, y_ext_sad, sub_ext_sad, X_glob, y_glob, sub_glob, mask_sad, COND_SAFETY_LEARN, COND_SAFETY_TARGET)\n",
    "df_safe_hc = calc_trajectory(X_ext_hc, y_ext_hc, sub_ext_hc, X_glob, y_glob, sub_glob, mask_hc, COND_SAFETY_LEARN, COND_SAFETY_TARGET)\n",
    "\n",
    "# B. Threat Maintenance\n",
    "# Axis: Early CSR (Ext) --> Reinstated CSR Centroid (Rst)\n",
    "print(\"  > Threat: CSR Trials projecting onto [Early CSR -> Reinstated CSR]\")\n",
    "df_threat_sad = calc_trajectory(X_ext_sad, y_ext_sad, sub_ext_sad, X_rst_sad, y_rst_sad, sub_rst_sad, mask_sad, COND_THREAT_LEARN, COND_THREAT_LEARN)\n",
    "df_threat_hc = calc_trajectory(X_ext_hc, y_ext_hc, sub_ext_hc, X_rst_hc, y_rst_hc, sub_rst_hc, mask_hc, COND_THREAT_LEARN, COND_THREAT_LEARN)\n",
    "\n",
    "# =============================================================================\n",
    "# Detailed Statistics\n",
    "# =============================================================================\n",
    "def run_detailed_stats(df_sad, df_hc, label):\n",
    "    if df_sad.empty or df_hc.empty: return pd.DataFrame()\n",
    "    \n",
    "    trials = sorted(list(set(df_sad['trial'].unique()) & set(df_hc['trial'].unique())))\n",
    "    results = []\n",
    "    \n",
    "    for t in trials:\n",
    "        s_vals = df_sad[df_sad['trial'] == t]['score'].values\n",
    "        h_vals = df_hc[df_hc['trial'] == t]['score'].values\n",
    "        \n",
    "        # A. SAD > 0\n",
    "        t_s, p_s = ttest_1samp(s_vals, 0, alternative='greater')\n",
    "        df_s = len(s_vals) - 1\n",
    "        \n",
    "        # B. HC > 0\n",
    "        t_h, p_h = ttest_1samp(h_vals, 0, alternative='greater')\n",
    "        df_h = len(h_vals) - 1\n",
    "        \n",
    "        # C. SAD != HC\n",
    "        t_d, p_d = ttest_ind(s_vals, h_vals)\n",
    "        df_d = len(s_vals) + len(h_vals) - 2\n",
    "        \n",
    "        results.append({\n",
    "            'Trial': t,\n",
    "            'SAD_t': t_s, 'SAD_df': df_s, 'SAD_p': p_s,\n",
    "            'HC_t': t_h, 'HC_df': df_h, 'HC_p': p_h,\n",
    "            'Diff_t': t_d, 'Diff_df': df_d, 'Diff_p': p_d\n",
    "        })\n",
    "        \n",
    "    stats_df = pd.DataFrame(results)\n",
    "    \n",
    "    # FDR Correction\n",
    "    if not stats_df.empty:\n",
    "        _, stats_df['SAD_p_fdr'], _, _ = multipletests(stats_df['SAD_p'], alpha=0.05, method='fdr_bh')\n",
    "        _, stats_df['HC_p_fdr'], _, _ = multipletests(stats_df['HC_p'], alpha=0.05, method='fdr_bh')\n",
    "        _, stats_df['Diff_p_fdr'], _, _ = multipletests(stats_df['Diff_p'], alpha=0.05, method='fdr_bh')\n",
    "        \n",
    "    print(f\"\\n--- Statistics: {label} ---\")\n",
    "    # Print significant trials (Diff)\n",
    "    sig_diff = stats_df[stats_df['Diff_p_fdr'] < 0.05]\n",
    "    if not sig_diff.empty:\n",
    "        print(\"Significant Group Differences (FDR < 0.05):\")\n",
    "        print(sig_diff[['Trial', 'Diff_t', 'Diff_df', 'Diff_p', 'Diff_p_fdr']].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant group differences found (FDR corrected).\")\n",
    "        \n",
    "    return stats_df\n",
    "\n",
    "print(\"\\n[Step 3] Calculating Statistics...\")\n",
    "stats_safe = run_detailed_stats(df_safe_sad, df_safe_hc, \"Safety Learning\")\n",
    "stats_threat = run_detailed_stats(df_threat_sad, df_threat_hc, \"Threat Maintenance\")\n",
    "# =============================================================================\n",
    "# 4. Visualization\n",
    "# =============================================================================\n",
    "def prepare_plot(df_sad, df_hc, name):\n",
    "    if df_sad.empty and df_hc.empty: return pd.DataFrame()\n",
    "    d_list = []\n",
    "    if not df_sad.empty:\n",
    "        d1 = df_sad.copy(); d1['Group'] = 'SAD'; d_list.append(d1)\n",
    "    if not df_hc.empty:\n",
    "        d2 = df_hc.copy();  d2['Group'] = 'HC'; d_list.append(d2)\n",
    "    \n",
    "    if not d_list: return pd.DataFrame()\n",
    "    \n",
    "    df = pd.concat(d_list)\n",
    "    df['Condition'] = name\n",
    "    # Bin trials if needed\n",
    "    if BLOCK_SIZE > 1:\n",
    "        df['trial'] = ((df['trial'] - 1) // BLOCK_SIZE) + 1\n",
    "    return df\n",
    "\n",
    "df_safe = prepare_plot(df_safe_sad, df_safe_hc, \"Safety Learning\")\n",
    "df_threat = prepare_plot(df_threat_sad, df_threat_hc, \"Threat Maintenance\")\n",
    "\n",
    "if df_safe.empty and df_threat.empty:\n",
    "    print(\"! No data to plot.\")\n",
    "else:\n",
    "    sns.set_context(\"poster\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(22, 9), sharey=True)\n",
    "    \n",
    "    # 1. Safety Plot\n",
    "    if not df_safe.empty:\n",
    "        sns.lineplot(data=df_safe, x='trial', y='score', hue='Group', \n",
    "                     palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, \n",
    "                     lw=3, marker=\"o\", err_style=\"band\", ax=axes[0])\n",
    "        axes[0].set_title(\"A. Safety Trajectory\\n(Target = CS-)\")\n",
    "        axes[0].set_ylabel(\"Similarity Score (0=Start, 1=Target)\")\n",
    "        axes[0].axhline(0, color='gray', ls='--', label='Start (Fear)')\n",
    "        axes[0].axhline(1, color='#2ca02c', ls='-', lw=2, label='Target (CS-)')\n",
    "        axes[0].legend(loc='upper left')\n",
    "\n",
    "    # 2. Threat Plot\n",
    "    if not df_threat.empty:\n",
    "        sns.lineplot(data=df_threat, x='trial', y='score', hue='Group', \n",
    "                     palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, \n",
    "                     lw=3, marker=\"s\", err_style=\"band\", ax=axes[1])\n",
    "        axes[1].set_title(\"B. Threat Maintenance\\n(Target = Early Half Reinstated CSR)\")\n",
    "        axes[1].set_xlabel(f\"Trial (Block Size: {BLOCK_SIZE})\")\n",
    "        axes[1].axhline(0, color='gray', ls='--', label='Start (Ext Early)')\n",
    "        axes[1].axhline(1, color='#d62728', ls='-', lw=2, label='Target (Early Half Reinstated CSR)')\n",
    "        axes[1].legend(loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "results_13 = {\n",
    "    'stats_safe': stats_safe, \n",
    "    'stats_threat': stats_threat,\n",
    "    'data_safe': df_safe,\n",
    "    'data_threat': df_threat\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 11: Analysis 1.4 - Decision Boundary Characteristics (Self-Network with Stats)\n",
    "# Objective: Quantify \"Cognitive Certainty\" (Entropy) and \"Decision Sharpness\" (Kurtosis) \n",
    "#            using each group's NATIVE feature network.\n",
    "# Method: Cross-Validated Probability Extraction (Fixed Optimal C).\n",
    "\n",
    "print(\"--- Running Analysis 1.4: Self-Network Statistics (Entropy, Kurtosis, Variance) ---\")\n",
    "\n",
    "# Constants\n",
    "COND_CLASS_THREAT = \"CSR\"\n",
    "COND_CLASS_SAFE = \"CSS\"\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup Feature Masks (Native) & Best Params\n",
    "# =============================================================================\n",
    "if 'importance_scores' not in locals(): \n",
    "    raise ValueError(\"Run Cell 8 first to generate 'importance_scores'.\")\n",
    "\n",
    "def get_significant_mask(scores): \n",
    "    return scores > 0\n",
    "\n",
    "mask_sad_native = get_significant_mask(importance_scores['SAD'])\n",
    "mask_hc_native = get_significant_mask(importance_scores['HC'])\n",
    "\n",
    "if 'subject_best_params' not in locals():\n",
    "    print(\"  > 'subject_best_params' not found. Using default C=1.0.\")\n",
    "    # Fallback default\n",
    "    subject_best_params = {}\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Calculation Helper (Entropy, Kurtosis, Variance)\n",
    "# =============================================================================\n",
    "def calculate_distribution_stats(X, y, subjects, feature_mask, best_params_dict):\n",
    "    # Slice Features & Center\n",
    "    X_masked = X[:, feature_mask]\n",
    "    \n",
    "    unique_subs = np.unique(subjects)\n",
    "    res = {'sub': [], 'entropy': [], 'kurtosis': [], 'variance': [], 'probabilities': [], 'brier': [], 'calib': []}\n",
    "    \n",
    "    for sub in unique_subs:\n",
    "        c_val = best_params_dict.get(sub, 1.0)\n",
    "        mask_sub = (subjects == sub)\n",
    "        X_sub = X_masked[mask_sub]; y_sub = y[mask_sub]\n",
    "        \n",
    "        # Filter Boundary Classes\n",
    "        mask_binary = np.isin(y_sub, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n",
    "        X_binary = X_sub[mask_binary]; y_binary = y_sub[mask_binary]\n",
    "        \n",
    "        if len(y_binary) < 10: continue\n",
    "        \n",
    "        try:\n",
    "            # Configure Model\n",
    "            fixed_model = build_binary_pipeline()\n",
    "            fixed_model.set_params(classification__C=c_val)\n",
    "            \n",
    "            # Cross-Validation\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "            calib_model = CalibratedClassifierCV(\n",
    "                fixed_model,\n",
    "                method=\"sigmoid\",\n",
    "                cv=3\n",
    "            )\n",
    "            probs_all = cross_val_predict(calib_model, X_binary, y_binary, cv=cv, method='predict_proba', n_jobs=1)\n",
    "            \n",
    "            # Extract Safety Cue Probabilities (P(Threat | Safety Cue))\n",
    "            classes = sorted(np.unique(y_binary))\n",
    "            if COND_CLASS_THREAT not in classes: continue\n",
    "            idx_threat = classes.index(COND_CLASS_THREAT)\n",
    "            \n",
    "            mask_css = (y_binary == COND_CLASS_SAFE)\n",
    "            if np.sum(mask_css) == 0: continue\n",
    "            probs_css = probs_all[mask_css, idx_threat]\n",
    "            \n",
    "            # Metrics\n",
    "            # Calibration Metrics\n",
    "            y_bin_threat = (y_binary == COND_CLASS_THREAT).astype(int)\n",
    "            brier = brier_score_loss(y_bin_threat, probs_all[:, idx_threat])\n",
    "            frac_pos, mean_pred = calibration_curve(y_bin_threat, probs_all[:, idx_threat], n_bins=CALIB_BINS, strategy='uniform')\n",
    "            # 1. Entropy\n",
    "            p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n",
    "            trial_entropies = [entropy([p, 1-p], base=2) for p in p_clean]\n",
    "            \n",
    "            # 2. Kurtosis (Fisher's definition, Normal = 0.0)\n",
    "            k_val = kurtosis(probs_css, fisher=True)\n",
    "            \n",
    "            # 3. Variance\n",
    "            v_val = np.var(probs_css)\n",
    "            \n",
    "            res['sub'].append(sub)\n",
    "            res['entropy'].append(np.mean(trial_entropies))\n",
    "            res['kurtosis'].append(k_val)\n",
    "            res['variance'].append(v_val)\n",
    "            res['probabilities'].append(probs_css)\n",
    "            res['brier'].append(brier)\n",
    "            res['calib'].append({'frac_pos': frac_pos, 'mean_pred': mean_pred})\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print(f\"  ! Subject {sub} failed: {e}\")\n",
    "            pass\n",
    "            \n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Execution (Self-Network)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Calculating Statistics (Native Networks)...\")\n",
    "\n",
    "# --- UPDATED DATA LOADING FROM CELL 5 STRUCTURE ---\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets or data_subsets[group_key]['ext'] is None:\n",
    "        raise ValueError(f\"Extinction data for {group_key} missing. Check Cell 5.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "# Load SAD Data\n",
    "X_sad, y_sad, sub_sad = get_ext_data(\"SAD_Placebo\")\n",
    "# Load HC Data\n",
    "X_hc, y_hc, sub_hc = get_ext_data(\"HC_Placebo\")\n",
    "\n",
    "# SAD Analysis (Native)\n",
    "print(\"  > Analyzing SAD Placebo...\")\n",
    "df_sad_stats = calculate_distribution_stats(\n",
    "    X_sad, y_sad, sub_sad, \n",
    "    mask_sad_native, subject_best_params\n",
    ")\n",
    "\n",
    "# HC Analysis (Native)\n",
    "print(\"  > Analyzing HC Placebo...\")\n",
    "df_hc_stats = calculate_distribution_stats(\n",
    "    X_hc, y_hc, sub_hc, \n",
    "    mask_hc_native, subject_best_params\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Statistical Comparison\n",
    "# =============================================================================\n",
    "def compare_metric(vec1, vec2, metric_name):\n",
    "    print(f\"\\n--- Metric: {metric_name} ---\")\n",
    "    if len(vec1) == 0 or len(vec2) == 0:\n",
    "        print(\"  ! Insufficient data.\")\n",
    "        return 1.0\n",
    "        \n",
    "    print(f\"  > SAD Mean: {np.mean(vec1):.3f}\")\n",
    "    print(f\"  > HC Mean:  {np.mean(vec2):.3f}\")\n",
    "    \n",
    "    t, p, _, _ = perm_ttest_ind(vec1, vec2, n_perm=N_PERMUTATION)\n",
    "    sig = \"*\" if p < 0.05 else \"ns\"\n",
    "    print(f\"  > Comparison: t={t:.3f}, p={p:.4f} ({sig})\")\n",
    "    return p\n",
    "\n",
    "print(\"\\n--- RESULTS: Self-Network Decision Statistics ---\")\n",
    "p_ent = compare_metric(df_sad_stats['entropy'], df_hc_stats['entropy'], \"Entropy (Uncertainty)\")\n",
    "p_kurt = compare_metric(df_sad_stats['kurtosis'], df_hc_stats['kurtosis'], \"Kurtosis (Sharpness)\")\n",
    "p_var = compare_metric(df_sad_stats['variance'], df_hc_stats['variance'], \"Variance (Spread)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Visualization\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\")\n",
    "fig = plt.figure(figsize=(24, 8))\n",
    "gs = fig.add_gridspec(1, 3)\n",
    "\n",
    "# A. Entropy (Violin)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "if not df_sad_stats.empty and not df_hc_stats.empty:\n",
    "    df_ent_plot = pd.concat([\n",
    "        pd.DataFrame({'Val': df_sad_stats['entropy'], 'Group': 'SAD'}),\n",
    "        pd.DataFrame({'Val': df_hc_stats['entropy'], 'Group': 'HC'})\n",
    "    ])\n",
    "    sns.violinplot(data=df_ent_plot, x='Group', y='Val', palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=ax1)\n",
    "    ax1.set_title(\"Uncertainty (Entropy)\")\n",
    "    ax1.set_ylabel(\"Shannon Entropy (bits)\")\n",
    "    if p_ent < 0.05: ax1.text(0.5, df_ent_plot['Val'].max(), f'* p={p_ent:.3f}', ha='center', fontsize=16)\n",
    "\n",
    "# B. Kurtosis (Box)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "if not df_sad_stats.empty and not df_hc_stats.empty:\n",
    "    df_kurt_plot = pd.concat([\n",
    "        pd.DataFrame({'Val': df_sad_stats['kurtosis'], 'Group': 'SAD'}),\n",
    "        pd.DataFrame({'Val': df_hc_stats['kurtosis'], 'Group': 'HC'})\n",
    "    ])\n",
    "    sns.boxplot(data=df_kurt_plot, x='Group', y='Val', palette={'SAD': '#c44e52', 'HC': '#4c72b0'}, ax=ax2)\n",
    "    ax2.set_title(\"Sharpness (Kurtosis)\")\n",
    "    ax2.set_ylabel(\"Fisher Kurtosis\")\n",
    "    if p_kurt < 0.05: ax2.text(0.5, df_kurt_plot['Val'].max(), f'* p={p_kurt:.3f}', ha='center', fontsize=16)\n",
    "\n",
    "# C. Density (Distribution)\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "if not df_sad_stats.empty and not df_hc_stats.empty:\n",
    "    probs_sad = np.concatenate(df_sad_stats['probabilities'].values)\n",
    "    probs_hc = np.concatenate(df_hc_stats['probabilities'].values)\n",
    "    sns.kdeplot(probs_sad, color='#c44e52', fill=True, label='SAD', bw_adjust=0.6, ax=ax3)\n",
    "    sns.kdeplot(probs_hc, color='#4c72b0', fill=True, label='HC', bw_adjust=0.6, ax=ax3)\n",
    "    ax3.set_title(\"Probability Distribution\")\n",
    "    ax3.set_xlabel(\"P(Threat) for Safety Cues\")\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_14_self = {'df_sad': df_sad_stats, 'df_hc': df_hc_stats}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 12: Analysis 2.1 - Safety Restoration & Threat Discrimination (Mixed Effects)\n",
    "# Objective: Test if Oxytocin rescues network topology in SAD.\n",
    "# Metrics:\n",
    "#   1. Safety Restoration: Dist(CSS, CS-) -> Should DECREASE (Return to baseline).\n",
    "#   2. Threat Discrimination: Dist(CSR, CSS) -> Should INCREASE (Better separation).\n",
    "# Statistical Model: Linear Mixed Effects (LME)\n",
    "#   Formula: Metric ~ Group * Drug\n",
    "#   Random Effect: 1 | Subject (Implicitly handles variance if repeated measures exist)\n",
    "\n",
    "print(\"--- Running Analysis 2.1: Safety Restoration & Threat Discrimination (LME) ---\")\n",
    "\n",
    "# Constants\n",
    "COND_SAFE_LEARN = \"CSS\"\n",
    "COND_SAFE_BASE  = \"CS-\"\n",
    "COND_THREAT     = \"CSR\"\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Validate Masks from Cell 9\n",
    "# =============================================================================\n",
    "if 'mask_sad_top5' not in locals() or 'mask_hc_top5' not in locals():\n",
    "    raise ValueError(\"Top 5% Masks not found! Please run Cell 9 first.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Calculate Distances (Both Metrics)\n",
    "# =============================================================================\n",
    "subgroups_21 = {\"SAD_Placebo\": [], \"SAD_Oxytocin\": [], \"HC_Placebo\": [], \"HC_Oxytocin\": []}\n",
    "\n",
    "# Link subjects to groups\n",
    "if 'sub_to_meta' not in locals():\n",
    "    if 'meta' in locals():\n",
    "        sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n",
    "    else:\n",
    "        raise ValueError(\"Metadata not found.\")\n",
    "\n",
    "for sub in np.unique(sub_ext):\n",
    "    s_str = str(sub).strip()\n",
    "    if s_str in sub_to_meta: info = sub_to_meta[s_str]\n",
    "    elif f\"sub-{s_str}\" in sub_to_meta: info = sub_to_meta[f\"sub-{s_str}\"]\n",
    "    else: continue\n",
    "\n",
    "    key = f\"{info['Group']}_{info['Drug']}\"\n",
    "    if key in subgroups_21: subgroups_21[key].append(sub)\n",
    "\n",
    "data_rows = []\n",
    "print(\"  > Calculating distances (Metric A & Metric B)...\")\n",
    "\n",
    "for key, subject_list in subgroups_21.items():\n",
    "    group, drug = key.split('_')\n",
    "    \n",
    "    # Select Native Mask\n",
    "    current_mask = mask_sad_top5 if group == \"SAD\" else mask_hc_top5\n",
    "        \n",
    "    for sub in subject_list:\n",
    "        mask_sub = (sub_ext == sub)\n",
    "        X_sub = X_ext[mask_sub]\n",
    "        y_sub = y_ext[mask_sub]\n",
    "        \n",
    "        # Apply Mask & Center\n",
    "        X_masked = X_sub[:, current_mask]\n",
    "        \n",
    "        # Extract Prototypes\n",
    "        idx_css = (y_sub == COND_SAFE_LEARN)\n",
    "        idx_cs_ = (y_sub == COND_SAFE_BASE)\n",
    "        idx_csr = (y_sub == COND_THREAT)\n",
    "        \n",
    "        if np.sum(idx_css) < 3 or np.sum(idx_cs_) < 3 or np.sum(idx_csr) < 3: continue\n",
    "        \n",
    "        p_css = np.mean(X_masked[idx_css], axis=0).reshape(1, -1)\n",
    "        p_cs_ = np.mean(X_masked[idx_cs_], axis=0).reshape(1, -1)\n",
    "        p_csr = np.mean(X_masked[idx_csr], axis=0).reshape(1, -1)\n",
    "        \n",
    "        # Metric 1: Safety Restoration (CSS vs CS-)\n",
    "        dist_safety = cdist(p_css, p_cs_, metric='correlation')[0][0]\n",
    "        \n",
    "        # Metric 2: Threat Discrimination (CSR vs CSS)\n",
    "        dist_threat = cdist(p_csr, p_css, metric='correlation')[0][0]\n",
    "            \n",
    "        data_rows.append({\n",
    "            \"Subject\": sub, \"Group\": group, \"Drug\": drug, \"Condition\": key,\n",
    "            \"Dist_Safety\": dist_safety,\n",
    "            \"Dist_Threat\": dist_threat\n",
    "        })\n",
    "\n",
    "df_topo = pd.DataFrame(data_rows)\n",
    "print(f\"  > Computed metrics for {len(df_topo)} subjects.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Statistical Tests (Linear Mixed Effects)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Testing for Interaction (Mixed Effects)...\")\n",
    "\n",
    "def run_lme(formula, data, title):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    # Groups='Subject' handles random intercepts per subject\n",
    "    # If design is between-subject, this converges to GLM/ANOVA but handles missingness better\n",
    "    md = smf.mixedlm(formula, data, groups=data[\"Subject\"]) \n",
    "    try:\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        \n",
    "        # Extract Interaction P-Value safely\n",
    "        term = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n",
    "        if term in mdf.pvalues:\n",
    "            p_val = mdf.pvalues[term]\n",
    "            print(f\"  >>> Interaction P-Value: {p_val:.5f} {'*' if p_val < 0.05 else ''}\")\n",
    "            return p_val\n",
    "        else:\n",
    "            print(\"  ! Interaction term not found in model results.\")\n",
    "            return 1.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ! Model Convergence Failed: {e}\")\n",
    "        return 1.0\n",
    "\n",
    "# Formula: Metric ~ Group * Drug\n",
    "# We set references explicitly: Group=HC, Drug=Placebo\n",
    "form_base = \"~ C(Group, Treatment(reference='HC')) * C(Drug, Treatment(reference='Placebo'))\"\n",
    "\n",
    "# Test 1: Safety Restoration\n",
    "p_int_safe = run_lme(\"Dist_Safety \" + form_base, df_topo, \"Metric 1: Safety Restoration (CSS - CS-)\")\n",
    "\n",
    "# Test 2: Threat Discrimination\n",
    "p_int_threat = run_lme(\"Dist_Threat \" + form_base, df_topo, \"Metric 2: Threat Discrimination (CSR - CSS)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Visualization\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "pal_group = {'SAD': '#c44e52', 'HC': '#4c72b0'}\n",
    "\n",
    "# Plot A: Safety Restoration\n",
    "sns.pointplot(data=df_topo, x='Drug', y='Dist_Safety', hue='Group', \n",
    "              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "              dodge=0.2, markers=['o', 's'], capsize=0.1, ax=axes[0])\n",
    "sns.stripplot(data=df_topo, x='Drug', y='Dist_Safety', hue='Group', \n",
    "              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "              dodge=True, alpha=0.4, jitter=True, legend=False, ax=axes[0])\n",
    "\n",
    "axes[0].set_title(\"A. Safety Restoration\\n(CSS vs CS-)\")\n",
    "axes[0].set_ylabel(\"Correlation Distance (Lower = Better)\")\n",
    "if p_int_safe < 0.05:\n",
    "    axes[0].text(0.5, 0.95, f\"Interaction: p={p_int_safe:.3f}\", transform=axes[0].transAxes, ha='center', fontweight='bold')\n",
    "\n",
    "# Plot B: Threat Discrimination\n",
    "sns.pointplot(data=df_topo, x='Drug', y='Dist_Threat', hue='Group', \n",
    "              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "              dodge=0.2, markers=['o', 's'], capsize=0.1, ax=axes[1])\n",
    "sns.stripplot(data=df_topo, x='Drug', y='Dist_Threat', hue='Group', \n",
    "              palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "              dodge=True, alpha=0.4, jitter=True, legend=False, ax=axes[1])\n",
    "\n",
    "axes[1].set_title(\"B. Threat Discrimination\\n(CSR vs CSS)\")\n",
    "axes[1].set_ylabel(\"Correlation Distance (Higher = Better)\")\n",
    "if p_int_threat < 0.05:\n",
    "    axes[1].text(0.5, 0.95, f\"Interaction: p={p_int_threat:.3f}\", transform=axes[1].transAxes, ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_21 = {'df': df_topo, 'p_safe': p_int_safe, 'p_threat': p_int_threat}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 13: Analysis 2.2 - Drift Efficiency (Safety & Threat Maintenance)\n",
    "# Objective: Test OXT effect on neural drift efficiency in the Core Top 5% Network.\n",
    "# Domains:\n",
    "#   1. Safety Learning:    CSS(Ext) -> CS-(Ext)\n",
    "#   2. Threat Maintenance: CSR(Ext) -> CSR(Reinst)\n",
    "# Stats: Linear Mixed Effects (LME)\n",
    "# Visualization: Line plots (Means \u00b1 SEM)\n",
    "\n",
    "print(\"--- Running Analysis 2.2: Drift Efficiency (Means \u00b1 SEM) ---\")\n",
    "\n",
    "# Constants\n",
    "COND_SAFE_TGT = \"CS-\"\n",
    "COND_SAFE_LRN = \"CSS\"\n",
    "COND_THREAT_LRN = \"CSR\"\n",
    "PERCENTILE_THRESH = 95  # Top 5%\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup: Masks & Data Loading\n",
    "# =============================================================================\n",
    "print(f\"\\n[Step 0] Setup & Data Loading...\")\n",
    "\n",
    "# Reinstatement data source from Cell 5 (X_rein/y_rein/sub_rein)\n",
    "if 'X_rein' not in locals() or X_rein is None:\n",
    "    raise ValueError(\"Reinstatement data missing (X_rein). Run Cell 5.\")\n",
    "X_rst_all = X_rein\n",
    "y_rst_all = y_rein\n",
    "sub_rst_all = sub_rein\n",
    "\n",
    "# Ensure core masks exist\n",
    "if 'mask_sad_core' not in locals() or 'mask_hc_core' not in locals():\n",
    "    if 'importance_masks' in locals():\n",
    "        mask_sad_core = importance_masks['SAD']\n",
    "        mask_hc_core = importance_masks['HC']\n",
    "    else:\n",
    "        raise ValueError(\"Core masks not found. Run Analysis 1.1 / Cell 9 first.\")\n",
    "\n",
    "# Build subject lists if missing\n",
    "if 'subgroups_22' not in locals():\n",
    "    subgroups_22 = {}\n",
    "    for key, d in data_subsets.items():\n",
    "        if d is None or 'ext' not in d or d['ext'] is None:\n",
    "            continue\n",
    "        subgroups_22[key] = np.unique(d['ext']['sub'])\n",
    "\n",
    "# Container for outputs\n",
    "\n",
    "# Reinstatement data (global) fallback\n",
    "data_rows = []\n",
    "\n",
    "if 'importance_masks' not in locals():\n",
    "    raise ValueError(\"Top 5% masks not found. Run Analysis 1.1 / Cell 9 first.\")\n",
    "\n",
    "def calc_drift_metrics(X_start_phase, y_start_phase, X_tgt_phase, y_tgt_phase, \n",
    "                       cond_start, cond_target, mask, sub_id):\n",
    "    # Mask & Center (Phase-wise centering)\n",
    "    X_s = X_start_phase[:, mask]\n",
    "    \n",
    "    X_t = X_tgt_phase[:, mask]\n",
    "    \n",
    "    # Target Centroid\n",
    "    mask_tgt = (y_tgt_phase == cond_target)\n",
    "    if np.sum(mask_tgt) < 2: return None\n",
    "    P_target = np.mean(X_t[mask_tgt], axis=0)\n",
    "    \n",
    "    # Trajectory\n",
    "    mask_lrn = (y_start_phase == cond_start)\n",
    "    idx_lrn = np.where(mask_lrn)[0]\n",
    "    if len(idx_lrn) < 4: return None\n",
    "    \n",
    "    cutoff = len(idx_lrn) // 2\n",
    "    P_start = np.mean(X_s[idx_lrn[:cutoff]], axis=0)\n",
    "    P_end = np.mean(X_s[idx_lrn[cutoff:]], axis=0)\n",
    "    \n",
    "    # Vectors\n",
    "    V_axis = P_target - P_start\n",
    "    V_drift = P_end - P_start\n",
    "    \n",
    "    nA, nD = norm(V_axis), norm(V_drift)\n",
    "    if nA == 0 or nD == 0: return None\n",
    "    \n",
    "    dot = np.dot(V_drift, V_axis)\n",
    "    return {'Cosine': dot / (nA * nD), 'Projection': dot / nA}\n",
    "\n",
    "for key, subject_list in subgroups_22.items():\n",
    "    group, drug = key.split('_')\n",
    "    curr_mask = mask_sad_core if group == \"SAD\" else mask_hc_core\n",
    "    \n",
    "    for sub in subject_list:\n",
    "        m_ext = (sub_ext == sub)\n",
    "        X_e, y_e = X_ext[m_ext], y_ext[m_ext]\n",
    "        \n",
    "        # 1. Safety\n",
    "        res_safe = calc_drift_metrics(X_e, y_e, X_e, y_e, COND_SAFE_LRN, COND_SAFE_TGT, curr_mask, sub)\n",
    "        if res_safe:\n",
    "            data_rows.append({\"Subject\": sub, \"Group\": group, \"Drug\": drug, \"Domain\": \"Safety\", **res_safe})\n",
    "            \n",
    "        # 2. Threat\n",
    "        if X_rst_all is not None:\n",
    "            m_rst = (sub_rst_all == sub)\n",
    "            if np.sum(m_rst) > 0:\n",
    "                X_r, y_r = X_rst_all[m_rst], y_rst_all[m_rst]\n",
    "                res_threat = calc_drift_metrics(X_e, y_e, X_r, y_r, COND_THREAT_LRN, COND_THREAT_LRN, curr_mask, sub)\n",
    "                if res_threat:\n",
    "                    data_rows.append({\"Subject\": sub, \"Group\": group, \"Drug\": drug, \"Domain\": \"Threat\", **res_threat})\n",
    "\n",
    "df_drift = pd.DataFrame(data_rows)\n",
    "print(f\"  > Computed vectors for {len(df_drift['Subject'].unique())} subjects.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Statistics (LME)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Statistical Testing (LME)...\")\n",
    "lme_results = {}\n",
    "\n",
    "for domain in [\"Safety\", \"Threat\"]:\n",
    "    if domain not in df_drift['Domain'].values: continue\n",
    "    df_sub = df_drift[df_drift[\"Domain\"] == domain].copy()\n",
    "    form_base = \"~ C(Group, Treatment(reference='HC')) * C(Drug, Treatment(reference='Placebo'))\"\n",
    "    \n",
    "    print(f\"\\n--- Domain: {domain} ---\")\n",
    "    for metric in [\"Cosine\", \"Projection\"]:\n",
    "        try:\n",
    "            md = smf.mixedlm(f\"{metric} {form_base}\", df_sub, groups=df_sub[\"Subject\"])\n",
    "            mdf = md.fit()\n",
    "            term = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n",
    "            p_val = mdf.pvalues.get(term, 1.0)\n",
    "            print(f\"  > {metric}: Interaction p={p_val:.4f} {'*' if p_val<0.05 else ''}\")\n",
    "            lme_results[f\"{domain}_{metric}\"] = p_val\n",
    "        except:\n",
    "            lme_results[f\"{domain}_{metric}\"] = 1.0\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Visualization (Lines Only, Error=SE)\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "pal_group = {'SAD': '#c44e52', 'HC': '#4c72b0'}\n",
    "\n",
    "def plot_interaction(ax, df, domain, metric, p_val):\n",
    "    data = df[df[\"Domain\"] == domain]\n",
    "    if data.empty: return\n",
    "    \n",
    "    # Error bars = Standard Error (se)\n",
    "    # This approximates within-subject error visualization for group means\n",
    "    sns.pointplot(data=data, x='Drug', y=metric, hue='Group', \n",
    "                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "                  dodge=0.15, markers=['o', 's'], linestyles=['-', '--'], \n",
    "                  capsize=0.1, err_kws={'linewidth': 2.5}, scale=1.2, \n",
    "                  errorbar='se', ax=ax)\n",
    "    \n",
    "    ax.set_title(f\"{domain} - {metric}\")\n",
    "    ax.axhline(0, color='gray', ls='--', alpha=0.5)\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    \n",
    "    if p_val < 0.05:\n",
    "        ax.text(0.5, 0.9, f\"Interaction p={p_val:.3f}\", transform=ax.transAxes, \n",
    "                ha='center', fontweight='bold', color='black')\n",
    "\n",
    "# Plot Grid\n",
    "plot_interaction(axes[0,0], df_drift, \"Safety\", \"Cosine\", lme_results.get(\"Safety_Cosine\", 1.0))\n",
    "plot_interaction(axes[0,1], df_drift, \"Safety\", \"Projection\", lme_results.get(\"Safety_Projection\", 1.0))\n",
    "plot_interaction(axes[1,0], df_drift, \"Threat\", \"Cosine\", lme_results.get(\"Threat_Cosine\", 1.0))\n",
    "plot_interaction(axes[1,1], df_drift, \"Threat\", \"Projection\", lme_results.get(\"Threat_Projection\", 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Error bars represent Standard Error of the Mean (SEM).\")\n",
    "results_22 = {'df': df_drift, 'stats': lme_results}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 14: Analysis 2.3 - The \"Probabilistic Opening\" Test (Entropy, Kurtosis, Variance)\n",
    "# Objective: Test if Oxytocin increases \"Cognitive Uncertainty\" in SAD.\n",
    "# Hypothesis: SAD-OXT will show HIGHER Entropy, LOWER Kurtosis, HIGHER Variance than SAD-PLC.\n",
    "# Method: Cross-Validated Probability Extraction -> Metrics.\n",
    "# Stats: Linear Mixed Effects (Metric ~ Group * Drug).\n",
    "\n",
    "print(\"--- Running Analysis 2.3: Probabilistic Opening (Entropy, Kurtosis, Variance) ---\")\n",
    "\n",
    "# Constants\n",
    "COND_CLASS_THREAT = \"CSR\"\n",
    "COND_CLASS_SAFE = \"CSS\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup: Masks & Data\n",
    "# =============================================================================\n",
    "if 'importance_scores' not in locals(): \n",
    "    raise ValueError(\"Importance scores missing. Run Cell 8.\")\n",
    "\n",
    "# Define Native Networks\n",
    "def get_significant_mask(scores): return scores > 0\n",
    "\n",
    "mask_sad_native = get_significant_mask(importance_scores['SAD'])\n",
    "mask_hc_native = get_significant_mask(importance_scores['HC'])\n",
    "print(f\"  > SAD Native Network: {np.sum(mask_sad_native)} voxels\")\n",
    "print(f\"  > HC Native Network:  {np.sum(mask_hc_native)} voxels\")\n",
    "\n",
    "# Load Subject-Group-Drug Mapping\n",
    "if 'sub_to_meta' not in locals():\n",
    "    if 'meta' in locals():\n",
    "        sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n",
    "    else: raise ValueError(\"Metadata not found.\")\n",
    "\n",
    "subgroups_23 = {\"SAD_Placebo\": [], \"SAD_Oxytocin\": [], \"HC_Placebo\": [], \"HC_Oxytocin\": []}\n",
    "for sub in np.unique(sub_ext):\n",
    "    s_str = str(sub).strip()\n",
    "    if s_str in sub_to_meta: info = sub_to_meta[s_str]\n",
    "    elif f\"sub-{s_str}\" in sub_to_meta: info = sub_to_meta[f\"sub-{s_str}\"]\n",
    "    else: continue\n",
    "    \n",
    "    key = f\"{info['Group']}_{info['Drug']}\"\n",
    "    if key in subgroups_23: subgroups_23[key].append(sub)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Calculation Helper (All 3 Metrics)\n",
    "# =============================================================================\n",
    "def calc_metrics_for_subject(X, y, sub_id, feature_mask, C_param=1.0):\n",
    "    # 1. Mask & Center\n",
    "    X_m = X[:, feature_mask]\n",
    "    \n",
    "    # 2. Filter Binary Classes\n",
    "    mask_bin = np.isin(y, [COND_CLASS_THREAT, COND_CLASS_SAFE])\n",
    "    X_bin, y_bin = X_m[mask_bin], y[mask_bin]\n",
    "    \n",
    "    if len(y_bin) < 10: return None\n",
    "    \n",
    "    try:\n",
    "                # 3. Nested CV for C (within-subject)\n",
    "        outer_cv = get_cv(y_bin, np.full(len(y_bin), sub_id), n_splits=SUBJECT_CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        inner_cv = get_cv(y_bin, np.full(len(y_bin), sub_id), n_splits=SUBJECT_INNER_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        probs_all = np.zeros((len(y_bin), 2))\n",
    "\n",
    "        for train_idx, test_idx in outer_cv.split(X_bin, y_bin, groups=np.full(len(y_bin), sub_id)):\n",
    "            gs = GridSearchCV(build_binary_pipeline(), param_grid, cv=inner_cv, scoring=forced_choice_scorer, n_jobs=1)\n",
    "            gs.fit(X_bin[train_idx], y_bin[train_idx], groups=np.full(len(train_idx), sub_id))\n",
    "            best_model = gs.best_estimator_\n",
    "            probs_all[test_idx] = best_model.predict_proba(X_bin[test_idx])\n",
    "\n",
    "        \n",
    "        # 4. Extract Safety Cue Probabilities\n",
    "        classes = sorted(np.unique(y_bin))\n",
    "        if COND_CLASS_THREAT not in classes: return None\n",
    "        idx_threat = classes.index(COND_CLASS_THREAT)\n",
    "        \n",
    "        mask_css = (y_bin == COND_CLASS_SAFE)\n",
    "        if np.sum(mask_css) == 0: return None\n",
    "        \n",
    "        # Prob(Threat | Safety Cue)\n",
    "        probs_css = probs_all[mask_css, idx_threat]\n",
    "        \n",
    "        # --- Metrics ---\n",
    "        # A. Entropy (Uncertainty)\n",
    "        p_clean = np.clip(probs_css, 1e-9, 1-1e-9)\n",
    "        ents = [entropy([p, 1-p], base=2) for p in p_clean]\n",
    "        val_ent = np.mean(ents)\n",
    "        \n",
    "        # B. Kurtosis (Sharpness) - Fisher's (Normal=0)\n",
    "        val_kurt = kurtosis(probs_css, fisher=True)\n",
    "        \n",
    "        # C. Variance (Spread)\n",
    "        val_var = np.var(probs_css)\n",
    "        \n",
    "        return {'Entropy': val_ent, 'Kurtosis': val_kurt, 'Variance': val_var}\n",
    "        \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Execution Loop\n",
    "# =============================================================================\n",
    "data_rows = []\n",
    "print(\"\\n[Step 1] Calculating Decision Metrics...\")\n",
    "\n",
    "if 'subject_best_params' not in locals(): subject_best_params = {}\n",
    "\n",
    "for key, sub_list in subgroups_23.items():\n",
    "    group, drug = key.split('_')\n",
    "    curr_mask = mask_sad_native if group == \"SAD\" else mask_hc_native\n",
    "    \n",
    "    for sub in sub_list:\n",
    "        mask_s = (sub_ext == sub)\n",
    "        X_s, y_s = X_ext[mask_s], y_ext[mask_s]\n",
    "        \n",
    "        c_val = subject_best_params.get(sub, 1.0)\n",
    "        \n",
    "        res = calc_metrics_for_subject(X_s, y_s, sub, curr_mask, c_val)\n",
    "        \n",
    "        if res is not None:\n",
    "            data_rows.append({\n",
    "                \"Subject\": sub, \"Group\": group, \"Drug\": drug, \n",
    "                \"Entropy\": res['Entropy'], \n",
    "                \"Kurtosis\": res['Kurtosis'], \n",
    "                \"Variance\": res['Variance']\n",
    "            })\n",
    "\n",
    "df_metrics = pd.DataFrame(data_rows)\n",
    "print(f\"  > Computed metrics for {len(df_metrics)} subjects.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Statistical Testing (LME Loop)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Statistical Testing (LME for each metric)...\")\n",
    "\n",
    "stats_results = {}\n",
    "metrics_list = [\"Entropy\", \"Kurtosis\", \"Variance\"]\n",
    "\n",
    "for met in metrics_list:\n",
    "    print(f\"\\n--- Metric: {met} ---\")\n",
    "    try:\n",
    "        # LME: Metric ~ Group * Drug + (1|Subject)\n",
    "        md = smf.mixedlm(f\"{met} ~ C(Group, Treatment(reference='HC')) * C(Drug, Treatment(reference='Placebo'))\", \n",
    "                         df_metrics, groups=df_metrics[\"Subject\"])\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        \n",
    "        # Interaction P-Value\n",
    "        term_int = \"C(Group, Treatment(reference='HC'))[T.SAD]:C(Drug, Treatment(reference='Placebo'))[T.Oxytocin]\"\n",
    "        p_val = mdf.pvalues.get(term_int, 1.0)\n",
    "        stats_results[met] = p_val\n",
    "        print(f\"  >>> Interaction p={p_val:.4f} {'*' if p_val < 0.05 else ''}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ! Model Failed: {e}\")\n",
    "        stats_results[met] = 1.0\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Visualization (Side-by-Side)\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 7))\n",
    "pal_group = {'SAD': '#c44e52', 'HC': '#4c72b0'}\n",
    "\n",
    "def plot_metric(ax, metric, p_val):\n",
    "    sns.pointplot(data=df_metrics, x='Drug', y=metric, hue='Group', \n",
    "                  palette=pal_group, order=['Placebo', 'Oxytocin'], hue_order=['SAD', 'HC'],\n",
    "                  dodge=0.2, markers=['o', 's'], linestyles=['-', '--'], \n",
    "                  capsize=0.1, errorbar='se', scale=1.1, ax=ax)\n",
    "    \n",
    "    ax.set_title(f\"{metric}\")\n",
    "    ax.set_ylabel(metric)\n",
    "    if metric == \"Entropy\": ax.set_ylabel(\"Entropy (Uncertainty)\")\n",
    "    if metric == \"Kurtosis\": ax.set_ylabel(\"Kurtosis (Sharpness)\")\n",
    "    \n",
    "    # Annotate Significance\n",
    "    if p_val < 0.05:\n",
    "        ax.text(0.5, 0.9, f\"Interaction\\np={p_val:.3f}\", transform=ax.transAxes, \n",
    "                ha='center', fontweight='bold', color='black')\n",
    "\n",
    "# Plot all 3\n",
    "plot_metric(axes[0], \"Entropy\", stats_results[\"Entropy\"])\n",
    "plot_metric(axes[1], \"Kurtosis\", stats_results[\"Kurtosis\"])\n",
    "plot_metric(axes[2], \"Variance\", stats_results[\"Variance\"])\n",
    "\n",
    "axes[1].get_legend().remove()\n",
    "axes[2].get_legend().remove()\n",
    "axes[0].legend(loc='lower left', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_23 = {'df': df_metrics, 'stats': stats_results}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 15: Analysis 2.4 - Spatial Re-Alignment (The \"Normalizing\" Effect)\n",
    "# Objective: Test if OXT shifts SAD representations to align with the \"Healthy\" template.\n",
    "# Protocol: \n",
    "#   1. Retrieve the 'CSS vs CSR' model specifically from Analysis 1.1 (Cell 6).\n",
    "#   2. Cross-Decode on SAD-Placebo vs. SAD-Oxytocin (using full feature set).\n",
    "#   3. Metric: Forced-Choice Accuracy (matching Analysis 1.1).\n",
    "# Visualization: Accuracy Heatmap (Train HC -> Test SAD groups).\n",
    "\n",
    "print(\"--- Running Analysis 2.4: Spatial Re-Alignment (Using Analysis 1.1 Output) ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Constants\n",
    "COND_SAFE = \"CSS\"\n",
    "COND_THREAT = \"CSR\"\n",
    "LABELS = [COND_SAFE, COND_THREAT]\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup: Retrieve Correct Model from Cell 6 Results\n",
    "# =============================================================================\n",
    "# We need the specific model trained on Safety (CSS) vs Threat (CSR).\n",
    "target_contrast = \"CSS vs CSR\"\n",
    "alt_contrast = \"CSR vs CSS\"\n",
    "\n",
    "if 'res_hc_dict' in locals():\n",
    "    # Check which key exists in the dictionary\n",
    "    if target_contrast in res_hc_dict:\n",
    "        gold_model = res_hc_dict[target_contrast]['model']\n",
    "        print(f\"  > Retrieved Analysis 1.1 Model for: {target_contrast}\")\n",
    "    elif alt_contrast in res_hc_dict:\n",
    "        gold_model = res_hc_dict[alt_contrast]['model']\n",
    "        print(f\"  > Retrieved Analysis 1.1 Model for: {alt_contrast}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Analysis 1.1 results found, but '{target_contrast}' is missing.\\n\"\n",
    "                         f\"    Available keys: {list(res_hc_dict.keys())}\")\n",
    "else:\n",
    "    raise ValueError(\"Analysis 1.1 results ('res_hc_dict') not found. Please run Cell 6 first.\")\n",
    "\n",
    "# Verify Classes (Must be Safety/Threat)\n",
    "print(f\"  > Model Classes: {gold_model.classes_}\")\n",
    "if COND_THREAT not in gold_model.classes_ or COND_SAFE not in gold_model.classes_:\n",
    "    raise ValueError(f\"CRITICAL: The retrieved model was trained on {gold_model.classes_}, \"\n",
    "                     f\"but this analysis requires {LABELS}.\")\n",
    "\n",
    "# Data Loading Helper\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets: raise ValueError(f\"{group_key} missing.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "X_sad_plc, y_sad_plc, sub_sad_plc = get_ext_data(\"SAD_Placebo\")\n",
    "X_sad_oxt, y_sad_oxt, sub_sad_oxt = get_ext_data(\"SAD_Oxytocin\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Cross-Decoding (Forced-Choice Accuracy, matching Analysis 1.1)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 1] Cross-Decoding on SAD Subgroups (Forced-Choice Accuracy, matching Analysis 1.1)...\")\n",
    "\n",
    "# Filter to only the two classes of interest (CSS and CSR)\n",
    "mask_sad_plc = np.isin(y_sad_plc, LABELS)\n",
    "mask_sad_oxt = np.isin(y_sad_oxt, LABELS)\n",
    "\n",
    "X_sad_plc_filtered = X_sad_plc[mask_sad_plc]\n",
    "y_sad_plc_filtered = y_sad_plc[mask_sad_plc]\n",
    "sub_sad_plc_filtered = sub_sad_plc[mask_sad_plc]\n",
    "\n",
    "X_sad_oxt_filtered = X_sad_oxt[mask_sad_oxt]\n",
    "y_sad_oxt_filtered = y_sad_oxt[mask_sad_oxt]\n",
    "sub_sad_oxt_filtered = sub_sad_oxt[mask_sad_oxt]\n",
    "\n",
    "# Decision scores -> subject-level forced-choice accuracy\n",
    "scores_plc = gold_model.decision_function(X_sad_plc_filtered)\n",
    "scores_oxt = gold_model.decision_function(X_sad_oxt_filtered)\n",
    "\n",
    "scores_plc_2d = (\n",
    "    np.column_stack((-scores_plc, scores_plc))\n",
    "    if scores_plc.ndim == 1\n",
    "    else scores_plc\n",
    ")\n",
    "scores_oxt_2d = (\n",
    "    np.column_stack((-scores_oxt, scores_oxt))\n",
    "    if scores_oxt.ndim == 1\n",
    "    else scores_oxt\n",
    ")\n",
    "\n",
    "acc_sad_plc = compute_subject_forced_choice_accs(\n",
    "    y_sad_plc_filtered,\n",
    "    scores_plc_2d,\n",
    "    sub_sad_plc_filtered,\n",
    "    list(gold_model.classes_)\n",
    ")\n",
    "acc_sad_oxt = compute_subject_forced_choice_accs(\n",
    "    y_sad_oxt_filtered,\n",
    "    scores_oxt_2d,\n",
    "    sub_sad_oxt_filtered,\n",
    "    list(gold_model.classes_)\n",
    ")\n",
    "m_plc = np.mean(acc_sad_plc) if len(acc_sad_plc) > 0 else 0\n",
    "m_oxt = np.mean(acc_sad_oxt) if len(acc_sad_oxt) > 0 else 0\n",
    "\n",
    "print(f\"  > SAD-Placebo Acc (decoded by HC Model):  {m_plc:.1%} (n={len(acc_sad_plc)})\")\n",
    "print(f\"  > SAD-Oxytocin Acc (decoded by HC Model): {m_oxt:.1%} (n={len(acc_sad_oxt)})\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Statistical Comparison\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Statistical Test...\")\n",
    "if len(acc_sad_oxt) > 1 and len(acc_sad_plc) > 1:\n",
    "    # One-tailed t-test: OXT > Placebo\n",
    "    t_stat, p_val = ttest_ind(acc_sad_oxt, acc_sad_plc, alternative='greater')\n",
    "    sig_label = \"*\" if p_val < 0.05 else \"ns\"\n",
    "    print(f\"  > Hypothesis (OXT > PLC): t={t_stat:.3f}, p={p_val:.4f} ({sig_label})\")\n",
    "else:\n",
    "    print(\"  ! Insufficient data for statistics.\")\n",
    "    p_val = 1.0; sig_label=\"nA\"\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Visualization (Heatmap)\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Prepare Matrix: 1 Row (Train HC) x 2 Cols (Test PLC, Test OXT)\n",
    "matrix_data = np.array([[m_plc, m_oxt]])\n",
    "\n",
    "# Annotation String\n",
    "annot_data = np.array([\n",
    "    [f\"{m_plc:.3f}\", f\"{m_oxt:.3f}\\n({sig_label})\"]\n",
    "])\n",
    "\n",
    "# Draw Heatmap\n",
    "sns.heatmap(matrix_data, annot=annot_data, fmt=\"\", cmap=\"RdBu_r\", \n",
    "            vmin=0.3, vmax=0.7, center=0.5, cbar=True,\n",
    "            xticklabels=['Test: SAD-Placebo', 'Test: SAD-Oxytocin'], \n",
    "            yticklabels=['Train: HC-Placebo (Anal 1.1)'], ax=ax)\n",
    "\n",
    "ax.set_title(f\"Analysis 2.4: Spatial Re-Alignment\\n(OXT vs PLC Improvement: p={p_val:.3f})\")\n",
    "plt.yticks(rotation=0) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\" - SAD-Placebo Accuracy ({m_plc:.1%}): How well the SAD brain fits the Healthy template naturally.\")\n",
    "print(f\" - SAD-Oxytocin Accuracy ({m_oxt:.1%}): How well it fits AFTER treatment.\")\n",
    "print(\" - A significant increase indicates OXT 'normalizes' the neural code for Threat vs Safety.\")\n",
    "\n",
    "results_24 = {'acc_plc': acc_sad_plc, 'acc_oxt': acc_sad_oxt, 'p_val': p_val, 'model': gold_model}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 16: Analysis 2.5 - Reverse Cross-Decoding (SAD Template -> HC)\n",
    "# Objective: Test if the \"Disordered\" SAD representation generalizes to Healthy brains.\n",
    "# Protocol:\n",
    "#   1. Train Model on SAD-Placebo (CSS vs CSR).\n",
    "#   2. Feature Selection: Full feature set.\n",
    "#   3. Test on HC-Placebo and HC-Oxytocin.\n",
    "#   4. Metric: Subject-level forced-choice accuracy from decision scores.\n",
    "# Hypothesis: Accuracy should be LOW (near chance), confirming \"Functional Specificity\".\n",
    "\n",
    "print(\"--- Running Analysis 2.5: Reverse Cross-Decoding (SAD -> HC) ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp, ttest_ind\n",
    "\n",
    "# Constants\n",
    "COND_SAFE = \"CSS\"\n",
    "COND_THREAT = \"CSR\"\n",
    "LABELS = [COND_SAFE, COND_THREAT]\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Setup: Full feature set (no mask)\n",
    "# =============================================================================\n",
    "print(\"  > Feature Space: Full feature set (no mask)\")\n",
    "\n",
    "# Data Loading Helper\n",
    "def get_ext_data(group_key):\n",
    "    if group_key not in data_subsets: raise ValueError(f\"{group_key} missing.\")\n",
    "    d = data_subsets[group_key]['ext']\n",
    "    return d[\"X\"], d[\"y\"], d[\"sub\"]\n",
    "\n",
    "# Load Groups\n",
    "X_sad_plc, y_sad_plc, sub_sad_plc = get_ext_data(\"SAD_Placebo\")\n",
    "X_hc_plc, y_hc_plc, sub_hc_plc = get_ext_data(\"HC_Placebo\")\n",
    "X_hc_oxt, y_hc_oxt, sub_hc_oxt = get_ext_data(\"HC_Oxytocin\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Train SAD-Placebo Model (The \"Disordered\" Classifier)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 1] Training SAD-Placebo Model...\")\n",
    "\n",
    "# Filter for CSS vs CSR\n",
    "mask_train = np.isin(y_sad_plc, LABELS)\n",
    "X_train = X_sad_plc[mask_train]\n",
    "y_train = y_sad_plc[mask_train]\n",
    "s_train = sub_sad_plc[mask_train]\n",
    "\n",
    "# Center (Subject-wise)\n",
    "\n",
    "# Train Classifier\n",
    "sad_model = build_binary_pipeline()\n",
    "sad_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"  > Model Trained on {len(np.unique(s_train))} SAD subjects.\")\n",
    "print(f\"  > Classes: {sad_model.classes_}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Cross-Decode on HC Groups (Forced-Choice Accuracy, matching Analysis 1.1)\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 2] Testing on HC Subgroups (Subject-Level Forced-Choice)...\")\n",
    "\n",
    "# Apply feature mask and filter to labels of interest\n",
    "mask_hc_plc_labels = np.isin(y_hc_plc, LABELS)\n",
    "mask_hc_oxt_labels = np.isin(y_hc_oxt, LABELS)\n",
    "\n",
    "X_hc_plc_filtered = X_hc_plc[mask_hc_plc_labels]\n",
    "y_hc_plc_filtered = y_hc_plc[mask_hc_plc_labels]\n",
    "sub_hc_plc_filtered = sub_hc_plc[mask_hc_plc_labels]\n",
    "\n",
    "X_hc_oxt_filtered = X_hc_oxt[mask_hc_oxt_labels]\n",
    "y_hc_oxt_filtered = y_hc_oxt[mask_hc_oxt_labels]\n",
    "sub_hc_oxt_filtered = sub_hc_oxt[mask_hc_oxt_labels]\n",
    "\n",
    "scores_hc_plc = sad_model.decision_function(X_hc_plc_filtered)\n",
    "scores_hc_oxt = sad_model.decision_function(X_hc_oxt_filtered)\n",
    "\n",
    "scores_hc_plc_2d = (\n",
    "    np.column_stack((-scores_hc_plc, scores_hc_plc))\n",
    "    if scores_hc_plc.ndim == 1\n",
    "    else scores_hc_plc\n",
    ")\n",
    "scores_hc_oxt_2d = (\n",
    "    np.column_stack((-scores_hc_oxt, scores_hc_oxt))\n",
    "    if scores_hc_oxt.ndim == 1\n",
    "    else scores_hc_oxt\n",
    ")\n",
    "\n",
    "acc_hc_plc = compute_subject_forced_choice_accs(\n",
    "    y_hc_plc_filtered,\n",
    "    scores_hc_plc_2d,\n",
    "    sub_hc_plc_filtered,\n",
    "    list(sad_model.classes_)\n",
    ")\n",
    "acc_hc_oxt = compute_subject_forced_choice_accs(\n",
    "    y_hc_oxt_filtered,\n",
    "    scores_hc_oxt_2d,\n",
    "    sub_hc_oxt_filtered,\n",
    "    list(sad_model.classes_)\n",
    ")\n",
    "m_hc_plc = np.mean(acc_hc_plc) if len(acc_hc_plc) > 0 else 0\n",
    "m_hc_oxt = np.mean(acc_hc_oxt) if len(acc_hc_oxt) > 0 else 0\n",
    "\n",
    "print(f\"  > HC-Placebo Acc (decoded by SAD):  {m_hc_plc:.1%} (n={len(acc_hc_plc)})\")\n",
    "print(f\"  > HC-Oxytocin Acc (decoded by SAD): {m_hc_oxt:.1%} (n={len(acc_hc_oxt)})\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Statistical Comparison\n",
    "# =============================================================================\n",
    "print(\"\\n[Step 3] Statistical Test (Vs Chance 50%)...\")\n",
    "\n",
    "# Test if HC-Placebo decoding is significantly above chance\n",
    "# If p > 0.05, it confirms SAD representations do NOT generalize to HC (High Specificity)\n",
    "t_chance, p_chance = ttest_1samp(acc_hc_plc, 0.5)\n",
    "sig_chance = \"*\" if p_chance < 0.05 else \"ns\"\n",
    "\n",
    "print(f\"  > SAD->HC Generalization (vs 50%): t={t_chance:.3f}, p={p_chance:.4f} ({sig_chance})\")\n",
    "print(\"    (Note: 'ns' is GOOD here -> implies disordered code is specific to SAD)\")\n",
    "\n",
    "# Compare HC-PLC vs HC-OXT (Exploratory)\n",
    "t_drug, p_drug = ttest_ind(acc_hc_oxt, acc_hc_plc)\n",
    "print(f\"  > Drug Effect in HC (OXT vs PLC): p={p_drug:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Visualization (Heatmap)\n",
    "# =============================================================================\n",
    "sns.set_context(\"poster\", font_scale=0.8)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "matrix_data = np.array([[m_hc_plc, m_hc_oxt]])\n",
    "annot_data = np.array([\n",
    "    [f\"{m_hc_plc:.3f}\\n({sig_chance} vs 0.5)\", f\"{m_hc_oxt:.3f}\"]\n",
    "])\n",
    "\n",
    "sns.heatmap(matrix_data, annot=annot_data, fmt=\"\", cmap=\"RdBu_r\", \n",
    "            vmin=0.3, vmax=0.7, center=0.5, cbar=True,\n",
    "            xticklabels=['Test: HC-Placebo', 'Test: HC-Oxytocin'], \n",
    "            yticklabels=['Train: SAD-Placebo'], ax=ax)\n",
    "\n",
    "ax.set_title(\"Analysis 2.5: Reverse Cross-Decoding\\n(Does SAD 'Disorder' generalize to Healthy?)\")\n",
    "plt.yticks(rotation=0) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "results_25 = {'acc_hc_plc': acc_hc_plc, 'acc_hc_oxt': acc_hc_oxt, 'model': sad_model}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 17: Searchlight RSM (CSR/CSS/CS-) + Early/Late Dynamics (Extinction & Reinstatement)\n",
    "# Objective: Identify regions sensitive to CSR/CSS/CS- via local RSM\n",
    "# and quantify early->late changes in extinction and reinstatement.\n",
    "# Add-ons:\n",
    "#   1) Group-specific maps (SAD/HC, OXT/PLC)\n",
    "#   2) Permutation testing for map significance + FDR correction\n",
    "#   3) Save NIfTI + ROI summary CSV outputs\n",
    "#   4) Group contrast maps (SAD-HC, OXT-PLC)\n",
    "#   5) Progress bars for permutation loops\n",
    "\n",
    "print(\"--- Running Cell 17: Searchlight RSM (CSR/CSS/CS-) ---\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from nilearn import plotting\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# 0. Configuration\n",
    "# =============================================================================\n",
    "ROI_DIR = \"/Users/xiaoqianxiao/tool/parcellation/Gillian_anatomically_constrained\"\n",
    "ROI_ORDER = [\n",
    "    'left_acc', 'left_amygdala', 'left_hippocampus', 'left_insula', 'left_vmpfc',\n",
    "    'right_acc', 'right_amygdala', 'right_hippocampus', 'right_insula', 'right_vmpfc'\n",
    "]\n",
    "\n",
    "COND_LIST = [\"CSR\", \"CSS\", \"CS-\"]\n",
    "SEARCH_RADIUS = 2.5  # in voxels\n",
    "MIN_VOXELS = 20\n",
    "N_PERMUTATION_SEARCHLIGHT = 200\n",
    "ALPHA_FDR = 0.05\n",
    "\n",
    "# Output\n",
    "if 'project_root' in locals():\n",
    "    out_dir = os.path.join(project_root, \"MRI/derivatives/fMRI_analysis/LSS\", \"results\", \"searchlight_rsm\")\n",
    "else:\n",
    "    out_dir = \"/tmp/searchlight_rsm\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "GROUPS_TO_RUN = [\n",
    "    \"ALL\",\n",
    "    \"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"\n",
    "]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RAW NPZ LOAD (force CS- availability)\n",
    "# =============================================================================\n",
    "LOAD_RAW_NPZ = True\n",
    "if LOAD_RAW_NPZ:\n",
    "    project_root = \"/Users/xiaoqianxiao/projects/NARSAD\"\n",
    "    data_root = os.path.join(project_root, \"MRI/derivatives/fMRI_analysis/LSS\", \"firstLevel\", \"all_subjects/fear_network\")\n",
    "    phase2_npz_path = os.path.join(data_root, \"phase2_X_ext_y_ext_roi_voxels.npz\")\n",
    "    phase3_npz_path = os.path.join(data_root, \"phase3_X_reinst_y_reinst_roi_voxels.npz\")\n",
    "\n",
    "    phase2 = np.load(phase2_npz_path, allow_pickle=True)\n",
    "    X_ext = phase2[\"X_ext\"]\n",
    "    y_ext = phase2[\"y_ext\"]\n",
    "    sub_ext = phase2[\"subjects\"]\n",
    "\n",
    "    phase3 = np.load(phase3_npz_path, allow_pickle=True)\n",
    "    X_reinst = phase3[\"X_reinst\"]\n",
    "    y_reinst = phase3[\"y_reinst\"]\n",
    "    sub_reinst = phase3[\"subjects\"]\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Subject ID normalization (align meta and subjects)\n",
    "# =============================================================================\n",
    "\n",
    "def normalize_subject_id(s):\n",
    "    s_str = str(s).strip()\n",
    "    # handle numpy floats like 123.0\n",
    "    if s_str.endswith('.0') and s_str.replace('.', '').isdigit():\n",
    "        s_str = s_str[:-2]\n",
    "    # remove leading 'sub-' if present\n",
    "    if s_str.startswith('sub-'):\n",
    "        s_str = s_str[4:]\n",
    "    return s_str\n",
    "\n",
    "# =============================================================================\n",
    "# META LOAD (force group mapping)\n",
    "# =============================================================================\n",
    "meta_path = os.path.join(project_root, \"MRI/source_data/behav/drug_order.csv\")\n",
    "meta = pd.read_csv(meta_path)\n",
    "meta['subject_id'] = meta['subject_id'].astype(str).str.strip()\n",
    "sub_to_meta = meta.set_index(\"subject_id\")[[\"Group\", \"Drug\"]].to_dict('index')\n",
    "# Normalized lookup (strip sub-, handle numeric ids)\n",
    "sub_to_meta_norm = {normalize_subject_id(k): v for k, v in sub_to_meta.items()}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Build ROI-based voxel mapping (feature index -> voxel coord)\n",
    "# =============================================================================\n",
    "print(\"[Step 1] Building feature-to-voxel mapping...\")\n",
    "\n",
    "roi_paths = []\n",
    "for name in ROI_ORDER:\n",
    "    matches = glob.glob(os.path.join(ROI_DIR, f\"*{name}*.nii*\"))\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"ROI mask not found for: {name}\")\n",
    "    roi_paths.append(matches[0])\n",
    "\n",
    "ref_img = nib.load(roi_paths[0])\n",
    "ref_shape = ref_img.shape\n",
    "coords = []\n",
    "feature_idx = 0\n",
    "roi_feature_idx = {}\n",
    "\n",
    "for name, p in zip(ROI_ORDER, roi_paths):\n",
    "    mask_img = nib.load(p)\n",
    "    mask_data = mask_img.get_fdata() > 0\n",
    "    inds = np.column_stack(np.where(mask_data))\n",
    "    roi_inds = []\n",
    "    for xyz in inds:\n",
    "        coords.append(xyz)\n",
    "        roi_inds.append(feature_idx)\n",
    "        feature_idx += 1\n",
    "    roi_feature_idx[name] = np.array(roi_inds, dtype=int)\n",
    "\n",
    "coords = np.array(coords)\n",
    "print(f\"  > Total voxels in ROI union: {coords.shape[0]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Collect phase data across groups\n",
    "# =============================================================================\n",
    "print(\"[Step 2] Collecting phase data...\")\n",
    "\n",
    "def collect_phase_data(phase_key, group_key=None):\n",
    "    # Always use raw arrays loaded in this cell (includes CS-)\n",
    "    if phase_key == \"ext\":\n",
    "        X_all, y_all, sub_all = X_ext, y_ext, sub_ext\n",
    "    else:\n",
    "        X_all, y_all, sub_all = X_reinst, y_reinst, sub_reinst\n",
    "\n",
    "    xs, ys, subs = [], [], []\n",
    "    if group_key is None or group_key == \"ALL\":\n",
    "        # no filtering, return all subjects\n",
    "        return X_all, y_all, sub_all\n",
    "\n",
    "    group_iter = [group_key]\n",
    "\n",
    "    def get_group_key(sub_id):\n",
    "        s_str = normalize_subject_id(sub_id)\n",
    "        conds = None\n",
    "        if 'sub_to_meta_norm' in globals():\n",
    "            if s_str in sub_to_meta_norm: conds = sub_to_meta_norm[s_str]\n",
    "            elif s_str in sub_to_meta: conds = sub_to_meta[s_str]\n",
    "        if conds:\n",
    "            return f\"{conds['Group']}_{conds['Drug']}\"\n",
    "        return None\n",
    "\n",
    "    subjects = np.unique(sub_all)\n",
    "    for grp in group_iter:\n",
    "        sel_subs = [s for s in subjects if get_group_key(s) == grp]\n",
    "        if not sel_subs:\n",
    "            continue\n",
    "        mask = np.isin(sub_all, sel_subs)\n",
    "        xs.append(X_all[mask])\n",
    "        ys.append(y_all[mask])\n",
    "        subs.append(sub_all[mask])\n",
    "\n",
    "    if not xs:\n",
    "        return None, None, None\n",
    "    return np.vstack(xs), np.concatenate(ys), np.concatenate(subs)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2.5 Diagnostics: Trial counts and subject coverage\n",
    "# =============================================================================\n",
    "print(\"[Step 2.5] Diagnostics: trial counts per condition...\")\n",
    "\n",
    "def diagnose_phase(phase_key):\n",
    "    for group_key in GROUPS_TO_RUN:\n",
    "        X_p, y_p, sub_p = collect_phase_data(phase_key, group_key=group_key)\n",
    "        if X_p is None:\n",
    "            print(f\"  ! {phase_key} missing for {group_key}\")\n",
    "            continue\n",
    "        print(f\"  [{group_key} | {phase_key}] total trials: {len(y_p)}\")\n",
    "        for cond in COND_LIST:\n",
    "            count = int(np.sum(y_p == cond))\n",
    "            print(f\"    - {cond}: {count}\")\n",
    "        # per-subject counts\n",
    "        subs = np.unique(sub_p)\n",
    "        ok_2 = {c: 0 for c in COND_LIST}\n",
    "        ok_4 = {c: 0 for c in COND_LIST}\n",
    "        for s in subs:\n",
    "            mask = sub_p == s\n",
    "            for c in COND_LIST:\n",
    "                n = int(np.sum(y_p[mask] == c))\n",
    "                if n >= 2:\n",
    "                    ok_2[c] += 1\n",
    "                if n >= 4:\n",
    "                    ok_4[c] += 1\n",
    "        print(\"    subjects with >=2 trials per condition:\")\n",
    "        print(\"      \" + \", \".join([f\"{c}:{ok_2[c]}\" for c in COND_LIST]))\n",
    "        print(\"    subjects with >=4 trials per condition (needed for early/late split):\")\n",
    "        print(\"      \" + \", \".join([f\"{c}:{ok_4[c]}\" for c in COND_LIST]))\n",
    "\n",
    "# Run diagnostics for both phases\n",
    "for phase_key in [\"ext\", \"rst\"]:\n",
    "    diagnose_phase(phase_key)\n",
    "\n",
    "\n",
    "print(\"[Step 2.6] Mapping diagnostics...\")\n",
    "try:\n",
    "    sample_subs = list(dict.fromkeys([normalize_subject_id(s) for s in sub_ext]))[:5]\n",
    "    sample_meta = list(sub_to_meta_norm.keys())[:5]\n",
    "    print(f\"  sample subjects: {sample_subs}\")\n",
    "    print(f\"  sample meta keys: {sample_meta}\")\n",
    "    for g in [\"SAD_Placebo\", \"SAD_Oxytocin\", \"HC_Placebo\", \"HC_Oxytocin\"]:\n",
    "        subs = np.unique(sub_ext)\n",
    "        matched = [s for s in subs if get_group_key(s) == g]\n",
    "        print(f\"  matched {g}: {len(matched)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  ! mapping diagnostics failed: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Build early/late condition vectors per subject\n",
    "# =============================================================================\n",
    "print(\"[Step 3] Building condition vectors (early/late)...\")\n",
    "\n",
    "def build_stage_vectors(X, y, sub, stage):\n",
    "    # Returns list of per-subject condition matrices (3 x n_features)\n",
    "    subjects = np.unique(sub)\n",
    "    subj_mats = []\n",
    "\n",
    "    for s in subjects:\n",
    "        rows = []\n",
    "        for cond in COND_LIST:\n",
    "            idx = np.where((sub == s) & (y == cond))[0]\n",
    "            if len(idx) < 2:\n",
    "                rows = []\n",
    "                break\n",
    "            split = len(idx) // 2\n",
    "            if stage == \"early\":\n",
    "                use_idx = idx[:split]\n",
    "            else:\n",
    "                use_idx = idx[split:]\n",
    "            if len(use_idx) == 0:\n",
    "                rows = []\n",
    "                break\n",
    "            rows.append(np.mean(X[use_idx], axis=0))\n",
    "        if rows:\n",
    "            subj_mats.append(np.vstack(rows))  # 3 x n_features\n",
    "    return subj_mats\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Precompute searchlight neighborhoods\n",
    "# =============================================================================\n",
    "print(\"[Step 4] Precomputing searchlight neighborhoods...\")\n",
    "\n",
    "tree = cKDTree(coords)\n",
    "neighbors = tree.query_ball_point(coords, r=SEARCH_RADIUS)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Searchlight RSM computation\n",
    "# =============================================================================\n",
    "print(\"[Step 5] Running searchlight RSM...\")\n",
    "\n",
    "def rsm_score_for_sphere(cond_mat, feat_idx):\n",
    "    # Compute mean off-diagonal dissimilarity for a 3xF condition matrix\n",
    "    if len(feat_idx) < MIN_VOXELS:\n",
    "        return np.nan\n",
    "    A = cond_mat[:, feat_idx]\n",
    "    r01 = pearsonr(A[0], A[1])[0]\n",
    "    r02 = pearsonr(A[0], A[2])[0]\n",
    "    r12 = pearsonr(A[1], A[2])[0]\n",
    "    return np.mean([1 - r01, 1 - r02, 1 - r12])\n",
    "\n",
    "\n",
    "def compute_searchlight_map(subj_mats):\n",
    "    if not subj_mats:\n",
    "        return None\n",
    "    n_centers = coords.shape[0]\n",
    "    vals = np.full(n_centers, np.nan)\n",
    "    for c in range(n_centers):\n",
    "        feat_idx = neighbors[c]\n",
    "        subj_scores = []\n",
    "        for m in subj_mats:\n",
    "            s = rsm_score_for_sphere(m, feat_idx)\n",
    "            if not np.isnan(s):\n",
    "                subj_scores.append(s)\n",
    "        if subj_scores:\n",
    "            vals[c] = float(np.mean(subj_scores))\n",
    "    return vals\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Permutation testing + FDR\n",
    "# =============================================================================\n",
    "print(\"[Step 6] Permutation testing setup...\")\n",
    "\n",
    "def permute_labels_within_subject(y, sub, rng):\n",
    "    y_perm = y.copy()\n",
    "    for s in np.unique(sub):\n",
    "        idx = np.where(sub == s)[0]\n",
    "        y_perm[idx] = rng.permutation(y_perm[idx])\n",
    "    return y_perm\n",
    "\n",
    "\n",
    "def permutation_null_maps(X, y, sub, stage, n_perm=200):\n",
    "    rng = np.random.default_rng(42)\n",
    "    null_maps = []\n",
    "    for _ in tqdm(range(n_perm), desc=f\"Permuting ({stage})\", leave=False):\n",
    "        y_perm = permute_labels_within_subject(y, sub, rng)\n",
    "        mats = build_stage_vectors(X, y_perm, sub, stage)\n",
    "        m = compute_searchlight_map(mats)\n",
    "        if m is not None:\n",
    "            null_maps.append(m)\n",
    "    if not null_maps:\n",
    "        return None\n",
    "    return np.array(null_maps)\n",
    "\n",
    "\n",
    "def pvals_and_fdr(null_maps, obs_map):\n",
    "    pvals = np.mean(null_maps >= obs_map, axis=0)\n",
    "    pvals_flat = pvals[~np.isnan(pvals)]\n",
    "    rej, p_fdr, _, _ = multipletests(pvals_flat, alpha=ALPHA_FDR, method='fdr_bh')\n",
    "    p_fdr_full = np.full_like(pvals, np.nan, dtype=float)\n",
    "    p_fdr_full[~np.isnan(pvals)] = p_fdr\n",
    "    return pvals, p_fdr_full\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Compute early/late maps and deltas (by group)\n",
    "# =============================================================================\n",
    "print(\"[Step 7] Computing maps for Extinction and Reinstatement (by group)...\")\n",
    "\n",
    "results_maps = {}\n",
    "results_pvals = {}\n",
    "results_fdr = {}\n",
    "\n",
    "for group_key in GROUPS_TO_RUN:\n",
    "    for phase_key, phase_name in [(\"ext\", \"Extinction\"), (\"rst\", \"Reinstatement\")]:\n",
    "        X_p, y_p, sub_p = collect_phase_data(phase_key, group_key=group_key)\n",
    "        if X_p is None:\n",
    "            print(f\"  ! {phase_name} data missing for {group_key}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        early_mats = build_stage_vectors(X_p, y_p, sub_p, \"early\")\n",
    "        late_mats = build_stage_vectors(X_p, y_p, sub_p, \"late\")\n",
    "\n",
    "        map_early = compute_searchlight_map(early_mats)\n",
    "        map_late = compute_searchlight_map(late_mats)\n",
    "\n",
    "        if map_early is None or map_late is None:\n",
    "            print(f\"  ! Not enough data for {phase_name}, {group_key}.\")\n",
    "            continue\n",
    "\n",
    "        delta = map_late - map_early\n",
    "\n",
    "        results_maps[(group_key, phase_key, \"early\")] = map_early\n",
    "        results_maps[(group_key, phase_key, \"late\")] = map_late\n",
    "        results_maps[(group_key, phase_key, \"delta\")] = delta\n",
    "\n",
    "        # Permutation p-values + FDR for early and late\n",
    "        null_early = permutation_null_maps(X_p, y_p, sub_p, \"early\", n_perm=N_PERMUTATION_SEARCHLIGHT)\n",
    "        null_late = permutation_null_maps(X_p, y_p, sub_p, \"late\", n_perm=N_PERMUTATION_SEARCHLIGHT)\n",
    "\n",
    "        if null_early is not None:\n",
    "            p_early, fdr_early = pvals_and_fdr(null_early, map_early)\n",
    "            results_pvals[(group_key, phase_key, \"early\")] = p_early\n",
    "            results_fdr[(group_key, phase_key, \"early\")] = fdr_early\n",
    "        if null_late is not None:\n",
    "            p_late, fdr_late = pvals_and_fdr(null_late, map_late)\n",
    "            results_pvals[(group_key, phase_key, \"late\")] = p_late\n",
    "            results_fdr[(group_key, phase_key, \"late\")] = fdr_late\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Group contrasts\n",
    "# =============================================================================\n",
    "print(\"[Step 8] Computing group contrasts...\")\n",
    "\n",
    "contrast_maps = {}\n",
    "\n",
    "def get_map(group, phase, stage):\n",
    "    return results_maps.get((group, phase, stage))\n",
    "\n",
    "for phase_key in [\"ext\", \"rst\"]:\n",
    "    for stage in [\"early\", \"late\", \"delta\"]:\n",
    "        m_sad = get_map(\"SAD_Placebo\", phase_key, stage)\n",
    "        m_hc = get_map(\"HC_Placebo\", phase_key, stage)\n",
    "        m_oxt = get_map(\"SAD_Oxytocin\", phase_key, stage)\n",
    "        m_plc = get_map(\"SAD_Placebo\", phase_key, stage)\n",
    "        if m_sad is not None and m_hc is not None:\n",
    "            contrast_maps[(\"SADminusHC\", phase_key, stage)] = m_sad - m_hc\n",
    "        if m_oxt is not None and m_plc is not None:\n",
    "            contrast_maps[(\"OXTminusPLC\", phase_key, stage)] = m_oxt - m_plc\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Write NIfTI, plot, and save ROI summaries\n",
    "# =============================================================================\n",
    "print(\"[Step 9] Saving NIfTI and ROI summaries...\")\n",
    "\n",
    "def to_nifti(vals, ref_img):\n",
    "    data = np.zeros(ref_shape)\n",
    "    data[:] = np.nan\n",
    "    for idx, v in enumerate(vals):\n",
    "        x, y, z = coords[idx]\n",
    "        data[x, y, z] = v\n",
    "    return nib.Nifti1Image(data, ref_img.affine)\n",
    "\n",
    "roi_rows = []\n",
    "\n",
    "# Save main maps\n",
    "for key, vals in results_maps.items():\n",
    "    group_key, phase_key, stage = key\n",
    "    img = to_nifti(vals, ref_img)\n",
    "    fname = f\"rsm_{group_key}_{phase_key}_{stage}.nii.gz\"\n",
    "    nib.save(img, os.path.join(out_dir, fname))\n",
    "\n",
    "    title = f\"RSM {group_key} {phase_key.upper()} - {stage}\"\n",
    "    plotting.plot_stat_map(img, title=title, display_mode='ortho', threshold=np.nanpercentile(vals, 90))\n",
    "\n",
    "    # ROI summary\n",
    "    for roi_name, idxs in roi_feature_idx.items():\n",
    "        roi_rows.append({\n",
    "            \"group\": group_key,\n",
    "            \"phase\": phase_key,\n",
    "            \"stage\": stage,\n",
    "            \"roi\": roi_name,\n",
    "            \"mean_rsm\": float(np.nanmean(vals[idxs]))\n",
    "        })\n",
    "\n",
    "# Save p-value and FDR maps\n",
    "for key, pvals in results_pvals.items():\n",
    "    group_key, phase_key, stage = key\n",
    "    img = to_nifti(pvals, ref_img)\n",
    "    fname = f\"rsm_pvals_{group_key}_{phase_key}_{stage}.nii.gz\"\n",
    "    nib.save(img, os.path.join(out_dir, fname))\n",
    "\n",
    "for key, fdr in results_fdr.items():\n",
    "    group_key, phase_key, stage = key\n",
    "    img = to_nifti(fdr, ref_img)\n",
    "    fname = f\"rsm_fdr_{group_key}_{phase_key}_{stage}.nii.gz\"\n",
    "    nib.save(img, os.path.join(out_dir, fname))\n",
    "\n",
    "# Save contrast maps\n",
    "for key, vals in contrast_maps.items():\n",
    "    contrast_name, phase_key, stage = key\n",
    "    img = to_nifti(vals, ref_img)\n",
    "    fname = f\"rsm_{contrast_name}_{phase_key}_{stage}.nii.gz\"\n",
    "    nib.save(img, os.path.join(out_dir, fname))\n",
    "    title = f\"RSM {contrast_name} {phase_key.upper()} - {stage}\"\n",
    "    plotting.plot_stat_map(img, title=title, display_mode='ortho', threshold=np.nanpercentile(vals, 90))\n",
    "\n",
    "# Save ROI summary CSV\n",
    "roi_df = pd.DataFrame(roi_rows)\n",
    "roi_csv = os.path.join(out_dir, \"rsm_roi_summary.csv\")\n",
    "roi_df.to_csv(roi_csv, index=False)\n",
    "\n",
    "print(f\"Cell 17 complete: outputs saved to {out_dir}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}